# 硬件结构
## 1.冯诺依曼模型
运算器、控制器、存储器、输入设备、输出设备

运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。

存储单元和输入输出设备要与中央处理器打交道离不开总线。

**内存**：存储的区域是线性的，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1。

**中央处理器**：CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据（32位4字节，64位8字节）。

**常见的寄存器种类：**

- **通用寄存器**，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
- **程序计数器**，用来存储 CPU 要执行下一条指令「所在的**内存地址**」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。
- **指令寄存器**，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。

**总线**：用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：

- **地址总线**，用于指定 CPU 将要操作的内存地址；
- **数据总线**，用于读写内存的数据；
- **控制总线**，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；

## 2.程序执行的基本过程
一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。

CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的**指令周期**。

CPU 执行程序的过程如下：

- 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。
- 第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；
- 第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；


> 数据和指令是分开区域存放的，存数据的是「数据段」，存放指令区域的地方称为「正文段」。

> 指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容；不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码。


## 3.CPU 指令周期的四个阶段？
大多数 CPU 都使用来流水线的方式来执行指令，所谓的流水线就是把一个任务拆分成多个小任务，于是一条指令通常分为 4 个阶段：

1. CPU 通过程序计数器读取（控制器）对应内存地址（存储器）的指令，这个部分称为 Fetch（取得指令）；
1. CPU 对指令进行解码（控制器），这个部分称为 Decode（指令译码）；
1. CPU 执行指令（运算器、控制器），这个部分称为 Execution（执行指令）；
1. CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 Store（数据回写）；


## 4.指令的类型与执行速度
指令从功能角度划分，可以分为 5 大类：

1. **数据传输**类型的指令，比如 store/load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令；
1. **运算**类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据；
1. **跳转**类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、switch-case、函数调用等。
1. **信号**类型的指令，比如发生中断的指令 trap；
1. **闲置**类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；

对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。
>  1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。

<font color = "#F100">程序的 CPU 执行时间 = CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积 </font>

<font color = "#F100"> CPU 时钟周期数 = 指令数 与 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）的乘积</font>

因此，<font color="#F8A">**程序的 CPU 执行时间 = 指令数 * CPI *  时钟周期时间** </font>

- 指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。
- 每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少;
- 时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。

## 5.磁盘与内存
- **寄存器**：每个寄存器可以用来存储一定的字节（byte）的数据。32 位 CPU 中大多数寄存器可以存储 4 个字节，64位可以存储 8 个字节。
- **CPU Cache**：用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。一旦**断电，数据就会丢失**了。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成 **指令缓存** 和 **数据缓存** 。L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。
- **内存**：使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。需要「**定时刷新**」，才能保证数据不会被丢失。
- **SSD/HDD 硬盘**：SSD（Solid-state disk） 固体硬盘与 HDD（Hard Disk Drive）机械硬盘。

**每个存储器只和相邻的一层存储器设备打交道**，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量。

另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。

## 6.CPU Cache 的数据结构和读取过程是什么样的？
CPU Cache 是由很多个Cache Line（缓存块）组成的，Cache Line 是 CPU 从内存读取数据的基本单位，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。

CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，具体这一小块数据的大小，取决于 `coherency_line_size` 的值，一般 64 字节。在内存中，这一块的数据我们称为**内存块（Block）**，读取的时候我们要拿到数据所在内存块的地址。

对于直接映射 Cache 采用的策略，就是**把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址**，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。

为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个**组标记**（Tag）。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。
> 除了**组标记**信息外，CPU Cache Line 还有两个信息：

>- 一个是，从内存加载过来的**实际存放数据（Data）**。
>- 另一个是，**有效位（Valid bit）**，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。

CPU 在从 CPU Cache 读取数据的时候，**并不是读取 CPU Cache Line 中的整个数据块**，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个**字（Word）**。

<font color="#F100">一个内存的访问地址，包括**组标记**、**CPU Cache Line 索引**、**偏移量**这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由**索引 + 有效位 + 组标记 + 数据块**组成。</font>

如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：

1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
1. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
1. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
1. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。


## 7.CPU Cache 的数据写入
**写直达**：把数据同时写入内存和 Cache 中。

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

**写回**：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中。

- 如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表**这个时候CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的**，这种情况是不用把数据写到内存里的；
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的：


 - 1.如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；

 - 2.如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。

<font color="#F100">在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</font>


## 8.CPU缓存的一致性
想实现缓存一致性，关键是要满足 2 点：

- 第一点是**写传播**，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是**事物的串行化**，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是**已修改、独占、共享、已失效**这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

[MESI 协议可视化](https://www.scss.tcd.ie/Jeremy.Jones/vivio/caches/MESI.htm)


## 9.CPU 是如何执行任务的？
CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作

如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。

因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为**伪共享（False Sharing）**

对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。

系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。（priority(new) = priority(old) + nice）

## 10.什么是软中断？
**中断**是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断是一种异步的事件处理机制，可以提高系统的并发处理能力。

中断请求的响应程序，也就是中断处理程序，要**尽可能快的执行完**，这样可以减少对正常进程运行调度地影响。

Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」

- 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。
中断处理程序的上部分和下半部可以理解为：

上半部直接处理硬件请求，也就是**硬中断**，主要是负责耗时短的工作，特点是快速执行；

下半部是由内核触发，也就说**软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

## 11.计算机是怎么存小数的？
计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：

- **符号位**：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；
- **指数位**：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；
- **尾数位**：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；

## 12.Linux中按下电源到展现命令行的过程是怎样的？
步骤1 - 当我们启动电源时，BIOS（基本输入/输出系统）或UEFI（统一可扩展固件接口）固件从非易失性存储器加载，并执行POST（上电自检）。

步骤2 - BIOS/UEFI检测连接到系统的设备，包括CPU、RAM和存储。

步骤3 - 选择一个启动设备以从中引导操作系统。这可以是硬盘、网络服务器或光盘驱动器。

步骤4 - BIOS/UEFI运行引导加载程序（GRUB），该加载程序提供一个菜单，用于选择操作系统或内核功能。

步骤5 - 内核准备好后，我们现在切换到用户空间。内核启动systemd作为第一个用户空间进程，它管理进程和服务，探测所有剩余的硬件，挂载文件系统，并运行桌面环境。

步骤6 - systemd默认在系统引导时激活默认的.target单元。其他分析单元也会被执行。

步骤7 - 系统运行一系列启动脚本并配置环境。

步骤8 - 用户被呈现出登录窗口。系统现在已经准备就绪。

[https://zhuanlan.zhihu.com/p/670742766](https://zhuanlan.zhihu.com/p/670742766)

----------


# 操作系统结构

## 1.Linux 内核
内核一般会提供 4 个基本能力：

1. 管理进程、线程，决定哪个进程、线程使用 CPU，也就是**进程调度**的能力；
1. 管理内存，决定内存的分配和回收，也就是**内存管理**的能力；
1. 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是**硬件通信**能力；
1. 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是**用户程序与操作系统之间的接口**。


## 2.Linux 内核设计的理念

1. MultiTask，多任务（并发或并行）
1. SMP，对称多处理（ CPU 地位相等）
1. ELF，可执行文件链接格式（Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE）
1. Monolithic Kernel，宏内核（内核是一个完整的可执行程序，且拥有最高的权限）


内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。

## 3.内核的架构种类
1. 宏内核，包含多个模块，整个内核像一个完整的程序；
1. 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；
1. 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；

Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。华为的鸿蒙操作系统的内核架构是微内核。


----------


# 内存管理

## 1.虚拟内存有什么作用？
- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
> **局部性原理**是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。

## 2.操作系统是如何管理虚拟地址与物理地址之间的关系？
主要有两种方式，分别是内存分段和内存分页；

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用**分段**（Segmentation）的形式把这些段分离出来。

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。
> 段选择因子和段内偏移量：
> 
>-  段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。
>- 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

分段（根据实际需求分配内存）解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

- 第一个就是内存碎片（外部内存碎片）的问题。
- 第二个就是内存交换的效率低的问题。

<font color="#F1000">分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。</font>

**分页**是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。

虚拟地址与物理地址之间通过页表来映射。页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。

<font color="#F1000">当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</font>

分页机制分配内存的最小单位是一页，即使程序不足一页大小，最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有**内部内存碎片**的现象。

在分页机制下，**虚拟地址分为两部分，页号和页内偏移**。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址

**段页式内存管理** 的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

地址结构就由**段号**、**段内页号**和**页内位移**三部分组成。


> Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。


## 3.Linux 的虚拟地址空间是如何分布的？
虚拟地址空间的内部又被分为**内核空间**和**用户空间**两部分，不同位数的系统，地址空间的范围也不同。

虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实**关联的都是相同的物理内存**。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.png)

用户空间内存，从低到高分别是 6 种不同的内存段：

- 代码段，包括二进制可执行代码；
- 数据段，包括已初始化的静态常量和全局变量；
- BSS(Block Started by Symbol) 段（Unix链接器产生的未初始化数据段），包括未初始化的静态变量和全局变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；


## 4.malloc 是如何分配内存的？
malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 brk() 系统调用从堆分配内存（通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间）
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存（私有匿名映射）；

> brk() 函数是一个系统调用，用于改变进程的结束地址（end of data segment），从而控制进程使用的堆内存大小。当应用程序需要分配更多的内存时，可以通过 brk() 调整堆区边界，增加可用内存大小。

malloc() 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

<font color="#F100">malloc() 分配的是虚拟内存</font>，如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的；只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发**缺页中断**，然后操作系统会建立虚拟内存和物理内存之间的映射关系。



- malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；
- malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。

## 5.内存分配的过程是怎样的？
应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。

缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。

如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收（kswapd）** ：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
- **直接内存回收（direct reclaim）**：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么触发 OOM （Out of Memory）机制。根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，直到释放足够的内存位置

可被回收的内存类型有**文件页**和**匿名页**：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

可以调整文件页和匿名页的回收倾向，尽量倾向于回收文件页
    
> 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。


> 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。

>文件页和匿名页的回收都是基于 LRU 算法（active 和 inactive 两个双向链表），越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。


## 6.在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
	- 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
	- 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；


## 7.如何避免预读失效和缓存污染的问题？

传统的 LRU 算法法无法避免下面这两个问题：

- 预读失效导致缓存命中率下降；
- 缓存污染导致缓存命中率下降；

> 预读失效（Predictive Prefetching Invalidation）是指在计算机系统中，特别是涉及到磁盘I/O操作时，系统预测未来的数据访问模式并提前加载数据到缓存中，但实际的访问模式与预测不符，导致提前加载的数据变得不再需要，从而造成缓存空间的浪费。

>缓存污染（Cache Pollution）是指在缓存中存储了大量不常用或不再需要的数据，这些数据占据了宝贵的缓存空间，导致有用的数据无法被缓存，从而降低了缓存效率。

为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：

- Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）。
- MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。

但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在**缓存污染**的问题。

为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别**提高了升级为热点数据的门槛**：

- Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
- MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
	- 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
	- 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；


通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。


## 8.南桥和北桥
北桥芯片还有个名字叫“图形与内存控制器”，南桥叫“输入/输出控制器”。

北桥芯片组因为与CPU联系密切所以它在主板靠近CPU的位置，而南桥芯片则在远离CPU的位置

北桥芯片(North Bridge)是主板芯片组中起主导作用的最重要的组成部分，也称为**主桥(Host Bridge)**，主要负责与CPU的联系并控制内存、AGP数据在北桥内部传输，提供对CPU的类型和主频、系统的前端总线频率、ECC纠错等支持。

南桥芯片主要是偏向于集成功能，主要负责I/O总线之间的通信，如PCI总线、USB和高级电源管理等。

现在芯片已经没有北桥了，功能被集成到了CPU中。

## 9.什么是虚拟内存？解决了什么问题？
虚拟内存是操作系统内存管理的一种技术，每个进程启动时，操作系统会提供一个独立的虚拟地址空间，这个地址空间是连续的，进程可以很方便的访问内存，这里的内存指的是访问虚拟内存。虚拟内存的目的，一是方便进程进行内存的访问，二是可以使有限的物理内存运行一个比它大很多的程序。

虚拟内存的基本思想：每个程序拥有自己的地址空间，这个空间被分割成很多块，每块称为一页，每一页地址都是连续的地址范围。这些页被映射到物理内存，但不要求是连续的物理内存，也不需要所有的页都映射到物理内存，而是按需分配，在程序片段需要分配内存时由硬件执行映射(通常是 MMU)，调入内存中执行。


## 10.说说分页和分段的机制？
分页是实现虚拟内存的技术，虚拟内存按照固定的大小分为页面，物理内存也会按照固定的大小分成页框，页面和页框大小通常是一样的，一般是 4KB，页面和页框可以实现一对一的映射。分页是一维的，主要是为了获得更大的线性地址空间。但是一个地址空间可能存在很多个表，表的数据大小是动态增长的，由于多个表都在一维空间中，有可能导致一个表的数据覆盖了另一个表。

分段是把虚拟内存划分为多个独立的地址空间，每个地址空间可以动态增长，互不影响。每个段可以单独进行控制，有助于保护和共享。

## 11. 页表的作用？为什么引入多级页表？
页表实现了虚拟内存到物理内存的映射，当访问一个虚拟内存页面时，页面的虚拟地址将作为一个索引指向页表，如果页表中存在对应物理内存的映射，则直接返回物理内存的地址，否则将引发一个缺页异常，从而陷入到内核中分配物理内存，返回对应的物理地址，然后更新页表。

为了加快虚拟地址到物理地址的转换，多数系统会引入一个转换检测缓冲区（TLB）的设备，通常又称为快表，当请求访问一个虚拟地址时，处理器检查是否缓存了该虚拟地址的映射，如果命中则直接返回物理地址，否则就通过页表搜索对应的物理地址。

由于虚拟内存通常比较大(32 位系统通常是 4G)，要实现整个地址空间的映射，需要非常大的页表。解决的办法是引入多级页表，只将那些用到的页面装载进来，因此，多级页表可以大大节约地址转换所需要的的空间。

## 12.页面置换算法有哪几种？
访问的页面不在内存中时，会发生一个缺页异常，操作系统必须将该页换出内存，如果此时内存已满，则操作系统必须将其中一个页面换出，放到 swap 交换区中，为当前访问的页面腾出空间，这个过程称为页面置换。操作系统提供了多种页面置换算法：

**1.最优页面置换算法**

选择一个将来最长时间不会被访问的页面换出。这样可以保证将来最低的缺页率。这是一种理论上的算法，因为无法知道哪个页面是将来最长时间都不会被访问的

**2.最近未使用页面置换算法 (NRU)**

为每个页面设两个状态位：被访问时设置为 R=1 位，页面被修改时，设置为 M=1 位。当启动一个进程时，所有页面都被初始化为 R=0，M=0。其中 R 位会被定时的清 0，以此区分最近被访问的页面和没有被访问的页面。

于是所有页面可以分为以下 4 类：

- 0 类：R=0，M=0；
- 1 类：R=0，M=1；
- 2 类：R=1，M=0；
- 3 类：R=1，M=1；

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出（挑选优先级：1 类 > 2 类 > 3 类）。

**3.最近最少未使用（LRU）页面置换算法**

在内存中维护一个所有页面的单链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**4.先进先出（FIFO）页面置换算法**

维护一个链表，最先进入的页面放在表头，最后进入的页面放在表尾，当缺页中断发生时，直接淘汰表头的页面，并把新的页面放在表尾。

这种算法有可能置换掉经常访问的页面，导致缺页率升高。

**5.第二次机会页面置换算法**

对 FIFO 算法做一个修改：取出表头的页面时，检查该页面的 R 位，如果是 1 表示是最近有访问的，将其清 0，然后放入表尾，然后继续检查下一个表头的页面，直到遇到一个 R 位为 0 的页面，将其换出。

**6.时钟页面置换算法**

单链表改成了环形链表，形成一个时钟，移动的也不是页面，而是中间的表针。检查页面逻辑类似，如果该页面 R 为 0，则直接置换该页面，否则将该 R 位清 0，然后表针向前移动。


## 13.内存是如何分配的？
Linux 分配物理内存的主要机制是页面分配机制（页分配器），使用了著名的伙伴算法，主要用来分配页大小的整数倍的内存(4n KB)。如果是小于页大小的内存分配，通常使用 slab 管理器。通过 slab 分配的内存通常会缓存起来，方便下次使用。


## 14.内存是如何回收的？
应用程序用完内存后，可以调用 free() 释放内存，或调用 unmap() 取消内存映射，归还系统。

在内存紧张时，会通过一系列机制来回收内存，如以下三种方式：

- 回收缓存。主要是页缓存。
- 回收不常访问的页面。使用页面置换算法，把不常用的页面放到交换区中。
- 通过 OOM 杀死占用大量内存的进程，释放内存。

----------


# 进程管理
## 1.进程和线程的区别?

总的来说，进程是资源的容器，用来把资源集中到一起，而线程是在 CPU 上被实际调度的实体对象。

进程是资源分配的基本单位，进程中包括可执行的代码、打开的文件描述符、挂起的信号、进程的状态、内存地址空间、存放全局变量的数据段，以及一个或多个执行线程等。

线程是进程中活动的对象，或者说独立调度的基本单位。每个线程都拥有一个独立的程序计数器、线程堆栈和寄存器。

这里引申一个问题，有了进程为什么还要有线程？

- 在一个进程中会存在多种活动任务，如果只有一个调度来执行这些任务，那么当某个任务被阻塞时，其他任务将得不到执行，因此需要有多个独立调度的单元来使这些任务可以并行的执行，这些单元就是线程。
- 线程比进程更轻量，它们比进程更快的创建，也更容易撤销。线程间切换的开销也比进程小，由于进程拥有大量的资源，当切换到另一个进程的时候，需要保存当前进程的所有资源，而线程间的切换只需要保存当前堆栈和少了寄存器的内容。

<font color="#F100">当进程只有一个线程时，可以认为进程就等于线程</font>

值得一提的是，在 Linux 中，并不太区分进程和线程，线程只是一种特殊的进程，他们都被叫做任务，用 task_struct 结构体表示。它们的创建方式也大致相同，都是调用 fork() 函数，然后底层执行 clone() 方法创建，只不过，创建线程会在执行 clone() 的时候传递一些参数来指明需要共享的资源。

## 2.轻量级进程如何理解？
轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。

在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。


在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：

- 1 : 1，即一个 LWP 对应 一个用户线程；
- N : 1，即一个 LWP 对应多个用户线程；
- M : N，即多个 LWP 对应多个用户线程；


## 3.并发和并行
同一个 CPU 在同一时刻只能执行一个任务指令。

**并发**是指一段时间内可以同时运行多道程序，因为时间较短，所以看起来像多个程序在同时执行，实际上是 CPU 在多个程序间进行快速的切换。

**并行**是同一时刻可以运行多个程序，是真正意义上的并发。并行需要多处理器的支持。

## 4.线程的实现
主要有三种线程的实现方式：

1. 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
1. 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；
1. 轻量级进程（LightWeight Process）：在内核中来支持用户线程；



## 5.进程间通信有哪几种方式，都有什么特点？

<font color="#F100">每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</font>

- **管道**：通常用在父子进程间通信(管道传输数据是单向的)。管道分为「匿名管道」和「命名管道」;**匿名管道**只能用于存在父子关系的进程间通信；**命名管道**去除了父子进程间通信的机制，通常用来汇聚多个客户端进程与服务端进程的通信，先进先出。
- **消息队列**：独立于进程存在，进程间可以通过消息队列来传递数据(消息队列是保存在内核中的消息链表，每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程)，典型的模式是生产者-消费者模型。
- **信号**：一个进程可以给另一个进程发送信号来触发某些操作，比如挂起一个进程。Linux 通过 kill 命令来发送信号。(进程间通信机制中唯一的异步通信机制)；进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP；
- **信号量**：信号量是一个计数器，用来保护临界资源(实现进程间的互斥与同步)。进程可以读取信号量的值，并对它进行加减操作，多个进程可以通过信号量实现进程同步。
- **共享内存**：多个进程上不同的地址空间(虚拟地址)可以映射到同一块物理内存上，实现数据的共享，因为不涉及数据的拷贝，所以这是一种高效的通信方式。需要注意的是，多个进程并行时，需要通过同步机制保护共享内存的访问。
- **Socket 通信**：不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。


## 6.生产者消费者问题?

也叫做有界缓冲区问题，两个进程共享一个公共的固定大小的缓冲区，一个进程产生数据放到缓冲区中，另一个进程从缓冲区中取走信息。这里存在对计数变量的竞争条件，任何时刻，只能有一个生产者或消费者可以访问缓冲区。

缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。


> 如何使用信号量解决生产者消费者问题？
> 
> 信号量是一个整型变量，用来实现计数器功能，主要提供 down 和 up 操作（即 P 和 V 操作），这两个操作都是原子性的。当执行 down 操作使信号量值变为 0 时，会导致当前进程睡眠，而执行 up 操作 +1 时，会同时唤醒一个进程。
> 
> 当信号量取值 0 和 1 时，就是一个互斥信号量，当取值大于 1 时，就是一个计数信号量。



## 7.哲学家就餐问题？

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：进餐以及思考。当一个哲学家进餐时，需要先拿起自己左右两边的叉子，并且一次只能拿起一只叉子。

五个哲学家最多只能同时两个人进餐，因为只有 5 只叉子。如果五个哲学家同时拿起左边的叉子，那么都在等待邻居放下右边的叉子，导致谁都无法进餐，产生饥饿（也叫死锁）。

为了避免死锁，需要设置两个条件：

- 必须同时拿起左右两边叉子
- 只有在两个邻居都没有进餐的情况下才允许进餐

## 8.读者-写者问题？

读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

## 9.怎么避免死锁？
当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

死锁只有同时满足以下四个条件才会发生：

- 互斥条件（多个线程不能同时使用同一个资源）；
- 持有并等待条件（线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1）；
- 不可剥夺条件（当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取）；
- 环路等待条件（两个线程获取资源的顺序构成了环形链）；


**避免死锁问题就只需要破环其中一个条件就可以**，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。


## 10.锁的种类
加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：

- 互斥锁加锁失败后，线程会释放 CPU ，给其他线程（从用户态陷入到内核态）；
- 自旋锁加锁失败后，线程会忙等待，直到它拿到锁；



**互斥锁**：是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。

- **对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的**。当加锁失败时，内核会将线程置为「**睡眠**」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。


**自旋锁**：是通过 CPU 提供的 CAS 函数（Compare And Swap），在「**用户态**」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一直自旋，利用 CPU 周期，直到锁可用。

- 需要注意，**在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）**。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。


**读写锁**：由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。适用于能明确区分读操作和写操作的场景。写锁是独占锁，读锁是共享锁。

- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
- 但是，**一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞**，而且其他写线程的获取写锁的操作也会被阻塞。


<font color = "#F100">互斥锁、自旋锁、读写锁，都是属于悲观锁。</font>

**悲观锁**：认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以**访问共享资源前，先要上锁**。


**乐观锁（全程并没有加锁）**：假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。






## 11.进程上下文切换和线程上下文切换？

上下文切换指的是当前任务的资源（寄存器和程序计数器等）、状态等内容保存起来，然后加载新任务的资源和状态，跳转到新的程序计数器指定的指令继续执行。

**进程上下文切换不仅需要保存虚拟内存、全局变量、文件描述符等用户空间资源，还需要保存内核堆栈、寄存器、程序计数器等内核资源。**

线程的上下文切换的是什么？**当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据（线程栈）、寄存器等不共享的数据。**比进程切换开销小很多。


## 12.僵尸进程和孤儿进程的区别？
**僵尸进程**：一个子进程退出时会处于 ZOMBIE 状态，此时它占用的进程描述符没有被释放，只有等它的父进程调用 wait() 或 waitpid() 获取到子进程的信息后，最后由父进程决定是否将子进程资源释放。如果子进程的资源由于某种原因一直得不到释放，那么就一直处于僵死状态，变成了僵尸进程。

**孤儿进程**：当父进程退出了，但是它的子进程还没有退出，这些子进程就变成了孤儿进程。孤儿进程只是暂时的，系统会在父进程退出时启动寻父机制，为子进程找到一个新的父亲：首先在当前进程组中寻找，如果找不到就会返回 init (PID=1) 进程作为父进程。

系统中如果驻留大量的僵死进程是危险的，因为会一直占用系统资源，解决的直接办法就是杀死父进程，让他们变成孤儿进程，最后会被新的进程领养，新的父进程会例行调用 wait() 来检查子进程状态，清除相关的僵死进程。

## 13.进程有哪几种状态，他们是如何转换的？
进程主要有三种状态：运行态、就绪态、阻塞态。

运行态和就绪态可以相互转换，通常由系统的进程调度引起的。当一个处于运行态的进程遇到阻塞的代码，需要等待触发条件，或者没有足够的运行资源时，就会挂起当前进程，进入阻塞状态，而当满足了触发条件，或者系统资源又满足时，就是进入就绪状态，等待再次被调度。


## 14.进程和线程的创建方式？
进程的创建发生在这么几个场景中：

- 系统启动时，主要会初始化创建 3 个系统进程，一个 idle 空闲进程(PID=0)、一个 init 进程(PID=1)、一个页面守护进程(PID=2)
- 正在运行的进程执行系统调用创建一个子进程(Unix/Linux 中使用 fork)
- 用户请求创建一个新进程，如在 shell 中输入执行命令。
- 提交一个批处理请求，会创建一个新进程来运行

Linux 中进程的创建主要是通过 fork 系统调用，线程被当做一种特殊的进程，也是用 fork 创建，不过通过传递不同的参数，指明共享父进程的地址空间，打开的文件等资源。

其他系统如 Windows 创建进程执行的是 CreateProcess，而线程创建实现的 POSIX 标准接口，POSIX 定义的线程包叫 Pthread，其中定义了许多的系统调用，如 Pthread_create、Pthread_join、Pthread_exit 等

## 15.子进程创建时会拷贝父进程哪些资源？
Linux系统中，子进程的创建不会马上拷贝父进程的所有资源，而是以只读的方式共享大部分父进程的资源，当需要修改地址空间资源时，触发只读保护，这时才会拷贝一份地址空间。这种机制叫做 **写时拷贝(copy-on-write)**。这种优化可以避免拷贝大量根本不会使用到的数据。

fork 系统调用实际上只是为子进程创建一个唯一的进程描述符，分配了一个有效的 PID，有的 Linux 系统 fork 调用也会复制一份父进程的页面。

## 16.什么是系统调用？为什么要有系统调用？
系统调用是在一个进程中，由用户态切换到内核态，在内核中执行任务，或者申请操作系统的资源。系统调用是一种**保护操作系统的机制**，它提供一系列定义良好的 API 接口来和操作系统交互，避免用户程序直接对内核进行操作，保证了系统的稳定、安全、可靠。

## 17.内核态和用户态是什么？
多数 CPU 都有两种模式，即用户态和内核态，通常由**程序状态字(PSW) 寄存器**中的一个位来控制这两种模式的切换（通过 TRAP 指令实现切换）。这两种状态其实对应着应用程序访问资源的权限：在用户态只能访问受限的资源，如虚拟内存，全局变量等，而要访问内核等资源需要通过系统调用等方式陷入到内核中；内核态可以访问操作系统的所有资源，包括内存、I/O 等资源。

## 18.如何实现进程同步？
进程同步是指控制进程按照一定顺序执行。只有处于临界区（指访问共享内存的代码片段）的进程才需要同步。

进程同步通常有两种方式：

- 忙等待互斥：当某个变量不满足条件时，会一直轮询直到变量值发送改变。用于忙等待的锁称为自旋锁。自旋锁一般用于中断处理程序中（需要禁止本地中断），因为中断程序需要安全、快速的执行，不能被打断、也不能被睡眠。
- 信号量：是一个整型变量，用来实现计数器功能，主要提供 down 和 up 操作（即 P 和 V 操作），这两个操作都是原子性的。当执行 down 操作使信号量值变为 0 时，会导致当前进程睡眠，而执行 up 操作 +1 时，会同时唤醒一个进程。
- **管程**：管程是由一个过程、变量和数据结构组成的一个集合，把需要控制的那部分代码独立出来执行，它有一个重要的特性，同一时刻在管程中只能有一个活跃的进程。为了避免一个进程一直占用管程，引入了条件变量和 wait 和 signal 操作。当发生当前进程无法运行时，执行 wait 操作，将当前进程阻塞，同时调入在管程外等待的另一进程执行，而另一个进程满足条件变量时，会执行 signal 操作将正在睡眠的进程唤醒，然后马上退出管程。

[面试-操作系统篇：进程与线程](https://www.cnblogs.com/turbobin/p/14287553.html)

## 19.一个进程最多可以创建多少个线程？

进程最多可以创建多少个线程有关的因素：

- **进程的虚拟内存空间上限**，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。
- **系统参数限制**（系统支持的最大线程数、 PID 号数值的限制），虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。


 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。

64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。


## 20.线程奔溃了，进程也会奔溃吗？

正常情况下，操作系统为了保证系统安全，所以针对非法内存访问会发送一个 SIGSEGV 信号，而操作系统一般会调用默认的信号处理函数（一般会让相关的进程崩溃）。

1、如果线程是非法访问内存引起的崩溃，其**对应进程一定会崩溃**。

2、进程崩溃的本质是：操作系统对进程发出了信号，例如非法访问内存的信号是 SIGSEGV（序号 11）

3、想要防止进程奔溃，需要**自定义信号处理函数去拦截 SIGSEGV 信号**。参考 JVM 中线程崩溃但 JVM 进程不会崩溃


----------


# 调度算法

进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。
当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。

## 1.什么时候会发生 CPU 调度？
1. 当进程从运行状态转到等待状态；
1. 当进程从运行状态转到就绪状态；
1. 当进程从等待状态转到就绪状态；
1. 当进程从运行状态转到终止状态；

其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。

**非抢占式**的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

**抢占式调度**，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

<font color = "#F100">调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。</font>

## 2.进程间常见的调度算法
- **先来先服务调度算法**：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行；
- **最短作业优先调度算法**：优先选择运行时间最短的进程来运行；
- **高响应比优先调度算法**：权衡了短作业和长作业。每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：[（等待时间 + 要求服务时间）/ 要求服务时间 ]；
- **时间片轮转调度算法**：让所有的进程同等重要，每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行，通常时间片设为 20ms~50ms折中值；
- **最高优先级调度算法**：从就绪队列中选择最高优先级的进程进行运行；

	- **静态优先级**：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
	- **动态优先级**：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。
- **多级反馈队列调度算法**：「时间片轮转算法」和「最高优先级算法」的综合和发展；
	- 「多级」表示有多个队列，每个队列优先级从高到低，同时*优先级越高时间片越短*。
	- 「反馈」表示如果有*新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列*； 
	-  新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
	-  当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

## 3.内存页面置换算法
功能：当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面；

**设计目标：**

1. 尽可能减少页面的调入调出次数；
2. 把未来不再访问或短期内不访问的页面调出。

**页表项通常有如下字段：**
【页号】【物理页号】【状态位】【访问字段】【修改位】【硬盘地址】

- 状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
- 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
- 修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
- 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。


常见的页面置换算法有如下几种：

- **最佳页面置换算法（OPT）**：置换在「未来」最长时间不访问的页面；
- **先进先出置换算法（FIFO）**：选择在内存驻留时间很长的页面进行中置换；
- **最近最久未使用的置换算法（LRU）**：选择最长时间没有被访问的页面进行置换；
- **时钟页面置换算法（Lock）**：把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面；当发生缺页中断时，算法首先检查表针指向的页面：
	- 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
	- 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；
- **最不常用置换算法（LFU）**：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。


## 4.磁盘调度算法
**目的**：为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。**寻道**的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。

- 先来先服务算法：先来的请求先被服务，即按照序列顺序移动；
- 最短寻道时间算法：优先选择从当前磁头位置所需寻道时间最短的请求；
- 扫描算法（电梯算法）：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向重复上面过程；
- 循环扫描算法：在扫描算法的基础上，磁头只响应一个方向的请求，返回时直接快速复位磁头（这个过程不处理任何请求），再重新往那个方向移动；
- LOOK：对扫描算法的优化，磁头移动到最远的请求位置就开始反向移动（原本是到达最后的磁道位置）；
- C-LOOK：对循环扫描算法的优化，磁头移动到最远的请求位置就开始反向移动（原本是到达最后的磁道位置）；


----------


# 文件系统

## 1. 文件系统和磁盘有什么关系？
磁盘属于硬件，是一种为系统提供了基本的持久化存储的设备。

文件系统属于操作系统的功能，以磁盘为载体，提供了一个用来管理文件的树状结构。
##2. 文件系统有哪些结构？
文件系统主要由索引节点、目录项、超级块、逻辑块组成。

- **索引节点**：记录了文件的元信息，包括文件权限、文件大小、创建时间、数据的索引位置等等。索引节点是文件的唯一标识，和文件一一对应，它和文件内容一样会持久化到磁盘中保存。
- **目录项**：用来记录文件的名字、索引节点的指针以及与其他目录项的关联关系。多个关联的目录项组成了文件系统的目录结构。目录项对象不会存储到磁盘中，而是被缓存起来，便于快速的解析目录。
- **超级块**：存储了整个文件系统的状态，如索引节点、逻辑块的使用情况。
- **逻辑块**：文件系统用来存储数据的最小单位，大小为 4 KB，一般由 8 个连续的扇区组成（磁盘读写的最小单位是扇区，大小为 512B），多个逻辑块组成了文件系统的数据块区。

##3. 什么是虚拟文件系统，有什么作用？
虚拟文件系统（VFS）是操作系统在用户层与文件系统之间引入的一个抽象层，屏蔽了不同文件系统之间的差异，定义了一组标准的系统调用接口，为用户提供了统一访问文件的方式。

**VFS 定义了一组所有文件都支持的数据结构和标准接口**，这样，用户和其他内核子系统只需要跟 VFS 提供的统一接口交互就可以了，而不需要关心底层各种文件系统的实现细节。

##4. 同步IO和异步IO，阻塞和非阻塞IO有什么区别？
两种是不同角度的 I/O 划分方式。

根据是否等待系统的 I/O 请求响应，可以分为**同步 I/O** 和**异步 I/O**，关注对象是I/O 的执行者(系统)，比如系统调用 read 是同步读，在没有得到磁盘数据前不会响应应用程序，而 aio_read 是异步读，系统收到 I/O 请求后不等待处理就立即返回了，而读取的结果通过回调的方式异步通知给应用程序。

根据应用程序是否阻塞自身运行，可以分为**阻塞 I/O** 和 **非阻塞 I/O**，针对的 I/O 的调用者(应用程序)。比如在套接字接口中，使用 send 向套接字接口发送数据时，如果套接字没有设置 O_NOBLOCK 标识，那么 send 操作会一直阻塞，而如果使用了 epoll，系统会告诉套接字的状态，就可以使用非阻塞的方式读写套接字。

##5. 什么是DMA技术？
一种内存访问技术。DMA（Direct Memory Access，直接存储器访问）**可以在不需要 CPU 参与的情况下实现内存的读取或写入**，因为不依赖 CPU 的大量中断负载，因而可以实现数据的快速传送，提高系统的并发性能。

DMA 的传输过程必须经过 DMA 请求，DMA 响应，DMA 传输，DMA 结束 4 个步骤：

1. **DMA 请求**：CPU 对 DMA 芯片进行设置，说明需要传送的字节数，有关的设备和内存地址，然后启动 DMA；
1. **DMA 响应**：DMA 向 CPU 请求总线控制权，CPU 处理完当前总线数据后就让出总线；
1. **DMA 传输**：DMA 控制器直接控制内存与 I/O 接口进行数据传输；
1. **DMA 结束**：DMA 传输结束后，把总线控制权交还给 CPU，并向 I/O 接口发送结束信号。

##6. 什么是零拷贝技术？
零拷贝指计算机不需要先将数据从一个内存区域复制到另外一个内存区域，从而减少系统调用切换、减少拷贝次数，从而减少 CPU 的执行时间和负载。

实现零拷贝主要用到的是 DMA 数据传输技术和内存映射技术。

 传统的 I/O 方式需要经过四次拷贝才能把磁盘上的数据输出到网络端口：

1. 执行 read 系统调用，从用户态切换到内核态，CPU 向 DMA 控制器芯片下发指令，将磁盘数据通过直接内存访问的方式拷贝到内核缓冲区中；
1. CPU 接收到 DMA 结束拷贝的信号，将内核缓冲区的数据拷贝到用户缓冲区中，read 调用结束，返回到用户态；
1. 用户程序执行 write 系统调用，从用户态切换到内核态，CPU 将数据从用户缓冲区中拷贝到Socket 发送缓冲区中；
1. CPU 下发指令，让 DMA 控制器来处理数据，将 Socket 发送缓冲区的数据拷贝到网卡进行网络传输，write 调用结束。

**零拷贝有几种实现方式**，如下：

1. `mmap + write`：mmap 是一个系统调用，主要作用就是将用户缓冲区与内核中的读缓冲区进行映射，映射后这一步就不需要进行数据拷贝了，而 write 操作实际上是从内核读缓冲区中把数据拷贝到 Socket 发送缓冲区，整个过程减少了一次拷贝操作，但是系统调用切换没有减少(4 次)。
> - 应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
> - 应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
> - 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

2. `sendfile`：sendfile 同样省去了将数据在内核和用户空间中拷贝，与 mmap 不同的是，sendfile 不需要借助 write 调用，而是一次完整的内核拷贝过程，减少了两次 CPU 上下文切换(2 次上下文切换，和 3 次数据拷贝)。
> - 可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销

3. `sendfile + DMA gather copy`：对 sendfile 系统调用做了修改，引入了 gather 操作，不需要将内核缓冲区的数据拷贝到 Socket 中，而是将它对于的数据描述信息（内存地址、文件描述符，文件长度等）记录到 Socket 缓冲区中，最后由 DMA 根据这些文件描述信息从内核读缓冲区中找到数据，直接拷贝到网卡设备中。

4. `splice`：splice 系统调用可以在内核空间的读缓冲区和网络缓冲区之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。

>  - mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间;
>  - read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里


##7. 磁盘的分类，都有什么特点？

- **机械磁盘**：也叫磁盘驱动器（HDD），带有旋转臂和磁头，由电机驱动带动盘片旋转，顺序读取的速度较快，随机读取较慢，因为要经常旋转磁头进行磁道寻址。最小读写单位是扇区，一般是 512 字节大小
- **固态硬盘**：SSD，控制闪存颗粒进行数据的读写，属于完全的电子操作。最小操作单位是页，通常是 4KB。

##8. IO调度算法有哪几种？

- NOOP：电梯调度，最简单一种调度算法，维护一个先进先出的队列，只做一些基本的请求合并，常用于 SSD。
- CFS：完全公平的调度器，一般是默认的调度算法，类似于进程调度，为每个 I/O 进程维护一个队列，并按照时间片均匀分布每个进程的 I/O 请求。适合运行大量进程的场景。
- DeadLine：截止时间请求调度，分别为每个读写请求都维护一个调度队列，以提高磁盘的吞吐量，并确保达到最终极限的请求得到优先处理。适用于 I/O 比较重的场景，如数据库。

## 9.在文件系统中，什么是硬链接和软链接？它们之间有什么区别？
在文件系统中，硬链接（Hard Link）和软链接（Symbolic Link，也称为符号链接或软连接）是两种链接文件的方式。

**硬链接** 是文件系统中一个文件对应多个目录项的链接关系。它们具有相同的 inode（索引节点）和数据块，它们在文件系统中的位置是完全相同的。因此，对于系统来说，硬链接文件与原始文件没有区别，可以独立地访问和操作。

 **软链接**是一个特殊的文件，它包含了指向目标文件的路径。软链接文件与原始文件有不同的 inode 和数据块，它只是一个指向目标文件的快捷方式。当访问软链接时，操作系统会根据软链接中的路径找到目标文件。

主要区别如下：

1. 硬链接不可跨越文件系统，而软链接可以跨越文件系统。
1. 硬链接不能链接目录，而软链接可以链接目录。
1. 硬链接不受目标文件删除的影响，只有所有的硬链接都被删除后，文件的空间才会被释放。软链接则只是指向目标文件的路径，如果目标文件被删除，软链接将成为一个无效的链接。
1. 修改硬链接文件会影响所有链接到该文件的硬链接，而修改软链接文件不会影响目标文件或其他软链接文件。

<font color="#F100">硬链接是多个文件共享相同的数据和 inode，而软链接是指向目标文件的路径。硬链接是一个文件的多个入口，而软链接是一个文件的快捷方式。</font>


## 10.请解释文件系统的目录结构和文件控制块?
**目录结构**是文件系统中用于组织和管理文件和目录的一种层次化结构。它提供了一种逻辑视图，使用户可以方便地查找、访问和管理文件。

- 目录结构通常采用树形结构，其中包含了文件和子目录。常见的目录结构类型有单级目录、层次目录、索引节点和哈希表等。


 **文件控制块（File Control Block，FCB）**是文件系统中用于存储文件相关信息的数据结构。每个文件都对应一个文件控制块，它存储了文件的元数据，包括文件名、大小、创建时间、修改时间、访问权限等。

通过目录结构和文件控制块，文件系统可以组织和管理大量的文件和目录，提供了用户友好的文件访问和管理接口，方便用户进行文件的读取、写入、删除和查找等操作。同时，文件控制块中的元数据信息也能够提供文件的属性和状态，以便进行权限控制、时间管理和数据完整性保护等功能。

## 11.请解释文件系统的索引结构和如何实现文件块分配？
**文件系统的索引结构**是一种用于快速定位和访问文件数据的数据结构。它通过维护一个索引表或索引节点（inode）来映射文件名与文件数据的关系。索引结构的设计旨在提高文件系统的性能和效率。

 常见的索引结构有以下几种：

- **单级目录结构**：文件系统维护一个全局的目录表，其中每个条目包含文件名和对应的数据块号。这种结构简单，但对于文件数量较大的情况效率较低。
- **多级目录结构**：文件系统将目录分为多级，通过嵌套的目录层次结构来组织文件。这样可以提高查找效率，但也增加了目录的管理复杂性。
- **哈希表结构**：使用哈希函数将文件名映射为数据块号，以快速查找文件数据。哈希表结构适用于大规模文件系统，可以在O(1)时间内找到文件数据。
- **B树和B+树结构**：这些树状结构适用于大型文件系统，能够高效地管理大量的文件和目录。B树和B+树结构具有平衡性和高度优化的查找性能。

**文件块分配是指在文件系统中为文件分配存储空间的过程**。常见的文件块分配方式有以下几种：

1. **连续分配**：将文件存储空间作为一块连续的物理空间分配给文件。这种方式简单高效，但容易产生外部碎片。
1. **链接分配**：使用链表将文件的数据块链接起来。每个数据块包含指向下一个数据块的指针。这种方式灵活，但需要额外的指针开销。
1. **索引分配**：为每个文件维护一个索引表，索引表中的条目指向实际存储数据的块。这种方式适用于大文件和随机访问，但需要更多的空间来存储索引表。
1. **混合分配**：将连续分配和链接分配结合使用，根据文件大小和访问模式选择合适的分配方式。例如，对于小文件使用链接分配，对于大文件使用索引分配。

实现文件块分配需要考虑空闲空间的管理、分配策略、碎片整理等因素。文件系统会维护一个空闲块列表或位图来跟踪可用的存储空间，并根据不同的分配策略选择合适的块进行分配。为了避免碎片问题，文件系统可能会进行碎片整理操作，将零散的空闲块整理成连续的空间，以提高存储利用率和访问效率。


## 12.如何保护文件系统的安全性和防止文件丢失？
保护文件系统的安全性和防止文件丢失是文件系统设计中非常重要的考虑因素。以下是几个关键的方面：

1. **访问控制和权限管理**：文件系统应提供访问控制机制，确保只有经过授权的用户能够访问文件和目录。这包括使用权限位（如读、写、执行权限）、用户身份验证和访问控制列表（ACL）等方式来管理和限制对文件的访问。
1. **加密和身份验证**：对于敏感数据和文件，可以使用加密算法来保护数据的机密性。此外，身份验证机制如用户名和密码、公钥加密等可以防止未经授权的用户访问文件系统。
1. **备份和恢复策略**：定期备份文件系统中的重要数据是防止文件丢失的关键措施。备份可以包括完整备份和增量备份，以确保文件系统的数据可以在故障或灾难发生时恢复。
1. **冗余和容错机制**：通过实现冗余存储和容错机制，如RAID（磁盘冗余阵列）等技术，可以增加文件系统的可靠性和容错能力。这样可以防止由于硬件故障而导致的数据丢失。
1. **定期维护和监控**：定期进行文件系统的维护工作，包括磁盘清理、碎片整理、错误修复等，以保持文件系统的健康状态。同时，监控文件系统的运行状态，及时发现和处理异常情况，可以防止进一步的数据损失。


# 设备管理

## 1.键盘敲入字母时，期间发生了什么？

CPU 里面的**内存接口，直接和系统总线通信**，然后系统总线再接入一个 I/O 桥接器，这个 I/O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I/O 总线，用来连接 I/O 设备，比如键盘、显示器等。

1. 当用户输入了键盘字符，键盘控制器就会产生扫描码数据，并**将其缓冲在键盘控制器的寄存器**中，紧接着键盘控制器**通过总线给 CPU 发送中断请求**。
2. CPU 收到中断请求后，操作系统会**保存被中断进程的 CPU 上下文，然后调用键盘的中断处理程序**。
3. 键盘的中断处理程序是在键盘驱动程序**初始化时注册的**，那键盘中断处理函数的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。
4. 得到了显示字符的 ASCII 码后，就会**把 ASCII 码放到「读缓冲区队列」**，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会**定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区**，最后将这些数据显示在屏幕里。


## 2.设备控制器（Device Control）
为了屏蔽设备之间的差异

设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信。

控制器是有三类寄存器，它们分别是状态寄存器（Status Register）、 命令寄存器（Command Register）以及数据寄存器（Data Register）：

1. **数据寄存器**，CPU 向 I/O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I/O 设备。
1. **命令寄存器**，CPU 发送一个命令，告诉 I/O 设备，要进行输入/输出操作，于是就会交给 I/O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。
1. **状态寄存器**，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。


## 3.通用块层

通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：

- 第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；
- 第二功能，通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。


## 4.存储系统 I/O 软件分层

可以把 Linux 存储系统的 I/O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。

- **文件系统层**，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。
- **通用块层**，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。
- **设备层**，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。

# 网络系统

## 1.PageCache 有什么作用？
文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是**磁盘高速缓存（PageCache）**。

PageCache 的优点主要是两个：

1. 缓存最近被访问的数据；
1. 预读功能；

<font color="#F100">但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能。</font>

1. PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；
1. PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；


## 2.大文件传输用什么方式实现？
绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。

在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。

>- 传输大文件的时候，使用「异步 I/O + 直接 I/O」；
> - 传输小文件的时候，则使用「零拷贝技术」；
> -  Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能


## 3.服务端给 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？
- **绑定端口的目的**：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。
- 绑定 **IP** 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；

## 4.文件描述符的作用是什么？
每一个进程都有一个数据结构 task_struct，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。

数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说**内核可以通过文件描述符找到对应打开的文件**。


## 5.服务器接数，主要会受两个方面的限制
1. **文件描述符**，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；
1. **系统内存**，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；

## 6.多进程模型与多线程模型
多进程模型：

- 服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。
- 这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。
- 子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了，

<font color = "#F100">子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。</font>

多线程模型：

当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。


## 7.I/O 复用
**Select**

select 实现多路复用的方式是，**将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生**，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket **标记为可读或可写**， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。

>  对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

**poll**

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。

poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用**动态数组**，以链表形式来组织，突破了 select 的文件描述符个数限制，当然**还会受到系统文件描述符限制**。

<font color="#F100">都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</font>

**Epoll**

 epoll 在内核里使用**红黑树**来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)

 epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数。

epoll 支持两种事件触发模式，分别是**边缘触发（edge-triggered，ET）**和**水平触发（level-triggered，LT）**。

1. 用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
1. 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒**，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；


## 8.高性能网络模式：Reactor 和 Proactor

第一种方案**单 Reactor 单进程 / 线程**，不用考虑进程间通信以及数据同步的问题，因此实现起来比较简单，这种方案的缺陷在于无*法充分利用多核 CPU，而且处理业务逻辑的时间不能太长，否则会延迟响应，所以不适用于计算机密集型的场景*，适用于业务处理快速的场景，比如 Redis（6.0之前 ） 采用的是单 Reactor 单进程的方案。

第二种方案**单 Reactor 多线程**，通过多线程的方式解决了方案一的缺陷，但它离高并发还差一点距离，差在*只有一个 Reactor 对象来承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方*。

第三种方案**多 Reactor 多进程 / 线程**，通过多个 Reactor 来解决了方案二的缺陷，主 Reactor 只负责监听事件，响应事件的工作交给了从 Reactor，Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案，Nginx 则采用了类似于 「多 Reactor 多进程」的方案。


## 9.什么是一致性哈希？
一致性哈希是一种哈希算法，就是在移除或者增加一个结点时，能够尽可能小的改变已存在 key 的映射关系。

一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。


- 当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。
- 添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。
- 更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。



为了**解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本**。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。


# Linux 命令

## 1.性能指标有哪些？
衡量网络的性能，分别是带宽、延时、吞吐率、PPS（Packet Per Second），它们表示的意义如下：

- **带宽**，表示链路的最大传输速率，单位是 b/s （比特 / 秒），带宽越大，其传输能力就越强。
- **延时**，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。
- **吞吐率**，表示单位时间内成功传输的数据量，单位是 b/s（比特 / 秒）或者 B/s（字节 / 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。
- **PPS**，全称是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。

除了以上这四种基本的指标，还有一些其他常用的性能指标，比如：

- **网络的可用性**，表示网络能否正常通信；
- **并发连接数**，表示 TCP 连接数量；
- **丢包率**，表示所丢失数据包数量占所发送数据组的比率；
- **重传率**，表示重传网络包的比例；