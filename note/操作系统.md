# 硬件结构
## 1.冯诺依曼模型
运算器、控制器、存储器、输入设备、输出设备

运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。

存储单元和输入输出设备要与中央处理器打交道离不开总线。

**内存**：存储的区域是线性的，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1。

**中央处理器**：CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据（32位4字节，64位8字节）。

**常见的寄存器种类：**

- **通用寄存器**，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
- **程序计数器**，用来存储 CPU 要执行下一条指令「所在的**内存地址**」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。
- **指令寄存器**，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。

**总线**：用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：

- **地址总线**，用于指定 CPU 将要操作的内存地址；
- **数据总线**，用于读写内存的数据；
- **控制总线**，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；

## 2.程序执行的基本过程
一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。

CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的**指令周期**。

CPU 执行程序的过程如下：

- 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。
- 第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；
- 第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；


> 数据和指令是分开区域存放的，存数据的是「数据段」，存放指令区域的地方称为「正文段」。

> 指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容；不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码。


## 3.CPU 指令周期的四个阶段？
大多数 CPU 都使用来流水线的方式来执行指令，所谓的流水线就是把一个任务拆分成多个小任务，于是一条指令通常分为 4 个阶段：

1. CPU 通过程序计数器读取（控制器）对应内存地址（存储器）的指令，这个部分称为 Fetch（取得指令）；
1. CPU 对指令进行解码（控制器），这个部分称为 Decode（指令译码）；
1. CPU 执行指令（运算器、控制器），这个部分称为 Execution（执行指令）；
1. CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 Store（数据回写）；


## 4.指令的类型与执行速度
指令从功能角度划分，可以分为 5 大类：

1. **数据传输**类型的指令，比如 store/load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令；
1. **运算**类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据；
1. **跳转**类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、switch-case、函数调用等。
1. **信号**类型的指令，比如发生中断的指令 trap；
1. **闲置**类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；

对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。
>  1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。

<font color = "#F100">程序的 CPU 执行时间 = CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积 </font>

<font color = "#F100"> CPU 时钟周期数 = 指令数 与 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）的乘积</font>

因此，<font color="#F8A">**程序的 CPU 执行时间 = 指令数 * CPI *  时钟周期时间** </font>

- 指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。
- 每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少;
- 时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。

## 5.磁盘与内存
- **寄存器**：每个寄存器可以用来存储一定的字节（byte）的数据。32 位 CPU 中大多数寄存器可以存储 4 个字节，64位可以存储 8 个字节。
- **CPU Cache**：用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。一旦**断电，数据就会丢失**了。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成 **指令缓存** 和 **数据缓存** 。L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。
- **内存**：使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。需要「**定时刷新**」，才能保证数据不会被丢失。
- **SSD/HDD 硬盘**：SSD（Solid-state disk） 固体硬盘与 HDD（Hard Disk Drive）机械硬盘。

**每个存储器只和相邻的一层存储器设备打交道**，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量。

另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。

## 6.CPU Cache 的数据结构和读取过程是什么样的？
CPU Cache 是由很多个Cache Line（缓存块）组成的，Cache Line 是 CPU 从内存读取数据的基本单位，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。

CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，具体这一小块数据的大小，取决于 `coherency_line_size` 的值，一般 64 字节。在内存中，这一块的数据我们称为**内存块（Block）**，读取的时候我们要拿到数据所在内存块的地址。

对于直接映射 Cache 采用的策略，就是**把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址**，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。

为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个**组标记**（Tag）。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。
> 除了**组标记**信息外，CPU Cache Line 还有两个信息：

>- 一个是，从内存加载过来的**实际存放数据（Data）**。
>- 另一个是，**有效位（Valid bit）**，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。

CPU 在从 CPU Cache 读取数据的时候，**并不是读取 CPU Cache Line 中的整个数据块**，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个**字（Word）**。

<font color="#F100">一个内存的访问地址，包括**组标记**、**CPU Cache Line 索引**、**偏移量**这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由**索引 + 有效位 + 组标记 + 数据块**组成。</font>

如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：

1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
1. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
1. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
1. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。


## 7.CPU Cache 的数据写入
**写直达**：把数据同时写入内存和 Cache 中。

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

**写回**：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中。

- 如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表**这个时候CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的**，这种情况是不用把数据写到内存里的；
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的：


-  1.如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；
-  2.如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。

<font color="#F100">在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</font>


## 8.CPU缓存的一致性
想实现缓存一致性，关键是要满足 2 点：

- 第一点是**写传播**，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是**事物的串行化**，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是**已修改、独占、共享、已失效**这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

[MESI 协议可视化](https://www.scss.tcd.ie/Jeremy.Jones/vivio/caches/MESI.htm)


## 9.CPU 是如何执行任务的？
CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作

如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。

因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为**伪共享（False Sharing）**

对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。

系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。（priority(new) = priority(old) + nice）

## 10.什么是软中断？
**中断**是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断是一种异步的事件处理机制，可以提高系统的并发处理能力。

中断请求的响应程序，也就是中断处理程序，要**尽可能快的执行完**，这样可以减少对正常进程运行调度地影响。

Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」

- 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。
中断处理程序的上部分和下半部可以理解为：

上半部直接处理硬件请求，也就是**硬中断**，主要是负责耗时短的工作，特点是快速执行；

下半部是由内核触发，也就说**软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

## 11.计算机是怎么存小数的？
计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：

- **符号位**：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；
- **指数位**：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；
- **尾数位**：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；


# 操作系统结构

## 1.



##1.共享内存使用时无访问控制——不会堵塞等待
我们把共享内存实际上是映射到了我们进程地址空间的用户空间了(堆和栈之间)。对每一个进程而言，挂接到自己的上下文中的共享内存，属于自己的空间，类似于堆空间或者栈空间，可以被用户直接使用，不需要调用系统接口。
共享内存，因为他自身的特性，它没有任何访问控制，共享内存被双方直接看到，属于双方的用户空间，可以直接通信，但是不安全!

## 2.共享内存是所有进程间通信速度最快的——解释
管道：父进程把外设的数据写入(拷贝)到自己进程的上下文代码中，再把自己进程上下文代码write写入(拷贝)进管道文件中，子进程管道文件中的数据read读入(拷贝)进子进程上下文代码中，再把子进程上下文代码刷(拷贝)到外设上，要进行4次拷贝。
而共享内存：进程1把外设的数据写入(拷贝)共享内存时，进程2就能立马看到，并使用共享内存的数据，如果不刷到外设上，只需1次拷贝即可，所以共享内存最快。

## 3.管道和共享内存的区别
- 管道需要在内核和用户空间进行四次的数据拷贝：由用户空间的buf中将数据拷贝到内核中 -> 内核将数据拷贝到内存中 -> 内存到内核 -> 内核到用户空间的buf；而共享内存则只拷贝两次数据：用户空间到内存 -> 内存到用户空间。
- 管道用循环队列实现，连续传送数据可以不限大小。共享内存每次传递数据大小是固定的;
- 共享内存可以随机访问被映射文件的任意位置，管道只能顺序读写；
- 管道可以独立完成数据的传递和通知机制，共享内存需要借助其他通讯方式进行消息传递；
- **两者之间最大的区别**： 共享内存区是最快的可用IPC形式，一旦这样的内存区映射到共享它的进程的地址空间，这些进程间数据的传递，就不再通过执行任何进入内核的系统调用来传递彼此的数据，节省了时间。




