# 硬件结构
## 1.冯诺依曼模型
运算器、控制器、存储器、输入设备、输出设备

运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。

存储单元和输入输出设备要与中央处理器打交道离不开总线。

**内存**：存储的区域是线性的，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1。

**中央处理器**：CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据（32位4字节，64位8字节）。

**常见的寄存器种类：**

- **通用寄存器**，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
- **程序计数器**，用来存储 CPU 要执行下一条指令「所在的**内存地址**」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。
- **指令寄存器**，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。

**总线**：用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：

- **地址总线**，用于指定 CPU 将要操作的内存地址；
- **数据总线**，用于读写内存的数据；
- **控制总线**，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；

## 2.程序执行的基本过程
一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。

CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的**指令周期**。

CPU 执行程序的过程如下：

- 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。
- 第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；
- 第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；


> 数据和指令是分开区域存放的，存数据的是「数据段」，存放指令区域的地方称为「正文段」。

> 指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容；不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码。


## 3.CPU 指令周期的四个阶段？
大多数 CPU 都使用来流水线的方式来执行指令，所谓的流水线就是把一个任务拆分成多个小任务，于是一条指令通常分为 4 个阶段：

1. CPU 通过程序计数器读取（控制器）对应内存地址（存储器）的指令，这个部分称为 Fetch（取得指令）；
1. CPU 对指令进行解码（控制器），这个部分称为 Decode（指令译码）；
1. CPU 执行指令（运算器、控制器），这个部分称为 Execution（执行指令）；
1. CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 Store（数据回写）；


## 4.指令的类型与执行速度
指令从功能角度划分，可以分为 5 大类：

1. **数据传输**类型的指令，比如 store/load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令；
1. **运算**类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据；
1. **跳转**类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、switch-case、函数调用等。
1. **信号**类型的指令，比如发生中断的指令 trap；
1. **闲置**类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；

对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。
>  1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。

<font color = "#F100">程序的 CPU 执行时间 = CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积 </font>

<font color = "#F100"> CPU 时钟周期数 = 指令数 与 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）的乘积</font>

因此，<font color="#F8A">**程序的 CPU 执行时间 = 指令数 * CPI *  时钟周期时间** </font>

- 指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。
- 每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少;
- 时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。

## 5.磁盘与内存
- **寄存器**：每个寄存器可以用来存储一定的字节（byte）的数据。32 位 CPU 中大多数寄存器可以存储 4 个字节，64位可以存储 8 个字节。
- **CPU Cache**：用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。一旦**断电，数据就会丢失**了。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成 **指令缓存** 和 **数据缓存** 。L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。
- **内存**：使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。需要「**定时刷新**」，才能保证数据不会被丢失。
- **SSD/HDD 硬盘**：SSD（Solid-state disk） 固体硬盘与 HDD（Hard Disk Drive）机械硬盘。

**每个存储器只和相邻的一层存储器设备打交道**，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量。

另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。

## 6.CPU Cache 的数据结构和读取过程是什么样的？
CPU Cache 是由很多个Cache Line（缓存块）组成的，Cache Line 是 CPU 从内存读取数据的基本单位，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。

CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，具体这一小块数据的大小，取决于 `coherency_line_size` 的值，一般 64 字节。在内存中，这一块的数据我们称为**内存块（Block）**，读取的时候我们要拿到数据所在内存块的地址。

对于直接映射 Cache 采用的策略，就是**把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址**，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。

为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个**组标记**（Tag）。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。
> 除了**组标记**信息外，CPU Cache Line 还有两个信息：

>- 一个是，从内存加载过来的**实际存放数据（Data）**。
>- 另一个是，**有效位（Valid bit）**，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。

CPU 在从 CPU Cache 读取数据的时候，**并不是读取 CPU Cache Line 中的整个数据块**，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个**字（Word）**。

<font color="#F100">一个内存的访问地址，包括**组标记**、**CPU Cache Line 索引**、**偏移量**这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由**索引 + 有效位 + 组标记 + 数据块**组成。</font>

如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：

1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
1. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
1. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
1. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。


## 7.CPU Cache 的数据写入
**写直达**：把数据同时写入内存和 Cache 中。

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

**写回**：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中。

- 如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表**这个时候CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的**，这种情况是不用把数据写到内存里的；
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的：


-  1.如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；
-  2.如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。

<font color="#F100">在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</font>


## 8.CPU缓存的一致性
想实现缓存一致性，关键是要满足 2 点：

- 第一点是**写传播**，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是**事物的串行化**，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是**已修改、独占、共享、已失效**这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

[MESI 协议可视化](https://www.scss.tcd.ie/Jeremy.Jones/vivio/caches/MESI.htm)


## 9.CPU 是如何执行任务的？
CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作

如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。

因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为**伪共享（False Sharing）**

对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。

系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。（priority(new) = priority(old) + nice）

## 10.什么是软中断？
**中断**是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断是一种异步的事件处理机制，可以提高系统的并发处理能力。

中断请求的响应程序，也就是中断处理程序，要**尽可能快的执行完**，这样可以减少对正常进程运行调度地影响。

Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」

- 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。
中断处理程序的上部分和下半部可以理解为：

上半部直接处理硬件请求，也就是**硬中断**，主要是负责耗时短的工作，特点是快速执行；

下半部是由内核触发，也就说**软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

## 11.计算机是怎么存小数的？
计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：

- **符号位**：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；
- **指数位**：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；
- **尾数位**：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；

## 12.Linux中按下电源到展现命令行的过程是怎样的？
步骤1 - 当我们启动电源时，BIOS（基本输入/输出系统）或UEFI（统一可扩展固件接口）固件从非易失性存储器加载，并执行POST（上电自检）。

步骤2 - BIOS/UEFI检测连接到系统的设备，包括CPU、RAM和存储。

步骤3 - 选择一个启动设备以从中引导操作系统。这可以是硬盘、网络服务器或光盘驱动器。

步骤4 - BIOS/UEFI运行引导加载程序（GRUB），该加载程序提供一个菜单，用于选择操作系统或内核功能。

步骤5 - 内核准备好后，我们现在切换到用户空间。内核启动systemd作为第一个用户空间进程，它管理进程和服务，探测所有剩余的硬件，挂载文件系统，并运行桌面环境。

步骤6 - systemd默认在系统引导时激活默认的.target单元。其他分析单元也会被执行。

步骤7 - 系统运行一系列启动脚本并配置环境。

步骤8 - 用户被呈现出登录窗口。系统现在已经准备就绪。

[https://zhuanlan.zhihu.com/p/670742766](https://zhuanlan.zhihu.com/p/670742766)

----------


# 操作系统结构

## 1.Linux 内核
内核一般会提供 4 个基本能力：

1. 管理进程、线程，决定哪个进程、线程使用 CPU，也就是**进程调度**的能力；
1. 管理内存，决定内存的分配和回收，也就是**内存管理**的能力；
1. 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是**硬件通信**能力；
1. 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是**用户程序与操作系统之间的接口**。


## 2.Linux 内核设计的理念

1. MultiTask，多任务（并发或并行）
1. SMP，对称多处理（ CPU 地位相等）
1. ELF，可执行文件链接格式（Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE）
1. Monolithic Kernel，宏内核（内核是一个完整的可执行程序，且拥有最高的权限）


内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。

## 3.内核的架构种类
1. 宏内核，包含多个模块，整个内核像一个完整的程序；
1. 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；
1. 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；

Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。华为的鸿蒙操作系统的内核架构是微内核。


----------


# 内存管理

## 1.虚拟内存有什么作用？
- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
> **局部性原理**是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。

## 2.操作系统是如何管理虚拟地址与物理地址之间的关系？
主要有两种方式，分别是内存分段和内存分页；

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用**分段**（Segmentation）的形式把这些段分离出来。

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。
> 段选择因子和段内偏移量：
> 
>-  段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。
>- 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

分段（根据实际需求分配内存）解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

- 第一个就是内存碎片（外部内存碎片）的问题。
- 第二个就是内存交换的效率低的问题。

<font color="#F1000">分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。</font>

**分页**是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。

虚拟地址与物理地址之间通过页表来映射。页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。

<font color="#F1000">当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</font>

分页机制分配内存的最小单位是一页，即使程序不足一页大小，最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有**内部内存碎片**的现象。

在分页机制下，**虚拟地址分为两部分，页号和页内偏移**。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址

**段页式内存管理** 的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

地址结构就由**段号**、**段内页号**和**页内位移**三部分组成。


> Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。


## 3.Linux 的虚拟地址空间是如何分布的？
虚拟地址空间的内部又被分为**内核空间**和**用户空间**两部分，不同位数的系统，地址空间的范围也不同。

虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实**关联的都是相同的物理内存**。

用户空间内存，从低到高分别是 6 种不同的内存段：

- 代码段，包括二进制可执行代码；
- 数据段，包括已初始化的静态常量和全局变量；
- BSS(Block Started by Symbol) 段（Unix链接器产生的未初始化数据段），包括未初始化的静态变量和全局变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；


## 4.malloc 是如何分配内存的？
malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 brk() 系统调用从堆分配内存（通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间）
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存（私有匿名映射）；

> brk() 函数是一个系统调用，用于改变进程的结束地址（end of data segment），从而控制进程使用的堆内存大小。当应用程序需要分配更多的内存时，可以通过 brk() 调整堆区边界，增加可用内存大小。

malloc() 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

<font color="#F100">malloc() 分配的是虚拟内存</font>，如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的；只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发**缺页中断**，然后操作系统会建立虚拟内存和物理内存之间的映射关系。



- malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；
- malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。

## 5.内存分配的过程是怎样的？
应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。

缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。

如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收（kswapd）** ：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
- **直接内存回收（direct reclaim）**：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么触发 OOM （Out of Memory）机制。根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，直到释放足够的内存位置

可被回收的内存类型有**文件页**和**匿名页**：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

可以调整文件页和匿名页的回收倾向，尽量倾向于回收文件页
    
> 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。


> 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。

>文件页和匿名页的回收都是基于 LRU 算法（active 和 inactive 两个双向链表），越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。


## 6.在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
	- 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
	- 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；


## 7.如何避免预读失效和缓存污染的问题？

传统的 LRU 算法法无法避免下面这两个问题：

- 预读失效导致缓存命中率下降；
- 缓存污染导致缓存命中率下降；

> 预读失效（Predictive Prefetching Invalidation）是指在计算机系统中，特别是涉及到磁盘I/O操作时，系统预测未来的数据访问模式并提前加载数据到缓存中，但实际的访问模式与预测不符，导致提前加载的数据变得不再需要，从而造成缓存空间的浪费。

>缓存污染（Cache Pollution）是指在缓存中存储了大量不常用或不再需要的数据，这些数据占据了宝贵的缓存空间，导致有用的数据无法被缓存，从而降低了缓存效率。

为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：

- Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）。
- MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。

但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在**缓存污染**的问题。

为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别**提高了升级为热点数据的门槛**：

- Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
- MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
	- 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
	- 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；


通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。


## 8.南桥和北桥
北桥芯片还有个名字叫“图形与内存控制器”，南桥叫“输入/输出控制器”。

北桥芯片组因为与CPU联系密切所以它在主板靠近CPU的位置，而南桥芯片则在远离CPU的位置

北桥芯片(North Bridge)是主板芯片组中起主导作用的最重要的组成部分，也称为**主桥(Host Bridge)**，主要负责与CPU的联系并控制内存、AGP数据在北桥内部传输，提供对CPU的类型和主频、系统的前端总线频率、ECC纠错等支持。

南桥芯片主要是偏向于集成功能，主要负责I/O总线之间的通信，如PCI总线、USB和高级电源管理等。

现在芯片已经没有北桥了，功能被集成到了CPU中。

## 9.什么是虚拟内存？解决了什么问题？
虚拟内存是操作系统内存管理的一种技术，每个进程启动时，操作系统会提供一个独立的虚拟地址空间，这个地址空间是连续的，进程可以很方便的访问内存，这里的内存指的是访问虚拟内存。虚拟内存的目的，一是方便进程进行内存的访问，二是可以使有限的物理内存运行一个比它大很多的程序。

虚拟内存的基本思想：每个程序拥有自己的地址空间，这个空间被分割成很多块，每块称为一页，每一页地址都是连续的地址范围。这些页被映射到物理内存，但不要求是连续的物理内存，也不需要所有的页都映射到物理内存，而是按需分配，在程序片段需要分配内存时由硬件执行映射(通常是 MMU)，调入内存中执行。


## 10.说说分页和分段的机制？
分页是实现虚拟内存的技术，虚拟内存按照固定的大小分为页面，物理内存也会按照固定的大小分成页框，页面和页框大小通常是一样的，一般是 4KB，页面和页框可以实现一对一的映射。分页是一维的，主要是为了获得更大的线性地址空间。但是一个地址空间可能存在很多个表，表的数据大小是动态增长的，由于多个表都在一维空间中，有可能导致一个表的数据覆盖了另一个表。

分段是把虚拟内存划分为多个独立的地址空间，每个地址空间可以动态增长，互不影响。每个段可以单独进行控制，有助于保护和共享。

## 11. 页表的作用？为什么引入多级页表？
页表实现了虚拟内存到物理内存的映射，当访问一个虚拟内存页面时，页面的虚拟地址将作为一个索引指向页表，如果页表中存在对应物理内存的映射，则直接返回物理内存的地址，否则将引发一个缺页异常，从而陷入到内核中分配物理内存，返回对应的物理地址，然后更新页表。

为了加快虚拟地址到物理地址的转换，多数系统会引入一个转换检测缓冲区（TLB）的设备，通常又称为快表，当请求访问一个虚拟地址时，处理器检查是否缓存了该虚拟地址的映射，如果命中则直接返回物理地址，否则就通过页表搜索对应的物理地址。

由于虚拟内存通常比较大(32 位系统通常是 4G)，要实现整个地址空间的映射，需要非常大的页表。解决的办法是引入多级页表，只将那些用到的页面装载进来，因此，多级页表可以大大节约地址转换所需要的的空间。

## 12.页面置换算法有哪几种？
访问的页面不在内存中时，会发生一个缺页异常，操作系统必须将该页换出内存，如果此时内存已满，则操作系统必须将其中一个页面换出，放到 swap 交换区中，为当前访问的页面腾出空间，这个过程称为页面置换。操作系统提供了多种页面置换算法：

**1.最优页面置换算法**

选择一个将来最长时间不会被访问的页面换出。这样可以保证将来最低的缺页率。这是一种理论上的算法，因为无法知道哪个页面是将来最长时间都不会被访问的

**2.最近未使用页面置换算法 (NRU)**

为每个页面设两个状态位：被访问时设置为 R=1 位，页面被修改时，设置为 M=1 位。当启动一个进程时，所有页面都被初始化为 R=0，M=0。其中 R 位会被定时的清 0，以此区分最近被访问的页面和没有被访问的页面。

于是所有页面可以分为以下 4 类：

- 0 类：R=0，M=0；
- 1 类：R=0，M=1；
- 2 类：R=1，M=0；
- 3 类：R=1，M=1；

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出（挑选优先级：1 类 > 2 类 > 3 类）。

**3.最近最少未使用（LRU）页面置换算法**

在内存中维护一个所有页面的单链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**4.先进先出（FIFO）页面置换算法**

维护一个链表，最先进入的页面放在表头，最后进入的页面放在表尾，当缺页中断发生时，直接淘汰表头的页面，并把新的页面放在表尾。

这种算法有可能置换掉经常访问的页面，导致缺页率升高。

**5.第二次机会页面置换算法**

对 FIFO 算法做一个修改：取出表头的页面时，检查该页面的 R 位，如果是 1 表示是最近有访问的，将其清 0，然后放入表尾，然后继续检查下一个表头的页面，直到遇到一个 R 位为 0 的页面，将其换出。

**6.时钟页面置换算法**

单链表改成了环形链表，形成一个时钟，移动的也不是页面，而是中间的表针。检查页面逻辑类似，如果该页面 R 为 0，则直接置换该页面，否则将该 R 位清 0，然后表针向前移动。


## 13.内存是如何分配的？
Linux 分配物理内存的主要机制是页面分配机制（页分配器），使用了著名的伙伴算法，主要用来分配页大小的整数倍的内存(4n KB)。如果是小于页大小的内存分配，通常使用 slab 管理器。通过 slab 分配的内存通常会缓存起来，方便下次使用。


## 14.内存是如何回收的？
应用程序用完内存后，可以调用 free() 释放内存，或调用 unmap() 取消内存映射，归还系统。

在内存紧张时，会通过一系列机制来回收内存，如以下三种方式：

- 回收缓存。主要是页缓存。
- 回收不常访问的页面。使用页面置换算法，把不常用的页面放到交换区中。
- 通过 OOM 杀死占用大量内存的进程，释放内存。

----------


# 进程管理
## 1.


## 2.



1. 进程和线程的区别?
2. 什么是协程，协程有什么优点？
3. 并发和并行
4. 进程间通信有哪几种方式，都有什么特点？
5. 僵尸进程和孤儿进程的区别？
6. 进程是怎么调度的？
7. 进程有哪几种状态，他们是如何转换的？
8. 进程和线程的创建方式？
9. 子进程创建时会拷贝父进程哪些资源？
10. 进程上下文切换和线程上下文切换
11. 什么是系统调用？为什么要有系统调用？
12. 内核态和用户态是什么？
13. 如何实现进程同步？
14. 生产者消费者问题
16. 什么是信号量？如何使用信号量解决生产者消费者问题？
17. 哲学家就餐问题
18. 读者-写者问题

[面试-操作系统篇：进程与线程](https://www.cnblogs.com/turbobin/p/14287553.html)


# 调度算法


# 文件系统

1. 文件系统和磁盘有什么关系？
2. 文件系统有哪些结构？
3. 什么是虚拟文件系统，有什么作用？
4. 同步IO和异步IO，阻塞和非阻塞IO有什么区别？
5. 什么是DMA技术？
6. 什么是零拷贝技术？
7. 磁盘的分类，都有什么特点？
8. IO调度算法有哪几种？

# 设备管理


# 网络系统



# Linux 命令