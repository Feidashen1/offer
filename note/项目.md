## 1.do{ ... }while(0) 的用途
**1.帮助定义复杂的宏以避免错误**
> do 能确保大括号里的逻辑能被执行，而 while(0) 能确保该逻辑只被执行一次，即与没有循环时一样；
> [https://www.cnblogs.com/lanxuezaipiao/p/3535674.html](https://www.cnblogs.com/lanxuezaipiao/p/3535674.html)


**2.避免使用goto控制程序流**
>由于 goto 不符合软件工程的结构化，而且有可能使得代码难懂，所以很多人都不倡导使用，那这个时候就可以用 do{}while(0)来进行统一的管理

**3.避免由宏引起的警告**
>由于内核不同体系结构的限制，我们可能需要多次使用空宏。在编译的时候，这些空宏会产生警告，为了避免这种警告，我们可以使用`do{...}while(0)`来定义空宏：`#define EMPTYMICRO do{}while(0) `，这样在编译的时候就不会产生警告。

**4.定义单一的函数块来完成复杂的操作**
>当你的功能很复杂，变量很多你又不愿意增加一个函数的时候，使用`do{}while(0)`;，将你的代码写在里面，里面可以定义变量而不用考虑变量名会同函数之前或者之后的重复。

## 2.socket accept 发生在三次握手的哪一步？
客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。

## 3.没有 accept 或 listen 能建立 TCP 连接吗？
可以。

- accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

- 客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是**没有服务端参与**，也就是没有 listen，就能 TCP 建立连接。

服务端如果只 bind 了 IP 地址和端口，没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文。


## 4.程序是如何表示 TCP 发送方和接收方滑动窗口呢？

**发送方**

发送方滑动窗口：| 已发送并收到ACK | 已发送未收到ACK | 未发送但大小在接受方处理范围内 | 未发送大于范围 |

TCP 发送方滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

1. 指向的是已发送但未收到确认的第一个字节的序列号；
2. 指向的是已发送但未收到确认的第一个字节的序列号；
3. 指向超范围的第一个字节，是个相对指针，利用前两个绝对指针求出。


**接收方**

接收方滑动窗口：| 已成功接收并确认的数据（等待应用进程读取） | 未收到数据但可以接收的数据 | 未收到数据并不可以接收的数据 |

其中三个接收部分，使用两个指针进行划分：

1. 绝对指针，指向期望从发送方发送来的下一个数据字节的序列号；
2. 相对指针，指向未收到数据并不可以接收的数据的第一个字节；



## 5.什么是argc参数和argv参数？
argc和argv是两个用于传递命令行参数的参数。

- argc（argument count）是一个整数，表示传递给程序的命令行参数的数量（包括程序本身）。它至少为1，因为第一个参数始终是程序的名称(argv[0])。
- argv（argument vector）是一个指向字符串数组的指针，每个字符串表示一个命令行参数。第一个元素argv[0]是程序的名称，后续元素argv[1]、argv[2]，以此类推，表示其他命令行参数。

## 6.C++（.）和（-＞）运算符用法
C++中，点运算符（.）用于访问类的成员变量和成员函数，而箭头运算符（->）用于通过指针访问类的成员变量和成员函数。

点运算符用法：

- 访问类的成员变量：对象名.成员变量名
- 访问类的成员函数：对象名.成员函数名(参数列表)

箭头运算符用法：

- 访问指针指向的对象的成员变量：指针->成员变量名
- 访问指针指向的对象的成员函数：指针->成员函数名(参数列表)

需要注意的是**，箭头运算符只能用于指向类对象的指针**，而不能用于普通对象。

[https://blog.csdn.net/weixin_45055461/article/details/132247105](https://blog.csdn.net/weixin_45055461/article/details/132247105)

## 7.C++ 单例模式？
单例 Singleton 是设计模式的一种，其特点是只提供**唯一一个类的实例**，具有**全局变量**的特点，**在任何位置都可以通过接口获取到**那个唯一实例；
具体运用场景如：

- 设备管理器，系统中可能有多个设备，但是只有一个设备管理器，用于管理设备驱动；
- 数据池，用来缓存数据的数据结构，需要在一处写，多处读取或者多处写，多处读取；
- 日志，需要确保即使多个线程或进程同时打印消息，消息也将按顺序打印，不会出现乱码或交错；

**问题：为什么需要单例模式？**

两个原因：

- 节省资源。一个类只有一个实例，不存在多份实例，节省资源。
- 方便控制。在一些操作公共资源的场景时，避免了多个对象引起的复杂操作。


但是在实现单例模式时，需要考虑到线程安全的问题。

**问题：单例模式分类？**

单例模式可以分为 懒汉式 和 饿汉式 ，两者之间的区别在于创建实例的时间不同。

- **懒汉式：**
系统运行中，实例并不存在，只有当需要使用该实例时，才会去创建并使用实例。这种方式要考虑线程安全。

- **饿汉式：**
系统一运行，就初始化创建实例，当需要时，直接调用即可。这种方式本身就线程安全，没有多线程的线程安全问题。

**问题：单例类的特点？**

- 构造函数和析构函数为私有类型，目的是禁止外部构造和析构。
- 拷贝构造函数和赋值构造函数是私有类型，目的是禁止外部拷贝和赋值，确保实例的唯一性。
- 类中有一个获取实例的静态方法，可以全局访问。

[C++ 单例模式总结（5种单例实现方法）](https://gitcode.csdn.net/65e6e7161a836825ed787677.html?dp_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpZCI6NjI1OTk5LCJleHAiOjE3MTY1MzczMjQsImlhdCI6MTcxNTkzMjUyNCwidXNlcm5hbWUiOiJGRFM5OTk5OSJ9.0AtBexPqRckfTu7996AB0xDbysx_YF6c8Ap3ZEF8Je0)

## 8.单例模式实现？

**静态局部变量的懒汉单例（推荐）**
> C++ 11标准中新增了一个特性叫 Magic Static：如果变量在初始化时，并发线程同时进入到static声明语句，并发线程会阻塞等待初始化结束。
> 
这样可以保证在获取静态局部变量的时候一定是初始化过的，所以具有线程安全性，同时也避免了new对象时指令重排序造成对象初始化不完全的现象。并且相比较与使用智能指针以及 mutex 来保证线程安全和内存安全来说，这样做能够提升效率。

**加锁的懒汉式单例**


- **方法1：返回普通指针**
- **方法2：返回智能指针**


**使用 C++11 std::call_once 实现

> std::call_once的作用是很简单的，　就是保证函数或者一些代码段在并发或者多线程的情况下，始终只会被执行一次。懒汉单例**



**饿汉式单例**

[https://blog.csdn.net/unonoi/article/details/121138176
](https://blog.csdn.net/unonoi/article/details/121138176)

## 9.C++ 日志工具 - Log4cpp 
Log4cpp是一个开源的C++类库，它提供了在C++程序中使用日志和跟踪调试的功能。

Log4cpp有三个主要的组件：日志类别（Category）、输出源（Appender）和布局（Layout）。

1）**日志类别（Category）** 含义是：如果配置文件中设置的级别是 DEBUG，则任意的 log 都能打印出来；但如果配置的级别是 ERROR，则只有高于 ERROR 优先级的日志才可以打印出来。

日志的常用优先级：DEBUG < INFO < WARN < ERROR < FATAL。

2）**输出源（Appender）** 用来输出日志（被layout格式化后）写到什么地方去，比如文件、命令行、内存等。也可以定义自己的 appender 输出日志信息到别的设备上。log4cpp 提供的 appender 如下： FileAppender 输出到文件 RollingFileAppender 输出到回卷文件，即当文件到达某个大小后回卷 ConsoleAppender 输出到控制台。

3）**布局（Layout）**：显示样式 PatternLayout 表示让用户根据类似于C语言printf函数的转换模式来指定输出格式。

三个组件之间的关系：

Category 和 Appender 的关系是：多个 Appender 可以附加到一个 Category 上，这样一个日志消息可以同时输出到多个设备上。
Appender 和 Layout 的关系是：Layout 附加在 Appender 上，appender 调用 layout 处理完日志消息后，记录到某个设备上。


## 10.try-catch
     try{ // 可能抛出异常的语句 }catch(exceptionType variable){ // 处理异常的语句 }

try和catch都是 C++ 中的关键字，后跟语句块，不能省略{ }。try 中包含可能会抛出异常的语句，一旦有异常抛出就会被后面的 catch 捕获。从 try 的意思可以看出，它只是“检测”语句块有没有异常，如果没有发生异常，它就“检测”不到。catch 是“抓住”的意思，用来捕获并处理 try 检测到的异常；如果 try 语句块没有检测到异常（没有异常抛出），那么就不会执行 catch 中的语句。

## 11.INI文件的解析器-inipaerse
Dictionary 是由一组无序的键（keys）和对应的值（values）组成的数据集合。每个键必须是独一无二的，而值可以重复。Dictionary中的键和值可以是任意的Objective-C对象。

Dictionary对象是通过NSDictionary类实现的。NSDictionary是一个不可变的类，一旦创建就不能修改。如果需要修改Dictionary，可以使用NSMutableDictionary类。NSMutableDictionary是可变的，可以在运行时添加、删除或修改键值对。

> 字典具有不可重复性，如果键重复会进行替换


ini 文件的最基本组成单元就是key或者叫property，每个key都有一个名称（name）和对应的值（value）

## 11.为什么static成员变量一定要在类外初始化?
在C++中，类的静态成员（static member）必须在类内声明，在类外初始化。

对于静态成员变量而言，它们的生命周期与类的生命周期相关联，而不是与类的实例的生命周期相关联。编译时在静态数据区分配内存，到程序结束时才释放。这就意味着 static 成员变量不随对象的创建而分配内存，也不随对象的销毁而释放内存。而普通成员变量在对象创建时分配内存，在对象销毁时释放内存。

静态成员变量**实际上就是类域中的全局变量**，类内声明，类外进行初始化操作。

因为静态成员属于整个类，而不属于某个对象，如果在类内初始化，会导致每个对象都包含该静态成员，这是矛盾的：

- 如果静态成员变量有默认初始化值，且在多个源文件中都包含了该类的定义，那么编译器会在每个源文件中生成对静态成员变量的初始化代码，从而导致链接时的多重定义错误。
- 此外，静态成员变量的默认初始化值可能会因编译器、平台或环境的不同而产生差异，这会导致程序行为的不确定性。


# RPC

## 1.为什么要有RPC
- http接口是在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段；优点就是简单、直接、开发方便。利用现成的http协议进行传输。但是如果是一个大型的网站，内部子系统较多、接口非常多的情况下，RPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。第三个来说就是安全性。最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑。
- socket只是一个简单的网络通信方式，只是创建通信双方的通信通道，而要实现rpc的功能，还需要对其进行封装，以实现更多的功能。
- RPC一般配合netty框架、spring自定义注解来编写轻量级框架，其实netty内部是封装了socket的，较新的jdk的IO一般是NIO，即非阻塞IO，在高并发网站中，RPC的优势会很明显

## 2.什么是RPC

RPC（Remote Procedure Call Protocol）远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。简言之，RPC使得程序能够像访问本地系统资源一样，去访问远端系统资源。比较关键的一些方面包括：通讯协议、序列化、资源（接口）描述、服务框架、性能、语言支持等

## 3.RPC架构组件
一个基本的RPC架构里面应该至少包含以下4个组件：

1、客户端（Client）:服务调用方（服务消费者）

2、客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端

3、服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理

4、服务端（Server）:服务的真正提供者



**具体调用过程：**

- 1、服务消费者（client客户端）通过调用本地服务的方式调用需要消费的服务；
- 2、客户端存根（client stub）接收到调用请求后负责将方法、入参等信息序列化（组装）成能够进行网传输的消息体；
- 3、客户端存根（client stub）找到远程的服务地址，并且将消息通过网络发送给服务端；
- 4、服务端存根（server stub）收到消息后进行解码（反序列化操作）；
- 5、服务端存根（server stub）根据解码结果调用本地的服务进行相关处理；
- 6、本地服务执行具体业务逻辑并将处理结果返回给服务端存根（server stub）；
- 7、服务端存根（server stub）将返回结果重新打包成消息（序列化）并通过网络发送至消费方；
- 8、客户端存根（client stub）接收到消息，并进行解码（反序列化）；
- 9、服务消费方得到最终结果；

而RPC框架的实现目标则是将上面的第2-10步完好地封装起来，也就是把调用、编码/解码的过程给封装起来，让用户感觉上像调用本地服务一样的调用远程服务。


## 4.RPC的实现基础？

- 1、需要有非常高效的网络通信，比如一般选择Netty作为网络通信框架；
- 2、需要有比较高效的序列化框架，比如谷歌的Protobuf序列化框架；
- 3、可靠的寻址方式（主要是提供服务的发现），比如可以使用Zookeeper来注册服务等等；
- 4、如果是带会话（状态）的RPC调用，还需要有会话和状态保持的功能；

## 5.RPC使用了哪些关键技术？

1、动态代理

生成Client Stub（客户端存根）和Server Stub（服务端存根）的时候需要用到Java动态代理技术，可以使用JDK提供的原生的动态代理机制，也可以使用开源的：CGLib代理，Javassist字节码生成技术。

2、序列化和反序列化

在网络中，所有的数据都将会被转化为字节进行传送，所以为了能够使参数对象在网络中进行传输，需要对这些参数进行序列化和反序列化操作。
序列化：把对象转换为字节序列的过程称为对象的序列化，也就是编码的过程。反序列化：把字节序列恢复为对象的过程称为对象的反序列化，也就是解码的过程。 目前比较高效的开源序列化框架：如Kryo、FastJson和Protobuf等。
反序列化：把字节序列恢复为对象的过程称为对象的反序列化，也就是解码的过程。 目前比较高效的开源序列化框架：如Kryo、FastJson和Protobuf等。

3、NIO通信

出于并发性能的考虑，传统的阻塞式 IO 显然不太合适，因此我们需要异步的 IO，即 NIO。Java 提供了 NIO 的解决方案，Java 7 也提供了更优秀的 NIO.2 支持。可以选择Netty或者MINA来解决NIO数据传输的问题。

4、服务注册中心

可选：Redis、Zookeeper、Consul 、Etcd。一般使用ZooKeeper提供服务注册与发现功能，解决单点故障以及分布式部署的问题(注册中心)。


## 6.主流RPC框架有哪些?

- 1、**RMI** 利用java.rmi包实现，基于Java远程方法协议(Java Remote Method Protocol) 和java的原生序列化。
- 2、**Hessian** 是一个轻量级的remoting onhttp工具，使用简单的方法提供了RMI的功能。 基于HTTP协议，采用二进制编解码。
- 3、**protobuf-rpc-pro** 是一个Java类库，提供了基于 Google 的 Protocol Buffers 协议的远程方法调用的框架。基于Netty 底层的 NIO 技术。支持 TCP 重用/keep-alive、SSL加密、RPC 调用取消操作、嵌入式日志等功能。
- 4、**Thrift** 是一种可伸缩的跨语言服务的软件框架。它拥有功能强大的代码生成引擎，无缝地支持C++，C#，Java，Python和PHP和Ruby。thrift允许你定义一个描述文件，描述数据类型和服务接口。依据该文件，编译器方便地生成RPC客户端和服务器通信代码。最初由facebook开发用做系统内个语言之间的RPC通信，2007年由facebook贡献到apache基金 ，现在是apache下的opensource之一 。支持多种语言之间的RPC方式的通信：php语言client可以构造一个对象，调用相应的服务方法来调用java语言的服务，跨越语言的C/S RPC调用。底层通讯基于SOCKET。
- 5、**Avro** 出自Hadoop之父Doug Cutting, 在Thrift已经相当流行的情况下推出Avro的目标不仅是提供一套类似Thrift的通讯中间件,更是要建立一个新的，标准性的云计算的数据交换和存储的Protocol。支持HTTP，TCP两种协议。
- 6、**Dubbo** 是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。

## 7.RPC的实现原理架构
[https://juejin.cn/post/7055613735020265479#heading-8](https://juejin.cn/post/7055613735020265479#heading-8)

两台服务器A，B，一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。

**1、建立通信**

首先要解决通讯的问题：即A机器想要调用B机器，首先得建立起通信连接。主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。

通常这个连接可以是按需连接（需要调用的时候就先建立连接，调用结束后就立马断掉），也可以是长连接（客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送，可以配合心跳检测机制定期检测建立的连接是否存活有效），多个远程过程调用共享同一个连接。

**2、服务寻址**

要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么。通常情况下我们需要提供B机器（主机名或IP地址）以及特定的端口，然后指定调用的方法或者函数的名称以及入参出参等信息，这样才能完成服务的一个调用。可靠的寻址方式（主要是提供服务的发现）是RPC的实现基石，比如可以采用Redis或者Zookeeper来注册服务等等。

- **从服务提供者的角度看**：当服务提供者启动的时候，需要将自己提供的服务注册到指定的注册中心，以便服务消费者能够通过服务注册中心进行查找；当服务提供者由于各种原因致使提供的服务停止时，需要向注册中心注销停止的服务；服务的提供者需要定期向服务注册中心发送心跳检测，服务注册中心如果一段时间未收到来自服务提供者的心跳后，认为该服务提供者已经停止服务，则将该服务从注册中心上去掉。
- **从调用者的角度看**： 服务的调用者启动的时候根据自己订阅的服务向服务注册中心查找服务提供者的地址等信息；当服务调用者消费的服务上线或者下线的时候，注册中心会告知该服务的调用者；服务调用者下线的时候，则取消订阅。

**3、网络传输**

- **序列化**：当 A 机器上的应用发起一个RPC调用时，调用方法和其入参等信息需要通过底层的网络协议如 TCP 传输到 B 机器，由于网络协议是基于二进制的，所有我们传输的参数数据都需要先进行序列化（Serialize）或者编组（marshal）成二进制的形式才能在网络中进行传输。然后通过寻址操作和网络传输将序列化或者编组之后的二进制数据发送给 B 机器。
- **反序列化**：当 B 机器接收到 A 机器的应用发来的请求之后，又需要对接收到的参数等信息进行反序列化操作（序列化的逆操作），即将二进制信息恢复为内存中的表达方式，然后再找到对应的方法（寻址的一部分）进行本地调用（一般是通过生成代理Proxy去调用, 通常会有JDK动态代理、CGLIB动态代理、Javassist生成字节码技术等），之后得到调用的返回值。

4、**服务调用**

B 机器进行本地调用（通过代理Proxy和反射调用）之后得到了返回值，此时还需要再把返回值发送回 A 机器，同样也需要经过序列化操作，然后再经过网络传输将二进制数据发送回 A 机器，而当A机器接收到这些返回值之后，则再次进行反序列化操作，恢复为内存中的表达方式，最后再交给A机器上的应用进行相关处理（一般是业务逻辑处理操作）。
通常，经过以上四个步骤之后，一次完整的RPC调用算是完成了，另外可能因为网络抖动等原因需要重试等。


# zookeeper
## 1.ZooKeeper 是什么？
ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是 Google 的 Chubby 一个开源的实现它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为 zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个 zookeeper 最新的 zxid。

## 2.ZooKeeper 提供了什么？
- 1、文件系统
- 2、通知机制
- 3.Zookeeper文件系统。Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。

## 3.四种类型的 znode

- 1、**PERSISTENT-持久化目录节点**：客户端与zookeeper 断开连接后，该节点依旧存在
- 2、**PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点**：客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号
- 3、**EPHEMERAL-临时目录节点**：客户端与 zookeeper 断开连接后，该节点被删除
- 4、**EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点**：客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper 给该节点名称进行顺序号


## 4.Zookeeper 通知机制
client 端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些 client 会收到 Zookeeper 的通知，然后 client 可以根据 znode 变化来做出业务上的改变等。

## 5.Zookeeper 做了什么？
- 1、命名服务
- 2、配置管理
- 3、集群管理
- 4、分布式锁
- 5、队列管理


## 6.zk 的命名服务（文件系统）
命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。

## 7.zk 的配置管理（文件系统、通知机制）
程序分布式的部署在不同的机器上，将程序的配置信息放在 zk 的 znode 下，当有配置发生改变时，也就是 znode 发生变化时，可以通过改变 zk 中某个目录节点的内容，利用 watcher 通知给各个客户端，从而更改配置。

## 8.Zookeeper 集群管理（文件系统、通知机制）
- 所谓集群管理无在乎两点：是否有机器退出和加入、选举 master。
- 对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了
- 新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount 又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为 master就好。

## 9.Zookeeper 分布式锁（文件系统、通知机制）
- 有了 zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。
- 对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。
- 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。

## 10.zookeeper watch 机制
Watch 机制官方声明：一个 Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。
Zookeeper 机制的特点：

- 1、一次性触发数据发生改变时，一个watcher event 会被发送到client，但是client 只会收到一次这样的信息。
- 2、watcher event 异步发送 watcher的通知事件从server发送到client是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化。所以我们使用 Zookeeper 不能期望能够监控到节点每次的变化。Zookeeper 只能保证最终的一致性，而无法保证强一致性。
- 3、数据监视Zookeeper有数据监视和子数据监视getdata() and exists()设置数据监视，getchildren()设置了子节点监视。
- 4、注册 watcher getData、exists、getChildren
- 5、触发 watcher create、delete、setData
- 6、setData()会触发 znode上设置的 data watch（如果 set 成功的话）。一个成功的 create() 操作会触发被创建的 znode上的数据 watch，以及其父节点上的child watch。而一个成功的 delete()操作将会同时触发一个 znode 的 data watch 和 child watch（因为这样就没有子节点了），同时也会触发其父节点的 childwatch。
- 7、当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到 watch 的。而当 client 重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch 可能会丢失：对于一个未创建的 znode 的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个 watch 事件可能会被丢失。
- 8、Watch 是轻量级的，其实就是本地 JVM 的 Callback，服务器端只是存了是否有设置了 Watcher 的布尔类型


## 线程池
**线程池的基本概念**：在应用程序启动时创建一定数量的线程，并将它们保存在线程池中。当需要执行任务时，从线程池中获取一个空闲的线程，将任务分配给该线程执行。当任务执行完毕后，线程将返回到线程池，可以被其他任务复用。

**线程池的设计思想**：为了避免频繁地创建和销毁线程的开销，以及控制并发执行的线程数量，从而提高系统的性能和资源利用率。

**线程池的关键组成部分**：

1. *线程池管理器（ThreadPoolExecutor）*：负责创建、管理和控制线程池。它负责线程的创建、销毁和管理，以及线程池的状态监控和调度任务。
1. *工作队列（BlockingQueue）*：用于存储待执行的任务。当线程池中的线程都在执行任务时，新的任务会被放入工作队列中等待执行。
1. *线程池线程（Worker Thread）*：实际执行任务的线程。线程池中会维护一组线程，这些线程可以被重复使用，从而避免了频繁创建和销毁线程的开销。


**运行机制如下**： 

1. 当任务到达时，线程池管理器会检查线程池中是否有空闲的线程。如果有，则将任务分配给空闲线程执行；如果没有，则进入下一步。
1. 如果线程池中的线程数量未达到最大限制，线程池管理器会创建一个新的线程，并将任务分配给该线程执行。
1. 如果线程池中的线程数量已达到最大限制，并且工作队列未满，则将任务放入工作队列中等待执行。
1. 当线程池中的线程执行完任务后，会从工作队列中获取下一个任务并执行。

**主要优点：**

1. 重用线程：线程池会在内部维护一组可重用的线程，避免了频繁地创建和销毁线程的开销，提高了线程的利用率。
1. 控制并发度：线程池可以限制并发执行的线程数量，防止系统过载。通过调整线程池的大小，可以控制并发度，避免资源消耗过大。
1. 提供线程管理和监控：线程池提供了一些管理和监控机制，例如线程池的创建、销毁、线程状态的监控等，方便开发人员进行线程的管理和调试。
1. 提供任务队列：线程池通常会使用任务队列来存储待执行的任务，这样可以实现任务的缓冲和调度。

**线程池的一些缺点包括**：

- 需要合理配置：线程池的性能和效果受到配置参数的影响，需要根据具体的应用场景和硬件环境来合理配置线程池的大小、任务队列的大小等参数。
- 可能引发资源泄露：如果线程池中的线程长时间闲置而不被使用，可能会导致资源的浪费和泄露。
- 可能引发死锁：在使用线程池时，如果任务之间存在依赖关系，可能会引发死锁问题，需要额外的注意和处理。


## volatile 关键字
volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改。volatile **提醒编译器它后面所定义的变量随时都有可能改变，因此编译后的程序每次需要存储或读取这个变量的时候，都会直接从变量地址中读取数据。**如 果没有 volatile 关键字，则编译器可能优化读取和存储，可能暂时使用寄存器中的值，如果这个变量由别的程序更新了的话，将出现不一致的现象。


销毁线程池时：` volatile uint_t  lock;`

在多线程编程中，有些变量可能会被多个线程访问并修改，如果不使用 volatile 声明，编译器可能会对变量进行一些优化，如缓存变量的值，从而可能导致线程间通信的错误。使用 volatile 声明变量后，编译器会强制要求每次访问该变量时都从内存中读取最新的值，从而确保了线程间通信的正确性。

一个参数既可以是const还可以是 volatile 吗？

可以，例如只读的状态寄存器。它是 volatile 因为它可能被意想不到地改变。它是 const 因为 程序不应该试图去修改它。

## void* 

如果指针 p1 和 p2 的类型相同，那么我们可以直接在 p1 和 p2 间互相赋值；如果 p1 和 p2 指向不同的数据类型，则必须使用强制类型转换运算符把赋值运算符右边的指针类型转换为左边指针的类型。

而 void * 则不同，任何类型的指针都可以直接赋值给它，无需进行强制类型转换。

但这并不意味着，void * 也可以无需强制类型转换地赋给其它类型的指针。因为"无类型"可以包容"有类型"，而"有类型"则不能包容"无类型"。

## 父类与子类的强转
**1.子类转换为父类**

子类转换为父类之后，不能调用子类独有的函数和成员变量，只能调用子类继承的虚函数，利用多态的特性。

**2.父类转换为子类**

父类转换为子类是会出现异常，因为子类比父类有更多的成员变量和函数。如果访问子类自己独有的成员变量，会访问到未知的地方。

**3.避免不安全的父类转换成子类**

使用强制转换符 dynamic_cast 来避免不安全的强制转换。


## 线程池处理任务的步骤
1. **任务提交**： 将任务提交给线程池管理器。
1. **任务队列**： 任务被放置在线程池的任务队列中等待执行。
1. **线程分配**： 线程池管理器根据任务队列的情况分配线程来执行任务。
1. **任务执行**： 分配的线程从任务队列中取出任务，并执行任务的代码逻辑。
1. **线程复用**： 线程执行完任务后，不会被销毁，而是重新放回线程池，以备下次使用。
1. **异常处理**： 如果任务执行过程中发生异常，线程池可以根据配置进行异常处理，比如记录日志、重启线程等。
1. **线程池关闭**： 当不再需要线程池时，可以关闭线程池，释放资源。


## CPU 密集型和 IO 密集型
CPU密集型和I/O密集型是根据任务对计算资源（CPU和内存）和输入/输出资源（磁盘、网络等）的需求程度来区分的

**CPU密集型**：指计算机程序或任务在执行过程中主要依赖于**中央处理器（CPU）**进行计算和处理的类型。这种类型的任务会占用大量的CPU资源，而相对较少地依赖其他计算机组件，如内存、硬盘或网络带宽。

**CPU密集型任务**:

- 主要依赖于中央处理器（CPU）进行计算和处理的任务。
- 需要大量的计算操作，例如科学计算、数据分析、图像处理、视频编码解码、密码学算法等。
- 对CPU的利用率要求较高，占用大量的计算资源，而对I/O资源的需求相对较低。
- CPU密集型任务通常会占用大量的CPU时间片，使CPU处于高负载状态，产生较高的功耗和热量。



**IO密集型**：与CPU密集型相对的是I/O密集型任务。I/O密集型任务主要依赖于**输入输出操作**，涉及较多的数据读写和网络通信，而CPU的计算和处理需求相对较少。例如，数据库访问、文件传输、网络通信等任务就属于I/O密集型。  

I/O密集型任务：

- 主要依赖于输入/输出操作，涉及较多的数据读写和网络通信的任务。
- 需要频繁地访问磁盘、网络或其他外部设备，例如数据库访问、文件传输、网络通信等。
- 对CPU的计算和处理需求相对较低，而对I/O资源的需求较高。
- I/O密集型任务通常会涉及大量的数据传输和等待时间，因此对磁盘、网络带宽等I/O资源的性能和响应速度要求较高。 

>I/O密集型任务的执行过程中，主要涉及以下几个方面：
>
> 1. **数据读取和写入**：任务需要从磁盘、网络或其他外部设备中读取数据或将数据写入到这些设备中，以完成任务的操作。
> 2. **等待时间**：在进行I/O操作时，任务需要等待设备响应和数据传输，这会占据大量的时间。因此，I/O密集型任务的执行效率往往受到磁盘、网络带宽等I/O资源的影响。
> 3. **缓存机制**：为了提高I/O密集型任务的执行效率，可以采用缓存机制来缓存一部分数据，以减少磁盘或网络访问次数，降低等待时间。
> 4. **并发操作**：为了充分利用I/O设备的性能，可以采用并发操作的方式，同时进行多个I/O任务，以提高I/O密集型任务的执行效率。


<font color = "#F100">一般来说，造成CPU密集型卡顿的原因通常是cpu不够用，使用多进程；而IO密集型卡顿则是由于线程不够用，需要多线程。</font>

**CPU密集型任务主要影响CPU内核的计算性能和负载情况，而I/O密集型任务则主要影响CPU内核的I/O调度和等待情况。**

核心线程数计算公式：

- CPU密集型：核心线程数 = CPU核数 + 1 //+1是为了预防某个线程被阻塞时，cpu可以调用其他线程。
- IO密集型：核心线程数 = CPU核数 / （1-阻塞系数） 
- IO密集型：核心线程数 = CPU核数 * 2


[https://blog.csdn.net/m0_62006803/article/details/134862520](https://blog.csdn.net/m0_62006803/article/details/134862520)


## Reactor 和 Proactor

Reactor 模式也叫 Dispatcher 模式，即 I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。

Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；

Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：

- Reactor 的数量可以只有一个，也可以有多个；
- 处理资源池可以是单个进程 / 线程，也可以是多个进程 /线程；

方案：

1.单 Reactor 单进程 / 线程；

- 因为只有一个进程，无法充分利用 多核 CPU 的性能；
- Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；

单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。

2.单 Reactor 多线程 / 进程；

- 单 Reator 多线程的方案优势在于能够充分利用多核 CPU 的能，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。
- 单 Reactor 的模式还有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。


3.多 Reactor 多进程 / 线程；



> 进程里有 Reactor、Acceptor、Handler 三个对象：

> - Reactor 对象的作用是监听和分发事件；
> - Acceptor 对象的作用是获取连接；
> - Handler 对象的作用是处理业务；


<font color="#F100">Reactor 是非阻塞同步网络模式，而 **Proactor 是异步网络模式**。</font>


- Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。
- Proactor 是异步网络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。

<font color="#F100">因此，Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。
</font>无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件。

[http://t.csdnimg.cn/RD39y](http://t.csdnimg.cn/RD39y)


## sprintf 与 snprintf 区别
	 int sprintf(char *str, const char &format, ...);

sprintf 是字符串格式化命令，主要功能是把格式化的数据写入字符串 str 中，返回值为写入 str 的字节数，结束字符‘\0’不计入内。其中， str是指要写入的缓冲区，format控制要写入str中数据的格式，例如%s、%d、%x等。

	int snprintf(char *str, size_t size, const char *format, ...);
snprintf 是字符串格式化命令，主要功能是把格式化的数据写入字符串 str 中，最多写 size 个字节，包括自动添加在字符串末尾处的结束字符 ‘\0’; 返回值为写入 str 的字节数，包括结束字符‘\0’。


## #inclue<string> 和 #include<string.h> 的区别
< string > 并非 < string.h > 的“升级版本”，他们是毫无关系的两个头文件。

- < string.h > 是旧的 C 头文件，对应的是基于 char* 的字符串处理函数；
- < string > 是包装了 std 的 C++ 头文件，对应的是新的 strng 类；
- < cstring > 是与 C 标准库的 <string.h> 相对应，但裹有 std 名字空间的版本。


## memset()和bzero()的使用和区别

	extern void bzero(void *s, int n)	//置字符串s的前n个字节为零且包括‘\0’
	extern void *memset(void *buffer, int c, int count)	//把buffer所指内存区域的前count个字节设置成c的值。


**区别**:

1、bzero() 不是 ANSI C 函数，其起源于早期的 Berkeley 网络编程代码，但是几乎所有支持套接字 API 的厂商都提供该函数；

2、memset() 为 ANSI C 函数，更常规、用途更广。


## C++函数前加两个冒号::但是前面没有类名，:C++中调用函数前，加两个冒号::和不加两个冒号，作用一样吗？

**不一样**，不加冒号的一定是当前作用域可见的所有的函数或者变量，否则报错，加冒号的可以一用冒号前的那个类或者命名空间里的函数或变量，否则一般是不能用的(双冒号前不加东西是全局变量或函数的意思)



## unique_ptr 使用场景
> **nique_ptr 不共享它的指针。**
> 内存资源所有权将转移到另一 unique_ptr，并且原始 unique_ptr 不再拥有此资源。

> 1. **创建unique_ptr**：不像shared_ptr一样拥有标准库函数make_shared来创建一个shared_ptr实例。要想创建一个unique_ptr，需要将一个new 操作符返回的指针传递给unique_ptr的构造函数：`unique_ptr<int> pInt(new int(5));`
> 2. unique_ptr没有copy构造函数，不支持普通的拷贝和赋值操作。可以进行移动构造和移动赋值操作：`unique_ptr<int> pInt2 = std::move(pInt);` `unique_ptr<int> pInt3(std::move(pInt2));`
> 3. **可以返回unique_pt**：可以从函数中返回一个unique_ptr。

**1、为动态申请的资源提供异常安全保证**

当我们动态申请内存后，有可能我们接下来的代码由于抛出异常或者提前退出（if语句）而没有执行 delete 操作。

解决的方法是使用unique_ptr来管理动态内存，**只要 unique_ptr 指针创建成功，其析构函数都会被调用**。确保动态资源被释放。

**2、返回函数内动态申请资源的所有权**

**3、在容器中保存指针**（使用移动语义）

**4、管理动态数组**

**5、作为auto_ptr的替代品**


# C++中的RAII机制

RAII是Resource Acquisition Is Initialization（wiki上面翻译成 “资源获取就是初始化”）的简称，是C++语言的一种管理资源、避免泄漏的惯用法。利用的就是**C++构造的对象最终会被销毁的原则**。

RAII的做法是使用一个对象，在其构造时获取对应的资源，在对象生命期内控制对资源的访问，使之始终保持有效，最后在对象析构的时候，释放构造时获取的资源。


**做法**：把资源用类进行封装起来，对资源操作都封装在类的内部，在析构函数中进行释放资源。当定义的局部变量的生命结束时，它的析构函数就会自动的被调用，如此，就不用程序员显示的去调用释放资源的操作了。


## C++静态成员变量为什么要类外初始化
**C++中的静态成员变量是属于整个类的，而不是属于类的任何特定实例。**

**1.多次定义：**
如果静态成员变量有默认初始化值，且在多个源文件中都包含了该类的定义，那么编译器会在每个源文件中生成对静态成员变量的初始化代码，从而导致链接时的多重定义错误。

**2.不确定性：**
静态成员变量的默认初始化值可能会因编译器、平台或环境的不同而产生差异，这会导致程序行为的不确定性。

## c++ 函数前面和后面 使用const 的作用
1.前面使用 const 表示返回值为 const；

2.后面加 const 表示函数不可以修改 class 的成员。


## C++ 中四种强制类型
**static_cast 转换**：**上行转换（派生类---->基类）**是安全的；**下行转换（基类---->派生类）**由于没有动态类型检查，所以是不安全的。


- a、主要执行非多态的转换操作，用于代替C中通常的转换操作；
- b、隐式转换都建议使用static_cast进行标明和替换；

**dynamic_cast 转换**：只有在派生类之间转换时才使用 dynamic_cast，type-id 必须是类指针，类引用或者void*。


**const_cast 转换**：唯一可以对常量进行操作的转换符；

**reinterpret_cast 转换**：

- a、reinterpret_cast是从底层对数据进行重新解释，依赖具体的平台，可移植性差
- b、reinterpret_cast可以将整型转换为指针，也可以把指针转换为数组
- c、reinterpret_cast可以在指针和引用里进行肆无忌惮的转换

<font color="#F100">reinterpret_cast用在任意指针（或引用）类型之间的转换；以及指针与足够大的整数类型之间的转换；从整数类型（包括枚举类型）到指针类型，无视大小。</font>


## 红黑树和AVL树（平衡二叉树）区别
**AVL树**是带有平衡条件的二叉查找树，一般是用平衡因子差值判断是否平衡并通过旋转来实现平衡，左右子树树高不超过1，和红黑树相比，AVL树是严格的平衡二叉树，平衡条件必须满足（所有节点的左右子树高度差的绝对值不超过1）。

**红黑树**是一种二叉查找树，但在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树。


1. AVL 树是一种更严格的平衡二叉树。相对来说旋转次数较多，所以适用于不那么需要频繁旋转的场景，比如插入删除较少的场景就可以用，比如查询。
1. 红黑树是一种相对不那么严格的弱平衡二叉树，因为旋转次数不那么多，所以对于插入删除等操作，优于 AVL 树。因此对于查找，插入，删除操作较多的情况，一般用红黑树。

## 红黑树特点
1. 节点是红色或黑色
1. 根是黑色
1. 叶子节点（外部节点，空节点）都是黑色，这里的叶子节点指的是最底层的空节点（外部节点），下图中的那些null节点才是叶子节点，null节点的父节点在红黑树里不将其看作叶子节点：
	1. 红色节点的子节点都是黑色
	1. 红色节点的父节点都是黑色
1. 从根节点到叶子节点的所有路径上不能有 2 个连续的红色节点
1. 从任一节点到叶子节点的所有路径都包含相同数目的黑色节点


[【数据结构】史上最好理解的红黑树讲解，让你彻底搞懂红黑树](https://blog.csdn.net/cy973071263/article/details/122543826?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172005728316800226575764%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172005728316800226575764&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122543826-null-null.142^v100^pc_search_result_base9&utm_term=%E7%BA%A2%E9%BB%91%E6%A0%91&spm=1018.2226.3001.4187)


## muduo 的 BUFFER
具体做法是，在栈上准备一个 64kb 字节的 extrabuf，然后利用 readv() 来读取数据，iovec 有两块，第一块指向 muduo Buffer 中的 writable 字节，另一块指向栈上的 extrabuf。这样如果读入的数据不多，那么全部都读到 Buffer 中去了；如果长度超过 Buffer 的 writable 字节数，就会读到栈上的 extrabuf 里，然后程序再把extrabuf 里的数据 append() 到 Buffer 中.

这么做利用了临时栈上空间 ，避免每个连接的初始 Buffer 过大造成的内存浪费，也避免反复调用 read() 的系统开销（由于缓冲区足够大，通常一次 readv() 系统调用就能读完全部数据）。由于 muduo 的事件触发采用 level trigger，因此这个函数并不会反复调用 read() 直到其返回 EAGAIN，从而可以降低消息处理的延迟。


## volatile关键字
确保本条指令不会因为编译器的优化而省略，而且要求每次从内存直接读值，而不是读高速cache中的备份。

**定时器的数量。**


## Linux中，如何获取某个时刻时间？
将字符串形式的时刻，用自纪元时间（Epoch时间，1970-01-01 00:00:00 +0000 (UTC)）以来的时间戳来表示，精度为1us（微秒）。

使用gettimeofday(2)，分辨率1us，其实现也能达到毫秒级（当然分辨率不等于精度），再加上Linux是非实时任务系统，也能满足日常计时功能。

time(2)只能精确到1s，ftime(3)已被废弃，clock_gettime(2)精度高，但系统调用开销比gettimeofday(2)大，网络编程中，最适合用gettimeofday(2)来计时。**muduo中也是这么做的**。




> 有没有一种可能，两个线程，或者两段出现在1us内执行？
> 
> 答案是有可能的，对于常规情况，即使时间戳相同，并不影响我们的日常计时功能；对于特殊需求，比如排序、查找，需要区分时间戳大小的，后面遇到具体情况具体分析。

## 单例模式，懒汉和饿汉的区别
**饿汉式**：立即加载，无论是否会用到这个对象，都会加载。适用于业务允许有充分启动和初始化时间的情况。

**懒汉式**：延迟加载，只有使用的时候才会加载。有线程安全的考量，适用于启动时感觉稍快但第一次调用时略慢的情况。


## RPC 相关
[https://www.nowcoder.com/discuss/363694300083879936](https://www.nowcoder.com/discuss/363694300083879936)

## 为什么引入readv()和writev()?
(1) 使用 read 函数将数据读到不连续的内存，或者 wirte 将不连续的内存发送出去，要多次调用read、write.

如果要从文件中读一片连续的数据至进程的不同区域，有两种方案:

① 使用read()一次将它们读至一个较大的缓冲区中，然后将它们分成若干部分复制到不同的区域；

② 调用read()若干次分批将它们读至不同区域。

同样，如果想将程序中不同区域的数据块连续地写至文件，也必须进行类似的处理。

(2) UNIX 提供了另外两个函数—readv() 和 writev()，它们只需一次系统调用就可以实现在文件和进程的多个缓冲区之间传送数据，免除了多次系统调用或复制数据的开销。

**readv()实现了分散输入的功能，writev()系统调用实现了集中输出。**

【**iov[0][iov\_base][iov\_len]**---**iov[1] [iov\_base] [iov\_len]** ....】


[https://blog.csdn.net/zhizhengguan/article/details/117173049](https://blog.csdn.net/zhizhengguan/article/details/117173049)


## 网络编程中使用 Protobuf 的两个先决条件
定义了一种紧凑（compact，相对 XML 和 JSON 而言）的可扩展二进制消息格式，特别适合网
络数据传输。

在网络编程中使用 Protobuf 需要解决以下两个问题：

1. **长度**，Protobuf 打包的数据没有自带长度信息或终结符，需要由应用程序自己在发送和接收的时候做正确的切分。

2. **类型**，Protobuf 打包的数据没有自带类型信息，需要由发送方把类型信息传给接收方，接收方创建具体的 Protobuf Message 对象，再做反序列化。

## O_CLOEXEC的作用
当一个进程使用 fork() 函数创建了一个子进程时，子进程会拷贝父进程的几乎所有内容，包括打开的文件描述符。

但是，实际上 fork 的过程是子进程复制了父进程的 task_struct 结构体，然后修改其中的部分内容。而**文件描述符的部分，是直接复制的父进程的**，也就是说，子进程并不是重新打开，而是直接复制，所以子进程和父进程使用的是相同的文件描述符。

而当子进程使用 exec 函数族执行新的程序的时候，新的内容会替换掉原空间中的内容，所以，文件描述符相关的东西就找不到了，这个文件描述符就无法关闭了。所以，在调用 exec 函数族前需要手动关闭文件描述符。

而当文件描述符设置了 O_CLOEXEC 属性后，在调用 exec 函数族时，文件描述符就会自动关闭，无需手动关闭。

## 大端模式和小端模式的区别
<font color="#F100">读数据永远是从低地址开始的</font>

地址编号小的是**低地址**，地址编号大的是**高地址**

**小端模式**：数据的**低位**放在**低地址空间**，数据的**高位**放在**高地址空间**；

**大端模式**：数据的**高位**放在**低地址空间**，数据的**低位**放在**高地址空间**。

[https://blog.csdn.net/weixin_45031801/article/details/136471384](https://blog.csdn.net/weixin_45031801/article/details/136471384)

## 什么是 `enable_shared_from_this`?
[http://t.csdnimg.cn/pbIm8](http://t.csdnimg.cn/pbIm8)

`enable_shared_from_this`，是一个模板类，定义在头文件 <memory>，其原型为：
`template< class T > class enable_shared_from_this`;

能让其一个对象（假设其名为 t ，且已被一个 `std::shared_ptr` 对象 pt 管理）安全地生成其他额外的 `std::shared_ptr` 实例（假设名为 pt1, pt2, … ），它们与 pt 共享对象 t 的所有权。

若一个类 T 继承自 `std::enable_shared_from_this<T>` ，则 T 类中有继承自父类的成员函数： `shared_from_this` 。 当 T 类的对象 t 被一个为名为 pt 的 `std::shared_ptr` 类对象管理时，调用 `T::shared_from_this` 成员函数，将会返回一个新的 `std::shared_ptr` 对象，它与 pt 共享 t 的所有权。


**为什么要用 `enable_shared_from_this`？**

- 需要在类对象的内部中获得一个指向当前对象的 shared_ptr 对象。
- 如果在一个程序中，对象内存的生命周期全部由智能指针来管理。在这种情况下，要在一个类的成员函数中，对外部返回 this 指针就成了一个很棘手的问题。


`enable_shared_from_this` 其内部保存着一个对 `this` 的弱引用（例如 `std::weak_ptr` )。 `std::shared_ptr` 的构造函数检测无歧义且可访问的 (C++17 起) `enable_shared_from_this` 基类，并且若内部存储的弱引用未为生存的 `std::shared_ptr` 占有，则 (C++17 起)赋值新建的 `std::shared_ptr` 为内部存储的弱引用。为已为另一 `std::shared_ptr` 所管理的对象构造一个 `std::shared_ptr` ，将不会考虑内部存储的弱引用，从而将导致未定义行为。

只允许在先前已被 `std::shared_ptr` 管理的对象上调用 `shared_from_this` 。否则调用行为未定义 (C++17 前)抛出 `std::bad_weak_ptr` 异常（通过 shared_ptr 从默认构造的 weak_this 的构造函数）  (C++17 起)。

`enable_shared_from_this` 提供安全的替用方案，以替代 `std::shared_ptr(this)` 这样的表达式（这种不安全的表达式可能会导致 this 被多个互不知晓的所有者析构）。

[http://t.csdnimg.cn/ektuW](http://t.csdnimg.cn/ektuW)


## Linux shutdown 与 close
**close 会关闭连接，并释放所有连接对应的资源**；
而**shutdown 并不会释放掉套接字和所有的资源**。 

`close`--关闭本进程的 `socket id`，但链接还是开着的，用这个 `socket id` 的其它进程还能用这个链接，能读或写这个socket id。


`shutdown`--破坏了 `socket` 链接，读的时候可能侦探到 `EOF` 结束符，写的时候可能会收到一个 `SIGPIPE` 信号，这个信号可能直到 `socket buffer` 被填充了才收到，`shutdown` 有一个关闭方式的参数，`0` 不能再读，`1` 不能再写，`2` 读写都不能。

确切地说，**close 用来关闭套接字**，将套接字描述符（或句柄）从内存清除，之后再也不能使用该套接字。 应用程序关闭套接字后，与该套接字相关的连接和缓存也失去了意义，TCP协议会自动触发关闭连接的操作。

如果有多个进程共享一个套接字，c**lose每被调用一次，计数减1，直到计数为0时**，也就是所用进程都调用了close，套接字将被释放。

在多进程中如果一个进程中shutdown(sfd, SHUT_RDWR)后其它的进程将无法进行通信。如果一个进程close(sfd)将不会影响到其它进程，得自己理解引用计数的用法了。

## cond.wait() 为什么要使用 mutex 变量来保持同步?

wait()函数的内部实现是：先释放了互斥量的锁，然后阻塞以等待条件为真；

notify系列函数需在unlock之后再被调用；

套路是：

    a. A 线程拿住锁，然后 wait，此时已经释放锁，只是阻塞了在等待条件为真；
    b. B 线程拿住锁，做一些业务处理，然后令条件为真，释放锁，再调用 notify 函数；
    c. A 线程被唤醒，接着运行。


## epoll 使用 LT 模式原因

1. 与 poll 兼容；
1. LT 模式不会发生漏掉事件的 BUG，但 POLLOUT 事件不能一开始就关注，否则会出现 busy loop，而应该在 write 无法完全写入内核缓冲区的时候才关注，将未写入内核缓冲区的数据添加到应用层 output buffer，直到应用层 output buffer写完，停止关注 POLLOUT 事件。-- 相当于写完成回调，处理写完成事件；
1. 读写的时候不必等候 EAGAIN，可以节省系统调用次数，降低延迟。（注：如果用 ET 模式，读的时候读到 EAGAIN，写的时候直到 output buffer 写完成或者 EAGAIN）。

## LT模式下，如何解决的粘包问题？
可以一次把内核缓冲区中的数据读完，存至 input buffer，通知应用程序，进行 onMessage(Buffer* buffer) 回调。在 onMessage 回调中，应用层协议判定是否是一个完整的包，如果不是一条完整的消息，不会取走数据，也不会进行相应的处理；如果是一条完整的消息（相应应用层协议制定协议，不由网络库负责），将取走这条消息，并进行相应的处理。



## 为什么需要有应用层缓冲区？
1.TcpConnection必须要有output buffer：要让程序在write操作上不阻塞，网络库必须给每个tcp connection配置output buffer。

2.TcpConnection必须要有input buffer：TCP是一个无边界的字节流协议，接收方必须要处理“收到的数据尚不构成一条完整的消息”“一次收到两条消息的数据”等情况。

## vector的 reserve 和 resize
 vector 的 reserve 增加了 vector 的 capacity，但是它的 size 没有改变！而 resize 改变了 vector 的 capacity 同时也增加了它的size。

 **reserve是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对象之前，不能引用容器内的元素**。加入新的元素时，要调用push_back()/insert()函数。

**resize 是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了**，因此当加入新的元素时，用operator[]操作符，或者用迭代器来引用元素对象。此时再调用push_back()函数，是加在这个新的空间后面的。

<<<<<<< HEAD

## RCU 机制解决了什么？
RCU（Read-Copy Update）是数据同步的一种方式。

RCU 主要针对的数据对象是**链表**，目的是提高遍历读取数据的效率，为了达到目的使用 RCU 机制读取数据的时候不对链表进行耗时的加锁操作。这样在**同一时间可以有多个线程同时读取该链表，并且允许一个线程对链表进行修改**（修改的时候，需要加锁）。

RCU 适用于需要频繁的读取数据，而相应修改数据并不多的情景，例如在文件系统中，经常需要查找定位目录，而对目录的修改相对来说并不多，这就是RCU发挥作用的最佳场景。

> RCU (Read-Copy Update)，顾名思义就是**读-拷贝修改**，它是基于其原理命名的。对于被 RCU 保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调（callback）机制在适当的时机把指向原来数据的指针重新指向新的被修改的数据。

**在RCU的实现过程中，主要解决以下问题**：

1. *在读取过程中，另外一个线程删除了一个节点*。删除线程可以把这个节点从链表中移除，但它不能直接销毁这个节点，必须等到所有的读取线程读取完成以后，才进行销毁操作。RCU中把这个过程称为**宽限期（Grace period）**；
2. *在读取过程中，另外一个线程插入了一个新节点，而读线程读到了这个节点，那么需要保证读到的这个节点是完整的*。这里涉及到了**发布-订阅机制（Publish-Subscribe Mechanism）**；
3. *保证读取链表的完整性*。新增或者删除一个节点，不至于导致遍历一个链表从中间断开。但是 RCU 并不保证一定能读到新增的节点或者不读到要被删除的节点。


### **RCU原理**

RCU 实际上是一种改进的 rwlock，读者几乎没有什么同步开销，它不需要锁，不使用原子指令，而且在除 alpha 的所有架构上也不需要内存栅（Memory Barrier），因此不会导致锁竞争，内存延迟以及流水线停滞。不需要锁也使得使用更容易，因为死锁问题就不需要考虑了。写者的同步开销比较大，它需要延迟数据结构的释放，复制被修改的数据结构，它也必须使用某种锁机制同步并行的其它写者的修改操作。

读者必须**提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机**。有一个专门的**垃圾收集器来探测读者的信号**，一旦所有的读者都已经发送信号告知它们都不在使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。

**RCU与rwlock的不同之处**是：它既允许多个读者同时访问被保护的数据，又允许多个读者和多个写者同时访问被保护的数据（注意：是否可以有多个写者并行访问取决于写者之间使用的同步机制），读者没有任何同步开销，而写者的同步开销则取决于使用的写者间同步机制。但**RCU不能替代rwlock，因为如果写比较多时，对读者的性能提高不能弥补写者导致的损失**。

**读者在访问被RCU保护的共享数据期间不能被阻塞**，这是RCU机制得以实现的一个基本前提，也就说当读者在引用被RCU保护的共享数据期间，读者所在的CPU不能发生上下文切换，spinlock和rwlock都需要这样的前提。写者在访问被RCU保护的共享数据时不需要和读者竞争任何锁，只有在有多于一个写者的情况下需要获得某种锁以与其他写者同步。

写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。等待适当时机的这一时期称为`grace period`，而CPU发生了上下文切换称为经历一个`quiescent state`，`grace period`就是所有CPU都经历一次`quiescent state`所需要的等待的时间。垃圾收集器就是在`grace period`之后调用写者注册的回调函数来完成真正的数据修改或数据释放操作的。


[Linux 内核：RCU机制与使用](https://www.cnblogs.com/schips/p/linux_cru.html)

## 
=======
## GET 和 POST安全性比较与讨论
**最基本区别：**

1. GET 请求通过 URL（请求行）提交数据，**在 URL 中可以看到所传参数**。POST 通过“请求体”传递数据，参数不会在 url 中显示；
1. GET 请求提交的数据**有长度限制**，POST 请求**没有限制**。
1. GET 请求返回的内容可以被浏览器缓存起来。而每次提交的 POST，浏览器在你按下 F5 的时候会跳出确认框，浏览器不会缓存 POST 请求返回的内容。
1. GET 对数据进行**查询**，POST 主要对数据进行**增删改**！简单说，GET是只读，POST是写。

**安全性：**

- 我认为post，更安全一些，因为 get 传输方式将在 URL 中显示参数，虽然可以编码，但也是可以解码的。而post则对方看不见，即使截获这些信息，也需要它筛选还有解码，相对来说比 get 方法更加安全。当然是没有绝对的安全的。
- HTTP协议中提到GET是安全的方法（safe method），其意思是说GET方法不会改变服务器端数据，所以不会产生副作用。如果是该用POST的地方用了GET，又说GET不安全，那GET也太冤枉了。也就是说，只要我们正确选择使用GET和POST，那么GET是安全的。
- 只要我们正确使用二者，因为GET方法中不对数据进行修改，不传送一些保密的信息，而这些需要由POST来传输，所以说GET不存在安全问题，而需要注意的是POST传输的安全问题。


## 智能指针理解
[http://t.csdnimg.cn/et0ON](http://t.csdnimg.cn/et0ON)

动态内存管理经常会出现两种问题：
（1）一种是忘记释放内存，会造成内存泄漏；
（2）一种是尚有指针引用内存的情况下就释放了它，就会产生引用非法内存的指针。

为了更加容易（更加安全）的使用动态内存，**引入了智能指针**的概念。智能指针的行为类似常规指针，重要的区别是它负责自动释放所指向的对象。

`auto_ptr` 是c++11以前的最原始的智能指针，可以将 new 获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用 delete 来释放内存。但是在c++11中已经被弃用（使用的话会被警告）了。

原因：

1. 复制或者赋值都会改变资源的所有权；
2. 在STL容器中使用auto_ptr存在着重大风险，因为容器内的元素必须支持可复制和可赋值；
3. 不支持对象数组的内存管理；

`unique_ptr`：`unique_ptr` 和 `auto_ptr` 用法几乎一样，除了一些特殊

特性：

1. 基于排他所有权模式：**两个指针不能指向同一个资源**
1. 无法进行左值 `unique_ptr` 复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值；
1. 保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象；
1. 在容器中保存指针是安全的；


`shared_ptr`：:它所指向的资源具有共享性，即多个shared_ptr可以指向同一份资源，并在内部使用引用计数机制来实现这一点。可以记录引用特定内存对象的智能指针数量，当复制或拷贝时，引用计数加 1，当智能指针析构时，引用计数减 1，如果计数为零，代表已经没有指针指向这块内存，那么就释放它。

<font color = "#FA1000">`shared_ptr` 的构造函数和拷贝构造函数做的事情，导致虽然都是指向同一个资源，但是**对于引用计数对象的管理方式**，这两个函数是不一样的，构造函数是**新分配引用计数对象**，拷贝构造函数只做引用**计数增减**。</font>

> 当新的 `shared_ptr` 对象与指针关联时，则在其构造函数中，将与此指针关联的引用计数增加1。

> 当任何 `shared_ptr` 对象超出作用域时，则在其析构函数中，它将关联指针的引用计数减1。如果引用计数变为0，则表示没有其他 `shared_ptr` 对象与此内存关联，在这种情况下，它使用delete函数删除该内存。


最安全的分配和使用动态内存的方法就是调用一个名为 `make_shared` 的标准库函数，此函数在动态内存中分配一个对象并初始化它，返回指向此对象的 `shared_ptr`。


<font color = "#F100">可以说，当生命控制权没有彼此互相掌握时，才能正确解决循环引用问题，而弱引用的使用可以使生命控制权互相掌握的情况消失。</font>

我们在 `enable_shared_from_this<A>` 基类中继承一个成员变量 `_Wptr`，当定义第一个智能指针对象的时候： `shared_ptr< A > ptr1(new A())`，调用 `shared_ptr` 的普通构造函数，就会初始化 `A` 对象的成员变量 `_Wptr`，作为观察 `A` 对象资源的一个弱智能指针观察者。

`weak_ptr` :设计的目的是为配合 `shared_ptr` 而引入的一种智能指针来协助 `shared_ptr` 工作, 它只提供了对管理对象的一个访问手段，同时也可以实时动态地知道指向的对象是否存活。它只可以从一个 `shared_ptr` 或另一个 `weak_ptr` 对象构造, 它的**构造和析构不会引起引用记数的增加或减少**。 同时 `weak_ptr` 没有重载`*`和`->`，，所以并不能直接使用资源，但可以使用 lock 获得一个可用的 `shared_ptr` 对象。

`shared_from_this()` 函数，是直接返回了一个 `shared_ptr<_Ty>(_Wptr)`，该语法在 shared_ptr 中也有相应的构造函数，其主要作用就是**把一个弱智能指针提升为一个强智能指针**，可以在多线程环境中判断对象是否存活或者已经析构释放.

[C/C++｜智能指针的 shared\_ from \_ this 和enable\_ shared\_ from\_ this](http://t.csdnimg.cn/sNhIH)

## HTTP 和 RPC 有什么区别？
**1.服务发现**：在 HTTP 中，知道服务的域名，就可以通过 DNS 服务去解析得到它背后的 IP 地址，默认 80 端口；而 RPC 的话，就有些区别，一般会有专门的中间服务去保存服务名和IP信息，比如我们项目中用的 Zookeeper；

**2.底层连接形式**：以主流的 HTTP/1.1 协议为例，其默认在建立底层 TCP 连接之后会一直保持这个连接（**Keep Alive**），之后的请求和响应都会复用这条连接；而 RPC 协议，也跟 HTTP 类似，也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个**连接池**，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用。

**3.传输的内容**：流的 HTTP/1.1，虽然它现在叫超文本协议，支持音频视频，但 HTTP 设计初是用于做网页文本展示的，所以它传的内容以字符串为主。Header 和 Body 都是如此。在 Body 这块，它使用 Json 来序列化结构体数据。内容非常多的冗余，显得非常啰嗦；而 RPC，因为它定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为。


## 接口是什么？什么是接口？
接口泛指实体把自己**提供给外界**的一种抽象化物（可以为另一实体），用以**由内部操作分离出外部沟通方法**，使其能被内部修改而不影响外界其他实体与其交互的方式。
**接口是指外部系统与系统之间以及内部各子系统之间的交互点。**

**接口的优势**

- 规范性：按照接口做具体的事情，就可以融合到整个系统中；
- 扩展性：需求经常变化，只改接口就可以；


常见web接口：一类是http协议的接口（et（查）、post（增），除此之外还有put（改）、delete（删）等），另一类是 web service 接口（如soup、rmi、rpc协议）。

## 内存池
内存池（memory pool）是一种内存管理机制，用于**管理一定数量的预分配内存块**。内存池在应用程序启动时就会分配一定数量的内存块，并在需要时从内存池中获取内存块，而不是使用常规的malloc或new等内存分配函数来动态分配内存。使用内存池可以显著降低内存分配和释放的开销，并且可以避免内存碎片的产生，从而提高应用程序的性能和可靠性。

**内存池的工作原理：**

1. 在初始化时，从操作系统申请一块**连续的物理内存**，称为内存池。
2. 将内存池按照**固定大小**分成多个内存块。
3. 将这些内存块用链表、栈或其他数据结构**连接**起来，形成一个内存块池。
4. 当需要分配内存时，从内存块池中获取一个内存块，并将其标记为已分配。
5. 当不需要使用内存块时，将其标记为未分配，放回到内存块池中。
6. 当内存块池中无可用内存块时，可以选择动态扩展内存池。

内存池的主要优势在于**可以避免动态分配内存时产生的内存碎片**，同时也避免了重复调用内存分配器的开销。由于内存块是预先分配的，因此内存池的内存分配速度相对较快。
并且内存池可以支持多种内存分配算法，适用于不同的应用场景；
内存池可以动态扩展，可以根据需要分配更多的内存块。


但内存池需要预先分配一定大小的内存，因此会占用一定的内存空间；内存池可能会浪费一些内存空间，因为每个内存块的大小都是固定的；内存池的实现需要额外的代码和管理工作，可能会增加代码复杂度和维护成本；内存池的性能取决于内存块大小的选择，如果选择不当，可能会影响性能。

## Linux内核空间内存申请函数kmalloc、kzalloc、vmalloc的区别
kmalloc() 申请的内存位于物理内存映射区域，而且在物理上也是连续的，它们与真实的物理地址只有一个固定的偏移，因为存在较简单的转换关系，所以对申请的内存大小有限制，不能超过128KB。

kzalloc() 函数与 kmalloc() 非常相似，参数及返回值是一样的，可以说是前者是后者的一个变种，因为 kzalloc() 实际上只是额外附加了 __GFP_ZERO 标志。所以它除了申请内核内存外，还会对申请到的内存内容清零。


vmalloc() 函数则会在**虚拟内存空间给出一块连续的内存区**，但这片**连续的虚拟内存在物理内存中并不一定连续**。由于 vmalloc() 没有保证申请到的是连续的物理内存，因此对申请的内存大小没有限制，如果需要申请较大的内存空间就需要用此函数了。


## 线程池定义任务队列
	// 定义任务队列类型
	typedef struct {
	    thread_task_t        *first;// 指向第一个任务的指针
	    thread_task_t        **last;// 指向最后一个任务的指针
	} thread_pool_queue_t;

last 是一个指向最后一个任务的指针，它的类型是一个指向 `thread_task_t` 指针的指针，也即**二级指针**。
它的作用是**方便在队列末尾添加新任务时更新队列最后一个任务的指针**。

如果 last 是一级指针，而不是指向指针的指针，那么在添加新任务时，就需要遍历整个任务队列，以找到最后一个任务的指针，这样会降低添加任务的效率。
而使用指向指针的指针，我们只需要将新任务的指针赋值给 `*last`，就可以方便地更新队列最后一个任务的指针，无需遍历整个队列。

	*queue.last = task; // 将 last 指向的新任务插入队列
    queue.last = &task->next; // 更新 last 以指向新任务的 next 指针

## 线程分离状态的理解
在任何一个时间点上，线程是可结合的（joinable），或者是分离的（detached）。一个可结合的线程能够被其他线程收回其资源和杀死；在被其他线程回收之前，它的存储器资源（如栈）是不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的，它的存储器资源在它终止时由系统自动释放。

**线程的分离状态决定一个线程以什么样的方式来终止自己**。
在默认情况下线程是非分离状态的，这种情况下，原有的线程等待创建的线程结束。只有当 `pthread_join()` 函数返回时，创建的线程才算终止，才能释放自己占用的系统资源；
而分离线程没有被其他的线程所等待，自己运行结束了，线程也就终止了，马上释放系统资源。

程序员应该根据自己的需要，选择适当的分离状态。所以如果我们在创建线程时就知道不需要了解线程的终止状态，则可以 `pthread_attr_t` 结构中的 `detachstate` 线程属性，让线程以分离状态启动。


## CAS操作
内核态的锁的时候需要操作系统进行一次上下文切换，加锁、释放锁会导致比较多的上下文切换和调度延时，等待锁的线程会被挂起直至锁释放。在上下文切换的时候，cpu之前缓存的指令和数据都将失效，对性能有很大的损失。

多线程读写非线程安全的数据结构时，为了保证结果正确性，一种方式是对数据结构加锁后进行读写。为了解决加锁带来的性能损耗问题，可使用CAS。

Compare-and-Swap (CAS)是**用于多线程以实现同步的原子指令**。它将存储位置的内容与给定值进行比较，当它们逐位相等，才将该存储位置的内容修改为新的给定值。整个流程为一个原子操作。
>>>>>>> 0ce19a78b59461ca84b1350ba55ea2bf54e2c640


