# C++

----------

## 1.C++ 在 main() 函数执行前，后执行了哪些操作?
main 函数执行之前，主要就是初始化系统相关资源：

1. 设置栈指针：栈分配相关的位置，用来放一些局部变量和其他数据；
2. 
3. 
4. 
5.  static 静态和 global 全局变量，即 data 段的内容：**把全局和静态变量初始化**；
3. 将未初始化部分的全局变量赋初值：数值型 short，int，long 等为0，bool 为FALSE，指针为NULL，等等，即 .bss 段的内容：**将未设置初值的全局变量赋初值**；
4. 全局对象初始化，在main之前调用构造函数；
5. 将main函数的参数，argc，argv等传递给main函数，然后才真正运行main函数。

在执行完 main 函数后：执行全局的析构函数，要销毁堆内存，关闭标准输入，输出，错误流。

## 2. 结构体内存对齐问题
- 结构体内成员按照声明顺序存储，第一个成员地址和整个结构体地址相同。
- 未特殊说明时，按结构体中size最大的成员对齐(若有double成员，按8字节对齐)

**内存对齐：** 一种提高内存访问速度的策略，CPU 在访问未对齐的内存可能需要经过两次的内存访问，而经过内存对齐一次就可以了。

**内存对齐的原则：**

- 对于结构体的各个成员，<font color="#F100">除了第一个成员的偏移量为 0 外，其余成员的偏移量是 **其实际长度** 的整数倍，如果不是，则在前一个成员后面补充字节。</font>
- 结构体内所有数据成员各自内存对齐后，结构体本身还要进行一次内存对齐，<font color="#F100">**保证整个结构体占用内存大小是结构体内最大数据成员的最小整数倍**。</font>
- 如程序中有  `#pragma pack(n)` 预编译指令，则所有成员对齐以 n 字节 为准（即偏移量是n的整数倍），不再考虑当前类型以及最大结构体内类型。

[https://www.cnblogs.com/hyacinthLJP/p/16041690.html](https://www.cnblogs.com/hyacinthLJP/p/16041690.html)

- C++ `alignas` 用来**指定**对象的对齐字节数。效果和__attribute__((aligned(n)))一样，对齐值必须是 2 的幂，`alignas` 指定的对齐要求不能低于类型的自然对齐要求。；
- C++ `alignof` 用来**查看**对象的对齐字节数。用法类似于sizeof。

使用<stddef.h>头文件中的，**offsetof 宏**，可以获得结构成员相对于结构开头的字节偏移量 `offserof(S,t)`，其中 `S` 是结构体，`t` 是结构体变量。

[http://t.csdnimg.cn/P5cZl](http://t.csdnimg.cn/P5cZl)

## 3. 指针和引用的区别
C++ 指针和引用的区别在于：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元； 而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。

- 指针是存储变量地址的变量；引用是变量的别名；
- 指针变量定义时不必初始化；引用定义时必须初始化，不然会报错；
- 指针变量定义时可以初始化为 NULL；引用不能初始化为 NULL，不然报错；
- const 修饰指针变量，const 放在之前，指针变量所指向变量的值不可改变，指针值可以改变；const 放在之后，指针变量所指向变量的值可以改变，指针值不可以改变；const 修饰引用，const 放在&之前，不能修改引用所表示的变量的值；const 放在 & 之后，const 的作用被忽略，可以修改引用所表示的变量的值。
- 非常指针在指针赋值后可以改变指针值；引用在初始化后不能再作为别的变量的别名。
- sizeof 运算符作用于指针变量得到指针变量自身大小；作用于引用，得到引用所指向的变量的大小。
- 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。
- 指针可以有多级，引用只有一级。
- 指针的自增、自减表示指向下一个同类型变量的地址，一般用于指向数组的指针；引用的自增、自减表示指向变量值的增、减。


> 指针的大小并不是固定的，它取决于运行程序的计算机架构。 在 32 位系统中，一个指针通常占用 4 个字节（32 bits / 8 bits per byte = 4 bytes）。 而在 64 位系统中，一个指针则占用 8 个字节（64 bits / 8 bits per byte = 8 bytes）。

## 4.在传递函数参数时，什么时候使用引用，什么时候使用指针，什么时候按值传递呢？
对于使用传递的值而不做修改的函数：

- 如果数据量很小，如内置数据类型或小型结构，则按值传递；
- 如果数据对象是数组，则使用指针，并将指针申明为指向 `const` 的指针(如`void fun(const int * arr, int length)`)；
- 如果数据对象是较大的结构，则使用 `const` 指针或 `const` 引用；
- 如果数据对象是类对象，则使用 `const` 引用。传递类对象参数的标准方式是按引用传递。

对于修改调用函数中数据的函数：

- 如果数据对象是内置数据类型，则使用引用，如`int* randomArr(int& length)`，别人看到这个声明就知道此函数内部会修改 `length` 的值；
- 如果数据对象是数组，则只能使用指针；
- 如果数据对象是结构体，则使用引用或指针；
- 如果数据对象是类对象，则使用引用；

总结：

- <font color="#A100">需要**返回函数内局部变量的内存的时候用指针**。使用指针传递参数需要先开辟内存，用完要释放指针，不然会内存泄漏。而返回局部变量的引用是没有意义的。
- 对栈空间大小比较敏感的场景（比如使用递归）要使用引用。**使用引用传递的时候不需要创建临时变量**，开销会更小。
- 类对象作为参数传递的时候使用引用，这是cpp类对象传递的标准方式。</font>


## 5. 堆和栈的区别
1. **申请方式不同**：
栈由系统自动分配；
堆是自己申请和释放的。
2. **申请大小限制不同**：
栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定（可以通过 `ulimit -a` 查看，由 `ulimit -s` 修改）；堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。【栈空间默认是4M，堆区一般是 1G - 4G】
3. **申请效率不同**：
栈由系统分配，速度快，不会有碎片；
堆由程序员分配，速度慢，且会有碎片。
4. **使用方法不同**：堆一般是底层用` malloc `通过` brk() `系统调用从堆分配内存；栈一般就是直接定义，就是分配，简单的 `esp, ebp` 指针的移动。
5. **存放内容不同**：堆一般是在堆的头部用一个字节存放堆的大小，具体内容由程序员安排；栈在函数调用时第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址然后是函数的各个参数，在大多数的 C 编译器中，**参数是由右往左入栈（占位符确定参数个数）**，然后是函数中的局部变量。
【[http://t.csdnimg.cn/b0Tcu](http://t.csdnimg.cn/b0Tcu)】
6. 栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了**栈的效率比较高**。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。
7. 堆地址向上生长（低到高），栈地址向下生长（高到低），因为计算机总是先从低地址开始读，所以，栈先进后出，堆先进先出。


[http://t.csdnimg.cn/sV3N5](http://t.csdnimg.cn/sV3N5)

## 6.区别指针类型
	int *p[10]
	int (*p)[10]
	int *p(int)
	int (*p)(int)

1. `int *p[10]`表示指针数组，强调数组概念，是一数组变量，数组大小为 10，数组内每个元素都是指向 `int` 类型的指针变量（一个有十个指针的数组）。
1. `int (*p)[10]`表示数组指针，强调是指针，只有一个变量，是指针类型，不过指向的是一个 `int` 类型的数组，这个数组大小是10（一个指向有十个整型数据数组的指针）。
1. `int *p(int)`是函数声明，函数名是 `p`，参数是 `int` 类型的，返回值是`int *`类型的。
1. `int (*p)(int)`是函数指针，强调是指针，该指针指向的函数具有 `int` 类型参数，并且返回值是 `int` 类型的。

**指针函数与函数指针：**

- **指针函数**：本质是一个函数，不过它的返回值是一个指针。【`ret *func(args, ...);`--`func` 是一个函数，`args` 是形参列表，`ret *` 作为一个整体，是 `func` 函数的返回值，是一个指针的形式。】
- **函数指针**：本质是一个指针，该指针的地址指向了一个函数，所以它是指向函数的指针。函数的定义是存在于代码段，因此，每个函数在代码段中，也有着自己的入口地址，函数指针就是指向代码段中函数入口地址的指针。【`ret (*p)(args, ...);` —`ret` 为返回值，`*p`作为一个整体，代表的是指向该函数的指针，`args` 为形参列表。其中`p`被称为函数指针变量 】


[http://t.csdnimg.cn/ItQSC](http://t.csdnimg.cn/ItQSC)


## 7.new/delete 与 malloc/free 的异同
- 相同点：都可用于内存的动态申请和释放；
- 不同点：
	- 前者是 C++ 运算符，后者是 C/C++ 语言标准库函数；
	- new 自动计算要分配的空间大小，malloc 需要手动计算；
	- new 是类型安全的，malloc不是。
	- new 调用名为 `operator new` 的标准库函数分配足够空间并调用相关对象的构造函数，delete 对指针所指对象运行适当的析构函数；然后通过调用名为`operator delete` 的标准库函数释放该对象所用内存。后者均没有相关调用；
	- 后者需要库文件支持，前者不用；
	- new 是封装了 malloc，直接 free 不会报错，但是这只是释放内存，而不会析构对象。
	- malloc 和 free 返回的是 void 类型指针(必须进行类型转换)，new 和 delete 返回的是具体类型指针。

**new 的实现过程**：首先调用名为 `operator new` 的标准库函数，分配足够大的原始为类型化的内存，以保存指定类型的一个对象；接下来运行该类型的一个构造函数，用指定初始化构造对象；最后返回指向新分配并构造后的的对象的指针。

**delete 的实现过程**：对指针指向的对象运行适当的析构函数，然后通过调用名为 `operator delete` 的标准库函数释放该对象所用内存。

## 8.malloc/free和new/delete释放后的内存系统会马上回收吗？
用户 `free` 掉的内存并不是都会马上归还给系统，`ptmalloc` 会统一管理 `heap` 和 `mmap` 映射区域中的空闲的 `chunk`，当用户进行下一次分配请求时，`ptmalloc` 会首先试图在空闲的 `chunk` 中挑选一块给用户，这样就避免了频繁的系统调用，降低了内存分配的开销。

`ptmalloc` 将相似大小的 `chunk` 用双向链表链接起来，这样的一个链表被称为一个 bin。`ptmalloc` 一共维护了 128 个 bin，并使用一个数组来存储这些 bin。

内存管理一般会有一个`free block list`，`free` 掉的东西就放在这里来，这里会尝试合并这些散乱的 `block`，而 `malloc` 首先找的也是` free block list`，而非从OS申请新的内存。【碎片问题：页大小固定，避免小内存一直分配，占据不同的页】

[http://t.csdnimg.cn/tjySr](http://t.csdnimg.cn/tjySr)


## 9.宏定义和函数有何区别？
- 宏在预处理阶段完成替换，之后被替换的文本参与编译，相当于**直接插入**了代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数；
- 宏定义属于在结构中插入代码，**没有返回值**；函数调用具有返回值；
- 宏定义**参数没有类型**，不进行类型检查；函数参数具有类型，需要检查类型；
- 宏定义不要在最后加分号。

## 10.宏定义 和 typedef 区别?
- 宏主要用于定义常量及书写复杂的内容；`typedef` 主要用于定义类型别名；
- 宏替换发生在编译阶段之前，属于文本插入替换；`typedef` 是编译的一部分；
- 宏不检查类型；typedef会检查数据类型；
- 宏不是语句，不在在最后加分号；typedef是语句，要加分号标识结束；

注意对指针的操作，`typedef char*p_char`和`#define p_char char *`区别巨大：

	typedef (int*)  pINT;
	#define pINT2 int*

效果相同？实则不同！实践中见差别：`pINT a,b;`的效果同`int *a; int *b;`表示定义了两个整型指针变量；而`pINT2 a,b;`的效果同`int *a, b;`表示定义了一个整型指针变量 a 和整型变量 b。


## 11.变量声明和定义区别?
- 声明仅仅是把变量的声明的位置及类型提供给编译器，并不分配内存空间；定义要在定义的地方为其**分配存储空间**。
- 相同变量可以在**多处声明**(外部变量 `extern`)，但只能在**一处定义**。


## 12.strlen 和 sizeof 区别?
- `sizeof` 是运算符，并不是函数，结果在编译时得到而非运行中获得；`strlen` 是字符处理的库函数；
- `sizeof` 参数可以是任何数据的类型或者数据(`sizeof` 参数不退化)；`strlen` 的参数只能是字符指针且结尾是`\0'`的字符串；
- 因为 `sizeof` 值在编译时确定，所以不能用来得到动态分配(运行时分配)存储空间的大小。

## 13.常量指针和指针常量区别?
- **指针常量**：是一个指针，读成常量的指针，指向一个只读变量，也就是后面所指明的`int const `和 `const int`，都是一个常量，可以写作 `int const *p` 或 `const int *p`；【**不能够通过指针修改内存数据**。只能防止通过指针引用修改内存中的数据，并不保护指针所指向的对象】
- **常量指针**：是一个不能改变指向的指针。指针是个常量，必须初始化，一旦初始化完成，它的值(也就是存放在指针中的地址)就不能在改变了，即不能中途改变指向，如`int *const p`。【**指针所指向的位置不能改变**，即指针本身是一个常量，但是指针所指向的内容可以改变。】

<font color="#F100">【以*为中间划一条线，看const修饰谁就谁就是常量。】</font>

[http://t.csdnimg.cn/q3F0U](http://t.csdnimg.cn/q3F0U)


## 14.C 语言和 C++ 的区别

1. **过程**：*C 编程语言不支持面向对象编程。因此，它不允许多态性、继承等。作为一种面向对象的语言，C++ 支持多态性和继承。*
2. **安全性**：*由于 C 语言不允许封装，数据变得可访问，其他实体可以破坏它。然而，C++ 支持封装，可以保护数据结构并根据需要使用它。*
3. **方法**：*C 编程语言鼓励自顶向下的方法，首先定义一个通用问题，然后将其分解为较小的任务。另一方面，C++ 鼓励自底向上的方法。这涉及首先识别和定义类，然后使用它们执行最初的任务。*
4. **输入/输出函数**：在 C 中，I/O 操作主要通过 C 标准库的标准 I/O 函数进行处理，如 printf() 和 scanf()。这些函数提供基本的格式化和读取功能，但缺少 C++ 中的一些高级功能；另一方面，C++ 通过使用 iostream 库中的对象扩展了 I/O 功能，这些对象称为**标准 I/O 流**。cout 流允许进行简单而灵活的输出操作，而 cin 流提供了增强的输入功能。C++ 流支持运算符重载，可方便地输出复杂数据类型并启用自定义格式选项。
5. **重载和覆盖**：方法覆盖允许子类重新定义从其祖先继承的函数。重载允许同一个函数有多个版本，每个版本具有唯一的参数。C 不支持这两者，但 C++ 支持。
6. **内存分配**：*C 编程依赖于两个关键函数——`calloc()`和`malloc()`——用于内存分配。相应的 free() 函数用于内存释放。C++使用new运算符进行动态内存分配，使用delete运算符进行释放。*
7. **编译**：C 和 C++ 的软件开发始于编写源代码。C文件的源代码具有`.c`扩展名，而 C++ 使用扩展名如`.cpp`或`.cxx`。这些源代码文件包含程序的指令和逻辑。


8. **变量**：通常，C编程语言使用两种类型的值：字面值和变量。C使用四种基本的变量类型：int、float、char和double。C++的主要变量类型包括bool、void和wchar_t。

9. **特点**：C编程语言是一种过程式、快速和高效的语言，具有模块化和丰富的内置运算符。与C不同，C++是一种过程式语言，具有OOP。此外，它是机器无关的、简单的和区分大小写的。
10. 在C++中，除了值和指针之外，**新增了引用**。引用型变量是其他变量的一个别名，我们可以认为他们只是名字不相同，其他都是相同的。

11. C++中的`try/catch/throw`异常处理机制取代了标准C中的`setjmp()`和`longjmp()`函数。

C编程语言是一种中级语言，而C++是一种高级语言。



[http://t.csdnimg.cn/X7tM2](http://t.csdnimg.cn/X7tM2)


## 15.C++中 struct 和 class 的区别？
相同点：

1. 两者都拥有成员函数、公有和私有部分；
1. 任何可以使用class完成的工作，同样可以使用struct完成。

不同点：

1. 两者中如果不对成员不指定公私有，struct默认是公有的，class则默认是私有的；
2. class默认是private继承，而struct默认是public继承；
3. class 可以使用模板，而 struct 不能；


**引申：C++和C的struct区别**

- C 语言中：struct 是用户自定义数据类型(UDT)；C++中 struct 是抽象数据类型(ADT)，支持成员函数的定义，(**C++中的 struct 能继承，能实现多态**)
- C 中 struct 是没有权限的设置的，且 struct 中只能是一些变量的集合体，可以封装数据却不可以隐藏数据，而且**成员不可以是函数**；C++中，struct 增加了访问权限，且可以和类一样有成员函数，成员默认访问说明符为public(为了与C兼容)；
- struct 作为类的一种特例是用来自定义数据结构的。一个结构标记声明后，在C中**必须在结构标记前加上struct**，才能做结构类型名(除:typedef struct class0;)；C++中结构体标记(结构体名)可以**直接作为结构体类型名使用**，此外结构体 struct 在C++ 中被当作类的一种特例；


[https://www.cnblogs.com/banluxinshou/p/11823158.html](https://www.cnblogs.com/banluxinshou/p/11823158.html)


## 16.define宏定义和const的区别？
角度1： 就定义常量说的话， const 定义的常数是**变量 也带类型**， #define 定义的只是个**常数 不带类型**。

角度2： 就起作用的阶段而言，#define 是在编译的**预处理阶段**起作用，而 const 是在 **编译、运行**的时候起作用。

角度3： 就起作用的方式而言，#define 只是简单的字符串替换，没有类型检查。而 const 有对应的数据类型，是要进行判断的，可以避免一些低级的错误。 正因为 define 只是简单的字符串替换会导致边界效应，具体举例可以参考下面代码：

	#define N 2+3     // 我们预想的 N 值是 5，我们这样使用 
	Ndouble a = N/2;  // 我们预想的  a 的值是 2.5，可实际上 a 的值是 3.5
角度4： 就空间占用而言， 例如：

	#define PI 3.14     //预处理后 占用代码段空间
	const float PI=3.14;    // 本质上还是一个 float，占用数据段空间

角度5： 从代码**调试**的方便程度而言, const 常量可以进行调试的，#define 是不能进行调试的，因为在预编译阶段就已经替换掉了

角度6： 从是否可以再定义的角度而言，const 不足的地方，是与生俱来的，**const 不能重定义**，而 #define 可以通过 #undef 取消某个符号的定义，再重新定义；【[const定义的对象属性可以改变](https://blog.csdn.net/Ain_z/article/details/109634087)】

[https://www.runoob.com/note/12963](https://www.runoob.com/note/12963)


## 17.C++ 中 const 和 static 的作用？
static

不考虑类的情况：

- 隐藏。所有不加 static 的全局变量和函数具有全局可见性，可以在其他文件中使用，**加了之后只能在该文件所在的编译模块中使用**；
- 默认**初始化为0**，包括未初始化的全局静态变量与局部静态变量，都存在**全局未初始化区**；
- 静态变量在函数内定义，**始终存在，且只进行一次初始化**，具有记忆性，其作用范围0与局部变量相同，函数退出后仍然存在，但不能使用

考虑类的情况：

- static 成员变量：**只与类关联**，不与类的对象关联。**定义时要分配空间，不能在类声明中初始化**，必须在类定义体外部初始化，**初始化时不需要标示为static**；可以被非static成员函数任意访问。
- static 成员函数：不具有this指针，无法访问类对象的非static成员变量和非static成员函数；不能被声明为const、虚函数和volatile；可以被非static成员函数任意访问；


const

不考虑类的情况：

- const 常量在定义时必须初始化，之后无法更改；
- const 形参可以接收 const 和非 const 类型的实参，例如//i可以是int 型或者 const int型void fun(const int& i){ //...}

考虑类的情况：

- const成员变量：不能在类定义外部初始化，只能通过构造函数初始化列表进行初始化，并且必须有构造函数；不同类对其const数据成员的值可以不同，所以不能在类中声明时初始化；
- const成员函数：const 对象不可以调用非 const 成员函数；非const对象都可以调用；不可以改变非 `mutable`(用该关键字声明的变量**可以在const成员函数中被修改)数据的值**）。


<font color="#A100">

const 定义的常量在超出其作用域之后其空间会被释放，而static 定义的静态常量在函数执行后不会释放其存储空间。</font>


类里的static cosnt 和 const static成员初始化：它们的初始化没有区别，虽然一个是静态常量一个是常量静态。静态都将存储在全局变量区域，其实最后结果都一样。可能在不同编译器内，不同处理，但最后结果都一样。  

[https://www.cnblogs.com/phpzhou/p/6390869.html](https://www.cnblogs.com/phpzhou/p/6390869.html)


## 18.C++的顶层 const 和底层 const?
**顶层const**：指的是 `const` 修饰的变量本身是一个常量，无法修改，指的是指针，就是`*`号的右边；

**底层const**：指的是 `const` 修饰的变量所指向的对象是一个常量，指的是所指变量，就是号的左边；

	int a = 10;int* const b1 = &a;        //顶层const，b1本身是一个常量
	const int* b2 = &a;       //底层const，b2本身可变，所指的对象是常量
	const int b3 = 20; 		   //顶层const，b3是常量不可变
	const int* const b4 = &a;  //前一个const为底层，后一个为顶层，b4不可变
	const int& b5 = a;		   //用于声明引用变量，都是底层const

- 如果 const 右结合修饰的为 `类型` 或者 `*`，那这个 const 就是一个底层 const；
- 如果 const 右结合修饰的为 `标识符`，那这个 const 就是一个顶层 const。

主要区别：

- 被修饰的变量本身无法改变的 const 是顶层 const；
- 通过指针或引用等间接途径来限制目标内容不可变的 const 是底层 const。

顶层 const 表示指针本身（对象值）是个常量；
底层 const 表示指针所指的对象（地址）是一个常量。

## 19.数组名和指针(这里为指向数组首元素的指针)区别?
- 二者均可通过**增减偏移量来访问**数组中的元素；
- 数组名不是真正意义上的指针，可以理解为常量指针，所以数组名没有自增、自减等操作；指针是变量指针；
- **当数组名当做形参传递给调用函数后，就失去了原有特性，退化成一般指针，多了自增、自减操作，但 sizeof 运算符不能再得到原数组的大小了**。

## 20.final 和 override 关键字
`final` 和 `override` 是C++11标准引入的两个关键字，它们为类的继承和多态机制提供了更多的控制权和明确性。

- `final` 关键字用于指示一个类或成员函数是最终的，**不能被继承或覆盖**，可以保护基类不被修改，防止滥用继承；
- `override` 关键字用于**明确指出**派生类中的成员函数旨在覆盖基类中的同名虚拟函数，并进行编译时类型检查。


## 21.拷贝初始化和直接初始化
- 如果**使用等号（=）**初始化一个变量，实际上执行的是“**拷贝初始化**”，编译器把等号右侧的初始值拷贝到新创建的对象中去。
- 与之相反，如果**不使用等号**，则执行的是“**直接初始化**”；

直接初始化实际上是要求编译器使用普通的函数匹配来选择与我们提供的参数最匹配的构造函数；

拷贝初始化实际上是要求编译器将右侧运算对象拷贝到正在创建的对象中，通常用拷贝构造函数来完成；

**拷贝构造函数的形参必须是引用类型**的原因：如果不是引用类型，为了调用拷贝构造函数，我们必须拷贝它的实参，但为了拷贝实参，我们又需要调用拷贝构造函数，如此无限循环，造成错误。

使用 `explicit` 修饰构造函数时：如果构造函数存在隐式转换，编译时会报错

[https://blog.csdn.net/capecape/article/details/78276677](https://blog.csdn.net/capecape/article/details/78276677)


## 22.C++初始化与赋值的区别
初始化不是赋值，初始化的含义是在创建对象时赋予一个初值，而赋值是将对象的当前值擦除掉，以一个新值代替。

[http://t.csdnimg.cn/sBvrQ](http://t.csdnimg.cn/sBvrQ)

## 23.extern"C" 的用法
`extern "c" ` 的主要作用就是为了**能够正确实现 C++ 代码调用其他 C 语言代码**。加上 `extern “c”` 后，会指示**编译器这部分的代码按C语言，而不是C++的方式进行编译**。


由于C++支持函数重载，因**此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名**；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。


**extern "C"使用要点**：

- 可以是单一语句：`extern “C” double sqrt(double);`
- 可以是复合语句，相当于复合语句中的声明都加了 `extern “C”`：`extern “C”{ double sqrt(double); int min(int, int);}`
- 可以包含头文件，相当于头文件中的声明都加了extern “C” ：`extern “C”{＃include <cmath> }`
- 不可以将 extern “C” 添加在函数内部;
- 如果函数有多个声明，可以都加 extern “C”, 也可以只出现在第一次声明中，后面的声明会接受第一个链接指示符的规则。


## 24.野指针和悬空指针
- **野指针**：指针变量未及时初始化 => 定义指针变量及时初始化，要么置空；
- **悬空指针**：指针 free 或 delete 之后没有及时置空  => 释放操作后立即置空；

C++智能指针的本质就是避免悬空指针的产生。

## 25.C 和 C++ 的类型安全？
类型安全很大程度上可以等价于内存安全，**类型安全的代码不会试图访问自己没被授权的内存区域**。

<font color="#F100">**类型安全**是指同一段内存在不同的地方，会被强制要求使用相同的办法来解释(内存中的数据是用类型来解释的)。</font>

C 只在局部上下文中表现出类型安全；因为同一段内存可以用不同的数据类型来解释，比如1用int来解释就是1，用boolean来解释就是true。

如果C++使用得当，它将远比C更有类型安全性。相比于C，C++提供了一些新的机制保障类型安全：

- 操作符new返回的指针类型严格与对象匹配，而不是void*；
- C中很多以void*为参数的函数可以改写为C++模板函数，而模板是支持类型检查的；
- 引入const关键字代替#define constants，它是有类型、有作用域的，而#define constants只是简单的文本替换；
- 一些#define宏可被改写为inline函数，结合函数的重载，可在类型安全的前提下支持多种类型，当然改写为模板也能保证类型安全；
- C++提供了dynamic_cast关键字，使得转换过程更加安全，因为dynamic_cast比static_cast涉及更多具体的类型检查。


Java语言是类型安全的，除非强制类型转换。

[http://t.csdnimg.cn/AlWSs](http://t.csdnimg.cn/AlWSs)


## 26.C++中的重载、重写(覆盖)和隐藏的区别？
**重载**：是指同一可访问区内被声明的几个具有不同参数列（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，**重载不关心函数返回类型**。

**隐藏**：是指派生类的函数屏蔽了与其同名的基类函数，注意**只要同名函数，不管参数列表是否相同，基类函数都会被隐藏**。

**重写(覆盖)**：是指派生类中存在重新定义的函数。其**函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致**。**只有函数体不同**（花括号内），派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有 `virtual` 修饰，派生类可以没有。


## 27.C++有哪几种的构造函数
通常 C++中的构造函数可以分为5类：默认构造函数、普通构造函数、拷贝构造函数、转换构造函数、移动构造函数。

- **默认构造函数**：未提供显式初始值时，用来创建对象的构造函数`Student();//没有参数`；
- **普通构造函数**：C++用于构建类的新对象时需要调用的函数`Student(int num，int age）;//有参数`；
- **拷贝构造函数**：何时生成默认的拷贝构造函数；
- **转换构造函数**：一个构造函数接收一个不同于其类类型的形参，可以视为将其形参转换成类的一个对象【string 类中可以找到使用转换构造函数的实用示例】；
- **移动构造函数**：以移动而非深拷贝的方式初始化含有指针成员的类对象。简单的理解，移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”。


委托构造函数是C++11引入的一个特性，它**允许一个构造函数调用同一类的另一个构造函数**，从而避免在类内部出现相似的初始化代码，提高代码的可维护性。在构造函数的初始化列表中使用` : `符号，可以调用同一类中的其他构造函数。

委托构造函数的调用必须出现在构造函数的初始化列表中。在构造函数主体中调用其他构造函数是不允许的。

## 28.浅拷贝和深拷贝的区别
**浅拷贝**：浅拷贝只是拷贝一个指针，并没有新开辟一个地址，拷贝的指针和原来的指针指向同一块地址，**如果原来的指针所指向的资源释放了，我那么再释放浅拷贝的指针的资源就会出现错误**。

**深拷贝**：**深拷贝不仅拷贝值，还开辟出一块新的空间用来存放新的值**，即使原先的对象被析构掉，释放内存了也不会影响到深拷贝得到的值。在自己实现拷贝赋值的时候，如果有指针变量的话是需要自己实现深拷贝的。

深拷贝和浅拷贝是指在赋值一个对象时，拷贝的深度不同。 在进行深拷贝时，会拷贝所有的属性，并且如果这些属性是对象，也会对这些对象进行深拷贝，直到最底层的基本数据类型为止。

## 29.内联函数和宏定义的区别
**宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的**。

而且**内联函数是真正的函数**，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销。

**内联函数有类型检测、语法判断等功能，而宏没有。**


## 30.public, protected 和 private 访问和继承权限 /public/protected/private 的区别?
**访问权限：**

- public:可以被任意实体访问；
- protected:只允许子类及本类的成员函数访问；
- private:只允许本类的成员函数访问；

**继承：**

1. public 继承不改变基类成员的访问权限；
2. private 继承使得基类所有成员在子类中的访问权限变为 private；
3. protected 继承将基类中public成员变为子类的protected成员，其它成员的访问 权限不变；
4. 基类中的 private 成员不受继承方式的影响，子类永远无权访问。


友元是一种**定义在类外部的普通函数，但它需要在类体内进行声明**，为了与该类的成员函数加以区别，在声明时前面加以关键字 `friend`。友元不是成员函数，但是它可以访问类中的私有成员。友元的作用在于提高程序的运行效率，但是，它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的私有成员。

[【C++】友元函数和友元类（作用及优缺点）](http://t.csdnimg.cn/ThyG8)

## 31.如何用代码判断大小端存储？
- **大端存储**：是指数据的低位保存在内存的高地址中，而数据的高位保存在内存的低地址中；
- **小端存储**：是指数据的低位保存在内存的低地址中，而数据的高位保存在内存的高地址中。

<font color="#F100">想办法取出一个字节的内容，就可以知道是哪种存储方式。</font>

初始化一个 `16 进制` 的int型的数据，然后把它放在一个 `char` 类型的数组中，由于**十六进制的数据一位代表四个bit位**；`char` 型是8个bit位，那么十六进制的两位占一个 `char` 位，那么就可以把数据位分离。

**方法一：直接法**

	int main()
	{
		int a = 0x12345678;
		char i = a;
		printf("%x", i);
	}
定义一个十六进制的数据，数据类型为int型，之后定义一个char类型的数据，**int数据类型的大小为四个字节，而char类型的数据为一个字节，所以将int类型的数据赋值给char时会丢失三个字节的数据，char类型中存储的是int类型中低地址的数据**，这时候char类型获取的数据输出之后，如果输出的是12那就说明你低地址位置的数据是12，那就说明你的数据是大端存储，如果输出的结果是78那当前条件下就是小端存储。

**方法二：指针法**

	int main()
	{
	    int i = 0x1122;
		char* p = (char*)& i;
		if (p[0] == 0x22 && p[1] == 0x11) {
			cout << "little endian" << endl;
		}
		else if (p[0] == 0x11 && p[1] == 0x22) {
			cout << "big endian" << endl;
		}
	}

`*p`就是`p[0]`，把变量的地址强制类型转换为`char*`，这样就可以每次取出一个字节的内容，因为 `char` 的大小就是1个字节，`p[0]`和`p[1]`都表示一个 `char` 类型。

将`int*`类型的` &i`强制转换为了`char*`类型，但值没有改变（地址）；地址存储的值也未改变，`p` 就是表示的这个地址，但 `p` 是 `char*` 类型的变量，因此可以用`p[0]p[1]`去取，每一个`p[]`就是两个十六进制的数（也就是一个字节）。`p[0]`就是`0x22`, `p[1]`就是`0x11`。

**方法三：联合体法**

	int main(){
		union
		{
			int value;
			char union_bytes[ sizeof(int) ];
		} test;
		test.value = 0x0102;
		if (  ( test.union_bytes[ 0 ] == 1 ) && ( test.union_bytes[ 1 ] == 2 ) )
		{
			printf( "big endian\n" );
		}
		else if ( ( test.union_bytes[ 0 ] == 2 ) && ( test.union_bytes[ 1 ] == 1 ) )
		{
			printf( "little endian\n" );
		}
		else
		{
			printf( "unknown...\n" );
		}
	}
在联合体中定义一个 char 类型的变量和 int 类型的变量，利用二者所占同一段存储空间，可以通过引用联合体变量中的成员访问 `char`  类型的数据，取出一个字节的内容。

**在 `union` 中所有的数据成员共用一个空间**，而且是**从低位开始占用**，同一时间只能储存其中一个数据成员，所有的数据成员具有相同的起始地址，**共用体变量的内存空间大小是该变量中某个占用空间最大的那个成员所占的空间**。。

即上述的union虽然定义了两个成员，但其实这个union只占用了4个字节(32位机器中 int 所占的空间大小)，往 value 成员赋值（value完整是0x00000102），然后读取 union_bytes ，union_bytes[0]就是value的第一个字节，union_bytes[1]就是value的第二个字节。

[http://t.csdnimg.cn/lm2iI](http://t.csdnimg.cn/lm2iI)


## 32.volatile、mutable 和 explicit 关键字的用法？
volatile 关键字是一种类型修饰符，用它声明的类型变量**表示可以被某些编译器未知的因素更改**。

<font color="#F100">当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。</font>


volatile 定义变量的值是易变的，每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份。

多线程中被几个任务共享的变量需要定义为 volatile 类型。


volatile 限定符的用法和 const 很相似，它起到对类型额外修饰的作用；const 和volatile 限定符互相没什么影响，**某种类型可能既是 const 的也是 volatile 的**，此时它同时具有二者的属性。

只有 `volatile` 的成员函数才能被 `volatile` 的对象调用。

可以把一个非 volatile in t赋给 volatile int，但是不能把非 volatile 对象赋给一个volatile对象。

**mutable**

- 用 const 修饰的成员函数时，**const修饰this指针指向的内存区域，成员函数体内不可以修改本类中的任何普通成员变量**，当成员变量类型符前用 `mutable` 修饰时例外。

-  常对象可访问 const 或非 const 数据成员，不能修改，除非成员用mutable修饰；


> 常函数不能对普通成员变量（除mutable修饰外）进行写操作 ；
> 常函数可以被普通对象或者常对象调用；
> 
> 常对象不能调用所有普通函数，只能调用常函数；
> 常对象可以读成员变量；
> 
> [http://t.csdnimg.cn/pOfDm](http://t.csdnimg.cn/pOfDm)


**explicit**

c++ 提供了关键字 `explicit`，禁止通过构造函数进行的隐式转换。声明为 `explicit` 的构造函数不能在隐式转换中使用。

- 是针对**单参数**的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造)而言，需要多个实参的构造函数不能用于执行隐式转换，所以无需将这些构造函数指定为explicit。
-  explicit用于修饰构造函数，防止隐式转化。




[https://www.cnblogs.com/codemagiciant/p/17524184.html](https://www.cnblogs.com/codemagiciant/p/17524184.html)


## 33.什么情况下会调用拷贝构造函数？
拷贝构造函数是一种特殊的构造函数，它在创建对象时，是**使用同一类中之前创建的对象来初始化新创建的对象**。拷贝构造函数通常用于：

- 通过使用另一个同类型的对象来初始化新创建的对象；
- 复制对象把它作为参数传递给函数；
- 复制对象，并从函数返回这个对象；

如果在类中没有定义拷贝构造函数，编译器会自行定义一个。如果类带有指针变量，并有动态内存分配，则它必须有一个拷贝构造函数。

## 34.C++中有几种类型的new（plain new\nothrow new\placement new)

**1. plain new**

言下之意就是普通的 `new`，就是我们常用的 `new`；

在C++中定义如下：

	void* operator new(std::size_t) throw(std::bad_alloc);
	void operator delete(void *) throw();
	Copy to clipboardErrorCopied
因此 plain new 在空间分配失败的情况下，抛出异常`std::bad_alloc`而不是返回 `NULL`，因此通过判断返回值是否为 `NULL` 是徒劳的。

**2.nothrow new**

	char *p = new(nothrow) char[10e11];
`nothrow new `在空间分配失败的情况下是不抛出异常，而是返回 `NULL`；


**3.placement new**

    ADT *q = new(p) ADT;
这种 new **允许在一块已经分配成功的内存上重新构造对象或对象数组。** `placement new`不用担心内存分配失败，因为它根本不分配内存，它做的唯一一件事情就是调用对象的构造函数。

	void* operator new(size_t,void*);
	void operator delete(void*,void*);
	Copy to clipboardErrorCopied

`palcement new` 的主要用途就是反复使用一块较大的动态分配的内存来构造不同类型的对象或者他们的数组；

`placement new`构造起来的对象数组，要显式的调用他们的析构函数来销毁（析构函数并不释放对象的内存），千万不要使用delete，这是因为`placement new`构造起来的对象或数组大小并不一定等于原来分配的内存大小，使用delete会造成内存泄漏或者之后释放内存时出现运行时错误。


## 35.C++的异常处理的方法
- try、throw 和 catch 关键字`try...(throw)...catch...`；
- 函数的异常声明列表：在定义函数的时候知道函数可能发生的异常，可以在函数声明和定义时，指出所能抛出异常的列表`int fun() throw(int,double,A,B,C) {...};`
这种写法表名函数可能会抛出 `int,double` 型或者A、B、C三种类型的异常，如果 `throw` 中为空表明不会抛出任何异常，如果没有 `throw` 则可能抛出任何异常【在C++11这种做法已经被摒弃，而后者则被C++11的 noexcept （noexcept 的一个作用是**阻止异常的传播，提高安全性**）异常声明所代替：`void func() noexcept {...}//等价于void func() throw(){...}`】；
- C++标准异常类 `exception`：C++标准提供了一组标准异常类，这些类以基类 Exception 开始，标准程序库抛出的所有异常，都派生于该基类，该基类提供一个成员函数 what()，用于返回错误信息（返回类型为 const char*）。

【析构函数默认也是noexcept的】

[https://www.cnblogs.com/QG-whz/p/5136883.html](https://www.cnblogs.com/QG-whz/p/5136883.html)
[https://www.cnblogs.com/suozhiyuan/p/12528891.html#_label0](https://www.cnblogs.com/suozhiyuan/p/12528891.html#_label0)

## 36.值传递、指针传递、引用传递的区别和效率

**传值**： 函数参数压栈的是参数的副本。  
任何的修改是在副本上作用，没有作用在原来的变量上。  

**传指针**：压栈的是指针变量的副本。    
当你对指针解指针操作时，其值是指向原来的那个变量，所以**对原来变量操作**。  

**传引用**：压栈的是引用的副本。由于引用是指向某个变量的，对引用的操作其实就是**对他指向的变量的操作**。

**传递效率上**： 调用被调函数的代码将实参传递到被调函数体内的过程。 
指针传递和引用传递比值传递效率高。一般主张使用引用传递，代码逻辑上更加紧凑、清晰。 

**执行效率上**：在被调用的函数体内执行时的效率。    
因为传值调用时，当值被传到函数体内，临时对象生成以后，所有的执行任务都是通过**直接寻址**的方式执行的，而指针和大多数情况下的引用则是以**间接寻址**的方式执行的，所以实际的执行效率会比传值调用要低；如果函数体内对参数传过来的变量进行操作比较频繁，执行总次数又多的情况下，传址调用和大多数情况下的引用参数传递会造成比较明显的执行效率损失。

[https://www.cnblogs.com/ywliao/articles/8127531.html](https://www.cnblogs.com/ywliao/articles/8127531.html)

## 37.C++ 全局变量和 static 变量初始化问题
- 全局变量、文件域中的静态变量、类中的成员静态变量在 main 函数执行前初始化；局部变量中的静态变量在第一次调用时初始化。


**在 C 语言中是编译期初始化并分配内存**，故不能用变量给静态局部变量赋值，只能用常量。

**在C++中是第一次执行时初始化**，因为 C++ 引入了对象的概念，对象一般需要构造函数，无法简单的分配内存，故可以用变量赋值，并且在**第一次使用时初始化**。


- 初始化顺序：对于编译单元（同一个文件）的全局变量来讲，初始化顺序跟声明的顺序一致。销毁顺序则相反。
对于不同编译单元的全局变量，初始化顺序不确定。对于不同编译单元的全局变量互相引用的情况应避免。

解决不同文件相互引用全局变量初始化顺序不确定问题：可以通过函数调用，引用的时候不直接引用全局变量，而是放在一个函数中。**函数中的全局变量在调用时初始化**。


**类的静态成员变量声明和定义**   
静态成员变量不属于任何一个对象，对象的数据中不应该包含静态成员的数据。所以在**定义类的时候不会给静态变量分配内存只是声明**，因此就要在其他地方分配即定义。

> 定义与声明的区别  
**声明**：只是向程序表面变明的类型和名字。    
**定义**：为变量分配内存，也可以顺便初始化。程序中变量有且只有一个定义（更能说明为什么要在类外再定义下类的静态成员变量了）





## 38.new 和 malloc 的区别
1、 new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持；
2、使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算；而malloc则需要显式地指出所需内存的尺寸。  
3、 new 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 new 是符合类型安全性的操作符。而malloc内存分配成功则是返回`void*`需要**通过强制类型转换将`void*`指针转换成我们需要的类型**。  
4、new 内存分配失败时，会抛出 `bac_alloc` 异常。malloc分配内存失败时返回NULL。  
5、 new 会先调用`operator new`函数，申请足够的内存(通常底层使用malloc实现)。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete 先调用析构函数，然后调用operator delete函数释放内存(通常底层使用free实现)。malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做**自定义类型对象构造和析构工作**。


## 39.delete p、delete [] p、allocator都有什么作用?
- delete p是用于释放由 new 运算符分配的单个对象的内存。
- 如果使用 new[] 运算符创建了一个对象数组，那么应该使用delete [] p 来释放内存，而不是 delete p。【delete[] p是用于释放由`new[]`运算符分配的对象数组的内存。在释放内存时，delete[] p会**调用每个对象的析构函数**，然后释放整个数组的内存（delete[时，数组中的元素按**逆序**的顺序进行销毁）】。

- new在内存分配上面有一些局限性，new 的机制是将内存分配和对象构造组合在一起同样的，delete 也是将对象析构和内存释放组合在一起的。allocator 将这两部分分开进行， **allocator 申请一部分内存，不进行初始化对象**，只有当需要的时候才进行初始化操作。

[https://www.cnblogs.com/codemagiciant/p/17524217.html](https://www.cnblogs.com/codemagiciant/p/17524217.html)


allocator的主要作用如下：

1.**内存分配**：allocator负责为容器中的元素分配内存。它使用动态内存分配机制（如new和malloc）从堆上分配内存，并返回指向分配内存的指针。

2.**内存释放**：当元素被从容器中移除或容器被销毁时，allocator负责释放先前分配的内存。它使用delete和free等函数释放先前分配的内存。

3.**对象构造和析构**：allocator还负责在分配的内存空间中构造和析构对象。当新元素被添加到容器中时，allocator使用元素的构造函数来创建对象，并在元素被移除时调用析构函数来销毁对象。

4.**内存对齐**：allocator还负责按照特定的内存对齐方式来分配内存，以确保对象的起始地址满足对齐要求。这对于某些类型的对象（如带有对齐要求的结构体）非常重要。


## 40.new和delete的实现原理，delete是如何知道释放内存的大小的？
new 和 delete是用户进行动态内存申请和释放的操作符，operator new 和operator delete是系统提供的全局函数，new在底层调用operator new全局函数来申请空间，delete在底层通过operator delete全局函数来释放空间。

C++ 的做法是在分配数组空间时多分**配了4个字节的大小，专门保存数组的大小**，在 delete 时就可以取出这个保存的数，就知道了需要调用析构函数多少次了。



[http://t.csdnimg.cn/NX0dG](http://t.csdnimg.cn/NX0dG)


## 41.malloc、realloc、calloc的区别
malloc 申请的空间的值是随机初始化的；  
calloc 申请的空间的值是初始值为0；  
realloc 给动态分配的空间分配额外的空间，用于扩充容量。


## 42.malloc与free的实现原理?
`malloc` 小于`128k`的内存，使用 `brk` 分配内存，将「堆顶」指针往高地址推；`malloc` 大于 `128k` 的内存，使用 `mmap` 分配内存，在堆和之间找一块空闲内存分配；

**brk分配的内存需要等到高地址内存释放以后才能释放，而mmap分配的内存可以单独释放。** 

**malloc分配内存之后，只是分配了虚拟内存，还没有映射到物理内存，只有当访问申请的内存的时候，才会发生缺页中断，分配对应的物理内存**

当最高地址空间的空闲内存超过128K(可由M TRIM THRESHOLD选项调节)时，执行内存紧缩操作(trim)。【调用`sbrk(-size)`将内存归还操作系统】


[https://jacktang816.github.io/post/mallocandfree/](https://jacktang816.github.io/post/mallocandfree/)


## 43.类成员初始化方式？构造函数的执行顺序？为什么用成员初始化列表会快一些？
**赋值初始化**，通过在函数体内进行赋值初始化；  
**列表初始化**，在冒号后使用初始化列表进行初始化。

主要区别在于：  
<font color = blue>对于在函数体中初始化，是在所有的数据成员被分配内存空间后才进行的；  </font>
列表初始化是给数据成员分配内存空间时就进行初始化，就是说分配一个数据成员只要冒号后有此数据成员的赋值表达式(此表达式必须是括号赋值表达式)，那么分配了内存空间后在进入函数体之前给数据成员赋值，就是说**初始化这个数据成员此时函数体还未执行**。


一个派生类构造函数的执行顺序如下：  
① 虚拟基类的构造函数（多个虚拟基类则按照继承的顺序执行构造函数）；  
② 基类的构造函数（多个普通基类也按照继承的顺序执行构造函数）；  
③ 类类型的成员对象的构造函数（按照成员对象在类中的定义顺序）；  
④ 派生类自己的构造函数。


方法一是在构造函数当中做赋值的操作，而方法二是做纯粹的初始化操作。我们都知道，**C++的赋值操作是会产生临时对象的**。临时对象的出现会降低程序的效率。


## 44.有哪些情况必须用到成员列表初始化？作用是什么？
1.**必须使用成员初始化**的四种情况：  
① 当初始化一个引用成员时；  
② 当初始化一个常量成员时；  
③ 当调用一个基类的构造函数，而它拥有一组参数时；  
④ 当调用一个成员类的构造函数，而它拥有一组参数时；  

**成员初始化列表做了什么**：  
① 编译器会一一操作初始化列表，以适当的顺序在构造函数之内安插初始化操作，并且在任何显示用户代码之前；  
② list 中的项目顺序是**由类中的成员声明顺序决定**的，不是由初始化列表的顺序决定的。

## 45.C++中新增了string，它与C语言中的 char * 有什么区别吗？它是如何实现的？
string 继承自 `basic_string`，其实是对 `char* `进行了封装，封装的 string 包含了 `char*` 数组，容量长度等等属性。

`string` 可以进行动态扩展，在每次扩展的时候另外申请一块原空间大小两倍的空间 (`2*n`) 然后将原字符串拷贝过去，并加上新增的内容。


## 46.什么是内存泄露，如何检测与避免？
**内存泄露**  
一般我们常说的内存泄漏是指**堆内存的泄漏**。  
堆内存是指程序从堆中分配的，大小任意的（内存块的大小可以在程序运行期决定）内存块，使用完后必须显式释放的内存。应用程序般使用 malloc、realloc、new 等函数从堆中分配到块内存，
**使用完后，程序必须负责相应的调用 free 或 delete 释放该内存块，否则，这块内存就不能被再次使用，我们就说这块内存泄漏**。

避免内存泄露的几种方式  
计数法：使用 new 或者 malloc 时，让该数+1，delete 或 free 时，该数 -1，程序执行完打印这个计数，如果不为 0 则表示存在内存泄露；  
一定要将基类的析构函数声明为虚函数【否则不会调用派生类的析构函数，要能够保证继承关系中最高的基类的析构函数是虚的（具有传递性）】；  
对象数组的释放一定要用delete []；  
有 new 就有delete，有 malloc 就有 free，保证它们一定成对出现；

检测工具  
Linux下可以使用Valgrind工具；  
Windows下可以使用CRT库。

## 47.对象复用的了解，零拷贝的了解
**对象复用是指将已经创建的对象进行重复使用，而不是创建新的对象。**  

在面向对象编程中，对象复用可以通过以下几种方式实现：  
1.**对象池** ：对象池是一种常见的对象复用方式，它可以将已经创建的对象保存起来，并在需要时将其重新使用。  
2.**模板类和模板对象** ：模板类和模板对象可以将一些公共的行为封装在类和对象中，从而实现对象的复用。  
3.**类的成员变量** ：类的成员变量可以是类的实例对象，这样可以将对象的状态和行为保存在类的成员变量中，从而实现对象的复用。  
4.**对象的静态变量** ：对象的静态变量可以是类的实例对象，这样可以将对象的状态和行为保存在类的静态变量中，从而实现对象的复用。

**零拷贝是指在程序运行过程中，对对象的复制和初始化过程中，只复制对象的引用而不复制对象本身**。  
这样可以避免对象的内存分配和释放过程，从而提高程序的性能。零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。零拷贝技术可以减少数据拷贝和共享总线操作的次数。  
实现零拷贝的方法有多种，其中最常见的是使用**C++中的智能指针和垃圾回收器**。


## 48.介绍面向对象的三大特性，并且举例说明
**1.封装**  
C++中的封装是指将属性和方法包装在一个类中，并通过访问控制符来限制外部对类的访问。封装可以提高代码的可维护性和安全性，同时也可以实现多态性。


**2.继承**  
C++最重要的特征是代码重用，通过继承机制可以利用已有的数据类型来定义新的数据类型，新的类不仅拥有旧类的成员，还拥有新定义的成员。


**3.多态**
同一事物表现出不同事物的能力，即向不同对象发送同一消息，不同的对象在接收时会产生不同的行为（重载实现编译时多态，虚函数实现运行时多态）【允许将子类类型的指针赋值给父类类型的指针（向上转换）】。

实现多态有二种方式：覆盖（override），重载（overload）。

## 48.C++的四种强制转换 reinterpret_cast/const_cast/static_cast/dynamic_cast

**为什么C++需要四种类型转换？**  
**1.隐式转换缺点**：  

- 可能会导致数据精度丢失：当将一个数据类型转换为另一个数据类型时，可能会发生精度丢失，例如将一个浮点数转换为整数时，小数部分会被截断。
- 可能导致未定义行为：隐式转换可能会导致未定义行为，例如将一个指针类型转换为整数类型可能会导致未定义行为。
- 代码不够清晰：隐式转换可能会使代码不够清晰，因为它不需要在代码中明确地指定转换的类型。

【C++中提供了 `explicit` 关键字，在构造函数声明的时候加上 `explicit` 关键字，能够**禁止隐式转换**】


**2.显式转换缺点：**

- 可能会导致数据失真：当使用显式转换将一个数据类型转换为另一个数据类型时，可能会导致数据失真，例如将一个整数转换为浮点数时，小数部分可能会出现不准确的情况。
- 可能会导致代码不够清晰：显式转换需要程序员在代码中明确地指定转换的类型，这可能会使代码不够清晰，同时也增加了代码的复杂性。


C++中的类型转换包括**自动类型转换**、**强制类型转换**、**类型解析转换**和**类型推断转换**。

- **static_cast**（编译时类型检查）：`static_cast < type-id > ( expression )`，将 `expression` 转换为 `type-id` 类型。  
<font color = red>static_cast 是静态类型转换，发生在编译期。这种转换不会进行运行时的动态检查（RTTI），因而这种转换可能是不安全的。 </font>
- **const_cast**：`const_cast` 只能改变运算对象的**底层 const**，用来移除变量的 `const` 或 `volatile` 限定符。  
注意：`const_cast` 是不能用来执行任何类型的转换的，比如只能将 `const char* p` 转换成` char* p`，而不能转成 `int* p`。
- **reinterpret_cast**：`reinterpret_cast` 可以将指针类型任意转换，甚至是不相关的类之间（既不检查指针所指向的内容，也不检查指针类型本身）【旧式强制类型转换执行与reinterpret_cast类似的功能】；
- **dynamic_cast**：`dynamic_cast` 只能用于指向类的指针和引用(或void*)。它的目的是确保类型转换的结果指向目标指针类型的有效完整对象。  
`dynamic_cast` 主要用于类层次结构中父类和子类之间指针和引用的转换，由于具有运行时类型检查，因此可以保证下行转换的安全性（）

> 何为安全性？  
> 即转换成功就返回转换后的正确类型指针，如果转换失败，则返回NULL，之所以说static_cast在下行转换时不安全，是因为即使转换失败，它也不返回NULL。


C++中层次类型转换中无非两种：上行转换和下行转换

- 对于上行转换，`static_cast` 和 `dynamic_cast` 效果一样，都安全；
- 对于下行转换：你必须确定要转换的数据确实是目标类型的数据，即需要注意要转换的父类类型指针是否真的指向子类对象，如果是，`static_cast` 和 `dynamic_cast` 都能成功；如果不是 `static_cast` 能返回，但是不安全，可能会出现访问越界错误，而 `dynamic_cast` 在运行时类型检查过程中，判定该过程不能转换，返回NULL。



[https://www.cnblogs.com/codemagiciant/p/17544722.html](https://www.cnblogs.com/codemagiciant/p/17544722.html)

## 49.C++函数调用的压栈过程
1. 当函数从入口函数 `main` 函数开始执行时，编译器会将我们操作系统的运行状态，`main` 函数的返回地址、`main` 的参数、`mian` 函数中的变量、进行依次压栈；
2. 当 `main` 函数开始调用 `func()` 函数时，编译器此时会将 `main` 函数的运行状态进行压栈，再将 `func()` 函数的返回地址、`func()` 函数的参数从右到左、`func()`  定义变量依次压栈；
3. 当 `func()` 调用 `f()` 的时候，编译器此时会将 `func()` 函数的运行状态进行压栈，再将的返回地址 `f()` 函数的参数从右到左、`f()`定义变量依次压栈。

**函数的调用过程**  
1)从栈空间分配存储空间；  
2)从实参的存储空间复制值到形参栈空间；  
3)进行运算


## 50. 写 C++ 代码时有一类错误是 coredump，很常见，你遇到过吗？怎么调试这个错误？
coredump 是程序由于异常或者 bug 在运行时异常退出或者终止，在一定的条件下生成的一个叫做 core 的文件，这个 **core 文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等**。对这个文件进行分析**可以定位到程序异常的时候对应的堆栈调用信息**。

【使用gdb命令对core文件进行调试】：`gdb [可执行文件名] [core文件名]`


## 51.说说移动构造函数
移动构造是C++11标准中提供的一种新的构造方法。  

移动构造函数首先将传递参数的内存地址空间接管，然后将内部所有指针设置为 `nullptr`，并且在原地址上进行新对象的构造，最后调用原对象的的析构函数，这样做既不会产生额外的拷贝开销，也不会给新对象分配内存空间。即提高程序的执行效率，节省内存消耗。

移动构造函数的参数和拷贝构造函数不同，拷贝构造函数的参数是一个左值引用，但是**移动构造函数的初值是一个右值引用**。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只用用一个右值，或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个 **move 语句，就是将一个左值变成一个将亡值**。

> 何为左值？能用取址符号 & 取出地址的皆为左值，剩下的都是右值。
> std::move() 能把左值强制转换为右值。
> 【匿名变量一律属于右值】

[C++中的左值、纯右值、将亡值](https://www.cnblogs.com/zpcdbky/p/5275959.html)

[http://t.csdnimg.cn/zleoS](http://t.csdnimg.cn/zleoS)

## 52.C++中将临时变量作为返回值时的处理过程
首先需要明白一件事情，临时变量，在函数调用过程中是被压到程序进程的栈中的，**当函数退出时，临时变量出栈，即临时变量已经被销毁**，临时变量占用的**内存空间没有被清空，但是可以被分配给其他变量**，所以有可能在函数退出时，该内存已经被修改了，对于临时变量来说已经是没有意义的值了。  
函数调用结束后，**返回值被临时存储到寄存器中**，并没有放到堆或栈中，也就是说与内存没有关系了。当退出函数的时候，临时变量可能被销毁，但是返回值却被放到寄存器中与临时变量的生命周期没有关系。
如果我们需要返回值，一般使用赋值语句就可以了。

## 53.静态类型和动态类型，静态绑定和动态绑定的介绍
- **静态类型**：对象在声明时采用的类型，在编译期既已确定；
- **动态类型**：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的；
- **静态绑定**：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期；
- **动态绑定**：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期；

从上面的定义也可以看出，**非虚函数一般都是静态绑定，而虚函数都是动态绑定**（如此才可实现多态性）。

<font color="#F100">绝对不要重新定义一个继承而来的 `virtual` 函数的缺省参数值，因为缺省参数值都是静态绑定（为了执行效率），而 `virtual` 函数却是动态绑定。</font>

[https://www.cnblogs.com/lizhenghn/p/3657717.html](https://www.cnblogs.com/lizhenghn/p/3657717.html)


## 54.指针加减计算要注意什么?
	int *a, *b, c;
	a = (int*)0x500;
	b = (int*)0x520;
	c = b - a;
	printf("%d\n", c); // 8
	a += 0x020;
	c = b - a;
	printf("%d\n", c); // -24

首先变量 `a` 和 `b` 都是以 `16` 进制的形式初始化，将它们转成 `10` 进制分别是`1280(5*16^2=1280)`和`1312(5*16^2+2*16=1312)`，那么它们的差值为`32`，也就是说a和b所指向的地址之间间隔`32`个位，但是考虑到是 `int` 类型占 `4` 位，所以 `c` 的值为`32/4=8`

`a `自增`16`进制 `0x20` 之后，其实际地址变为`1280+2*16*4=1408`，(`因为一个int占4位，所以要乘4`)，这样它们的差值就变成了`1312-1280=-96`，所以`c`的值就变成了`-96/4=-24`。

<font color=blue> 需要明确的是指针每移动一位，它实际跨越的内存间隔是指针类型的长度，建议都转成 10 进制计算，计算结果除以类型长度取得结果 </font>

## 55.怎样判断两个浮点数是否相等？
浮点数在内存中的存储有舍入误差，在计算机中用近似表示某个实数；
所以不能用`==`来判断两个浮点数是否相等，而是

	const double eps = 1e-8;
	
	if(abs(a-b) <= eps)  相等
	else 不相等

**对于两个浮点数比较只能通过相减并与预先设定的精度比较**，记得要取绝对值。浮点数与 0 的比较也应该注意。与浮点数的表示方式有关。


**结构体变量比较是否相等**  
1.重载了“==”操作符；  

	struct foo {
	
	  int a;
	  int b;
	
	  bool operator==(const foo& rhs) *//* *操作运算符重载*
	
	  {
	    return( a == rhs.a) && (b == rhs.b);
	  }
	};
2.元素的话，一个个比；  
3.指针直接比较，如果保存的是同一个实例地址，则(p1==p2)为真;





## 56.C++中的指针参数传递和引用参数传递有什么区别?底层原理你知道吗?
**1) 指针参数传递本质上是值传递，它所传递的是一个地址值。**

值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的一个副本（替身）。  
值传递的特点是，被调函数对形式参数的任何操作都是作为**局部变量**进行的，不会影响主调函数的实参变量的值（形参指针变了，实参指针不会变）。

 
**2) 引用参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。**

被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量（根据别名找到主调函数中的本体）。  
因此，被调函数对形参的任何操作都会影响主调函数中的实参变量。

**3) 引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。**

而对于指针传递的参数，如果改变被调函数中的指针地址，它将应用不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就得使用指向指针的指针或者指针引用。

 

**4) 从编译的角度来讲，程序在编译时分别将指针和引用添加到符号表上，符号表中记录的是变量名及变量所对应地址。**

指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值（与实参名字不同，地址相同）。  
符号表生成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。


[https://www.cnblogs.com/crbhf/p/15004480.html](https://www.cnblogs.com/crbhf/p/15004480.html)

## 57.类如何实现只能静态分配和只能动态分配？
1.前者是把 `new`、`delete` 运算符重载为 `private` 属性。后者是把构造、析构函数设为 `protected` 属性，再用子类来动态创建；

2.建立类的对象有两种方式：

① 静态建立，例如 A a;

静态建立一个类对象，就是由编译器为对象在栈空间中分配内存。使用这种方法，是直接调用类的构造函数。

② 动态建立，例如 A *p = new A();

动态建立一个类对象，就是使用 `new` 运算符为对象在堆空间中分配内存。这个过程分为两步，第一步执行`operator new()`函数，在堆中搜索一块内存并进行分配；第二步调用类构造函数构造对象；

<font color=red>**只有使用new运算符，对象才会被建立在堆上**</font>，因此只要限制 `new` 运算符就可以实现类对象只能建立在栈上，可以将 `new` 运算符设为私有。

## 58.继承机制中对象之间如何转换？指针和引用之间如何转换?
**1. 向上类型转换**  
将派生类指针或引用转换为基类的指针或引用被称为向上类型转换，向上类型转换会自动进行，而且向上类型转换是安全的。

**2. 向下类型转换**  
将基类指针或引用转换为派生类指针或引用被称为向下类型转换，向下类型转换不会自动进行，因为一个基类对应几个派生类，所以向下类型转换时不知道对应哪个派生类，所以在向下类型转换时必须加动态类型识别技术。RTTI（运行时类型识别（Run-Time Type Identification，RTTI））技术，用 `dynamic_cast` 进行向下类型转换。

**指针和引用之间怎么转换：**  

- 指针转引用：把指针用`*`就可以转换成对象，可以用在引用参数当中。
- 引用转指针：把引用类型的对象用`&`取地址就获得指针了。

[https://www.cnblogs.com/swk0918/p/14444983.html](https://www.cnblogs.com/swk0918/p/14444983.html)

## 59.知道C++中的组合吗？它与继承相比有什么优缺点吗？
**继承：**  
优点：是子类可以重写父类的方法来方便地实现对父类的扩展。  
缺点：

- 父类的内部细节对子类是可见的；
- 子类从父类继承的方法在编译时就确定下来了，无法在运行期间改变从父类继承的方法的行为；
- 如果对父类的方法做了修改的话（比如增加了一个参数），则子类的方法必须做出相应的修改。
- 子类与父类是一种高耦合，违背了面向对象思想。

**组合**   
设计类的时候把要组合的类的对象加入到该类中作为自己的成员变量。  
优点：

- 当前对象只能通过所包含的那个对象去调用其方法，所以所包含的对象的内部细节对当前对象时不可见的。
- 当前对象与包含的对象是一个低耦合关系，如果修改包含对象的类中代码不需要修改当前对象类的代码。
- 当前对象可以在运行时动态的绑定所包含的对象。可以通过set方法给所包含对象赋值


缺点：

- 容易产生过多的对象；
- 为了能组合多个对象，必须仔细对接口进行定义。

[http://t.csdnimg.cn/sU2LO](http://t.csdnimg.cn/sU2LO)

## 60.函数指针？
函数指针**指向的是函数而非对象**。和其他指针一样，函数指针指向某种特定类型。函数的类型由它的返回类型和形参类型共同决定，与函数名无关。

要想声明一个可以指向该函数的指针，只需要**用指针替换函数名即可**。

**为什么有函数指针**：函数与数据项相似，函数也有地址。我们希望在同一个函数中通过使用相同的形参在不同的时间使用产生不同的效果。

**一个函数名就是一个指针，它指向函数的代码**。  
一个函数地址是该函数的进入点，也就是调用函数的地址。函数的调用可以通过函数名，也可以通过指向函数的指针来调用。函数指针还允许将函数作为变元传递给其他函数；

两种赋值方法：`指针名 =函数名`；`指针名=&函数名`

> `decltype` 与 `auto` 关键字一样，用于**进行编译时类型推导**，不过它与 auto 还是有一些区别的。decltype 的类型推导并不是像 auto 一样是从变量声明的初始化表达式获得变量的类型，而是总是**以一个普通表达式作为参数**，返回该表达式的类型，而且 **decltype 并不会对表达式进行求值**。  
> [https://www.cnblogs.com/QG-whz/p/4952980.html](https://www.cnblogs.com/QG-whz/p/4952980.html)


## 61.说一说你理解的内存对齐以及原因？
内存对齐是指在结构体中，**成员变量按照特定规则排列**以满足硬件平台要求和提高性能的过程。

1.平台原因：  
不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。

2.性能原因 ：  
数据结构( 尤其是栈 ) 应该尽可能地在自然边界上对齐。 原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。这里归根结底的来说就**是以空间换时间** 。


[https://blog.csdn.net/weixin_45897952/article/details/123727425](https://blog.csdn.net/weixin_45897952/article/details/123727425)


**对齐规则**  
1.每个特定平台上的编译器都有自己的默认“对齐系数”#pragma pack(show)可以查看；  
2.有效对齐值：是给定值#pragma pack(n)和结构体中最长数据类型长度中较小的那个。有效对齐值也叫对齐单位。  
3.结构体第一个成员变量的偏移量(offset)为0，以后每个数据成员的起始位置要从自身大小的整数倍开始存储；  
4.结构体的总大小为：若没有设定对齐字节数，则最大成员为对齐字节数。若有设定对齐字节数，则对齐字节数为：min(最大成员，设定的对齐字节数)的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。

<font color=blue>对齐规则是按照成员的声明顺序，依次安排内存，其偏移量为成员大小的整数倍，0看做任何成员的整数倍，最后结构体的大小为最大成员的整数倍</font>

## 62.函数调用过程栈的变化，返回值和参数变量哪个先入栈？
1. 将函数的参数压入栈中。参数的压入顺序与调用约定有关，在大多数C/C++编译器中，在函数调用的过程中，函数的参数是 ***由右向左*** 入栈的；
2. 将**当前函数的返回地址**压入栈中。返回地址是指函数调用结束后回到调用点的地址。
3. 将当**前函数的栈帧**（Stack Frame）压入栈中。栈帧包括本地变量、临时变量、函数的返回值等信息。栈帧的大小取决于函数中定义的变量和数据类型。
4. 跳转到**函数的入口点**开始执行函数代码。
5. 函数执行完毕后，将**返回值存放在寄存器中**（或者放在栈内存中），然后将栈帧弹出，恢复返回地址，跳转回调用点。

在返回之前，可以进行一些清理工作，例如释放内存、关闭文件等。函数调用过程中，栈的变化是动态的，每次函数调用都会增加栈的深度，而函数返回时栈的深度又会减少。如果递归调用函数，栈的深度会不断增加，直到达到一定限制，例如栈溢出。

## 63.你知道 printf 函数的实现原理是什么吗？
printf 是格式化输出可以自己定义输出的格式；`printf(“%d\n”,a),`其中" "之间的是格式说明串。% 后的一个或两个字符是格式说明符，用它来控制输出变量值的形式,
printf可以输入以上两种格式:

- 字符说明符 `%c` 同于 `putchar`；
- 字符串说明符 `%s` 同于 `puts`；


压栈时从右往左压栈，因此，printf  的第一个被找到的参数就是那个**字符指针**，就是被双引号括起来的那一部分，函数通过判断字符串里控制参数的个数来判断参数个数及数据类型，通过这些就可算出数据需要的堆栈指针的偏移量了。

## 64.为什么模板类一般都是放在一个 h 文件中？
1. 模板定义很特殊。由`template<…>`处理的任何东西都意味着编译器**在当时不为它分配存储空间**，它一直处于**等待状态直到被一个模板实例告知**。在编译器和连接器的某一处，有一机制能去掉指定模板的多重定义。所以为了容易使用，几乎总是在头文件中放置全部的模板声明和定义。
2. 在分离式编译的环境下，编译器编译某一个`.cpp`文件时并不知道另一个`.cpp`文件的存在，也不会去查找（当遇到未决符号时它会寄希望于连接器）。这种模式在没有模板的情况下运行良好，但遇到模板时就傻眼了，因为**模板仅在需要的时候才会实例化出来**。    
所以，当编译器只看到模板的声明时，它不能实例化该模板，只能创建一个具有外部连接的符号并期待连接器能够将符号的地址决议出来。  
然而**当实现该模板的`.cpp`文件中没有用到模板的实例**时，编译器懒得去实例化，所以，整个工程的.obj中就找不到一行模板实例的二进制代码，于是连接器也黔驴技穷了。

## 65.cout 和 printf 有什么区别？
C中的printf是一个标准的**输出函数**。  
C++中的cout是在iostrem文件中定义的**全局对象**。


**1.原理不同**  
    std::cout<<“输出内容"std::endl;  
其中`<<`操作符提取"输出内容”，然后进行重载，同时重载函数，根据"输出内容"的类型来重载不同类型的函数。

同时在定义每一个流对象时，系统会在内存中**开辟一段缓冲区（全缓冲）**，用来暂存数据（系统内有多个缓冲区）。此时当收到endl时，cout行会进行换行，同时刷新缓冲区。  
当缓冲区满或者收到结束符时，会将缓冲区数据一并清空并在显示设备输出。  
**flush 立即强迫缓冲输出**。

printf 是**行缓冲输出**，不是无缓冲输出。

> **全缓冲**： 全缓冲就是等待标准IO缓冲区填满或者flush操作，才进行IO操作输入输出  ；  
**行缓冲**：当遇到 \n 回车换行符时，进行IO操作输入输出；  
**无缓冲**：没有缓冲，直接进行IO操作；

**2.cout与printf格式不同**：  
**cout**：` std::cout<<"任意类型函数"std::endl;`  
**printf**：` printf(“其他+%转换+其他”，参数)`；


**3.输出效率不同(C++中 cin,cout 是不是效率不如scanf,printf)**：    
因为 printf 是在编译期确定操作数类型和调用的输出函数，**不用在运行期解析格式**控制字符串带来额外开销。不过标准流对象 cin/cout 为了普适性，继承体系很复杂，所以在对象的构造等方面会影响效率，因此总体效率比较低。。

## 66.你知道重载运算符吗？
重载的运算符是带有特殊名称的函数，函数名是由**关键字 operator** 和其后**要重载的运算符符号**构成的。

1. **只能重载已有的运算符**，而无权发明新的运算符；对于一个重载的运算符，其优先级和结合律与内置类型一致才可以；不能改变运算符操作数个数；
2. 两种重载方式：**成员运算符和非成员运算符**，成员运算符比非成员运算符少一个参数；下标运算符、箭头运算符必须是成员运算符；
3. 引入运算符重载，是为了实现类的**多态性**；
4. 当重载的运算符是成员函数时，**this 绑定到左侧运算符对象**。成员运算符函数的参数数量比运算符对象的数量少一个；至少含有一个类类型的参数；
5. 从参数的个数推断到底定义的是哪种运算符，当运算符既是一元运算符又是二元运算符（`+，-，*，&`）；
6. **下标运算符必须是成员函数**，下标运算符通常以所访问元素的引用作为返回值，同时最好定义下标运算符的常量版本和非常量版本；
7. **箭头运算符必须是类的成员**，解引用通常也是类的成员；重载的箭头运算符必须返回类的指针；


当程序中有函数重载时，函数的匹配原则和顺序：
1.名字查找（选定候选函数）；
2.确定候选函数（选定可行函数）；
3.寻找最佳匹配；

<font color=blue>**重载可以根据静态子类型分派不同表现，所以它是一种静态多态。**</font>


## 67.动态多态和静态多态的比较
**静态多态**  

优点：

- 由于**静多态是在编译期完成的**，因此效率较高，编译器也可以进行优化；
- 有很强的适配性和松耦合性，比如可以通过偏特化、全特化来处理特殊类型；
- 最重要一点是静态多态通过模板编程为C++带来了泛型设计的概念，比如强大的STL库。

缺点：

- 由于是模板来实现静态多态，因此模板的不足也就是静多态的劣势，比如调试困难、编译耗时、代码膨胀、编译器支持的兼容性
- 不能够处理异质对象集合；


**动态多态**

优点：

- OO设计，对是客观世界的直觉认识；
- 实现与接口分离，可复用；
- 处理同一继承体系下异质对象集合的强大威力；


缺点：

- 运行期绑定，导致一定程度的运行时开销；
- 编译器无法对虚函数进行优化
- 笨重的类继承体系，对接口的修改影响整个类层次；


**不同点：**

- 本质不同，静态多态在编译期决定，由模板具现完成，而动态多态在运行期决定，由继承、虚函数实现；
- 动态多态中接口是显式的，以函数签名为中心，多态**通过虚函数在运行期实现**；静态多台中接口是隐式的，以有效表达式为中心，多态通过模板具现在编译期完成


**相同点：**

- 都能够实现多态性，静态多态/编译期多态、动态多态/运行期多态；
- 都能够使接口和实现相分离，一个是模板定义接口，类型参数定义实现，一个是基类虚函数定义接口，继承类负责实现；



[https://www.cnblogs.com/lizhenghn/p/3667681.html](https://www.cnblogs.com/lizhenghn/p/3667681.html)

## 68.定义和声明的区别
**如果是指变量的声明和定义**：  
从编译原理上来说，声明是仅仅告诉编译器，有个某类型的变量会被使用，但是编译器并不会为它分配任何内存。而定义就是分配了内存。

**如果是指函数的声明和定义**：  
**声明**：一般在头文件里，对编译器说{这里我有一个函数叫function()}，让编译器知道这个函数的存在；  
**定义**：一般在源文件里，具体就是函数的实现过程写明函数体。


[https://linhongbo.com/posts/difference-between-definition-and-declaration/](https://linhongbo.com/posts/difference-between-definition-and-declaration/)

## 69.说一下你理解的 ifdef endif 代表着什么？
1.  一般情况下，源程序中所有的行都参加编译。但是有时希**望对其中一部分内容只在满足一定条件才进行编译**，也就是对一部分内容指定编译的条件，这就是“**条件编译**”。有时，希望当满足某条件时对一 组语句进行编译，而当条件不满足时则编译另一组语句。

2) 条件编译命令最常见的形式为：

	\#ifdef 标识符
		程序段1
	\#else
		程序段2
	\#endif

它的作用是：**当标识符已经被定义过(一般是用#define命令定义)，则对程序段1进行编译，否则编译程 序段2**。

3) 在一个大的软件工程里面，**可能会有多个文件同时包含一个头文件**，当这些文件编译链接成一个可执行文件上时，就会出现大量“重定义”错误。

在头文件中使用#define、#ifndef、#ifdef、#endif** 能避免头文件重定义**。

## 70.C++如何处理多个异常的？
- **C++ 中的异常情况**：   
**语法错误**（编译错误）：比如变量未定义、括号不匹配、关键字拼写错误等等编译器在编译时能发现的错误，这类错误可以及时被编译器发现，而且可以及时知道出错的位置及原因，方便改正；  
**运行时错误**：比如数组下标越界、系统内存不足等等。这类错误不易被程序员发现，它能通过编译且能进入运行，但运行时会出错，导致程序崩溃。为了有效处理程序运行时错误，C++中引入异常处理机制来解决此问题。
- **C++异常处理机制**：    
**异常处理基本思想**：执行一个函数的过程中发现异常，**可以不用在本函数内立即进行处理， 而是抛出该异常，让函数的调用者直接或间接处理这个问题**。    
C++异常处理机制由3个模块组成：try(检查)、throw(抛出)、catch(捕获) 抛出异常的语句格式为：throw 表达式；如果 try 块中程序段发现了异常则抛出异常。

## 71.如何在不使用额外空间的情况下交换两个数？你有几种方法？
1)  算术

	x = x + y;
	y = x - y;
	
	x = x - y; 

2)  异或

	x = x^y;// 只能对int,char..
	y = x^y;
	x = x^y;
	x ^= y ^= x;

## 72.你知道 strcpy 和 memcpy 的区别是什么吗？
1. **复制的内容不同**。strcpy 只能复制字符串，而 memcpy 可以复制任意内容，例如字符数组、整型、结构体、类等。
2. **复制的方法不同**。strcpy 不需要指定长度，它遇到被复制字符的串结束符"`\0`"才结束，所以容易溢出。memcpy 则是根据其第3个参数决定复制的长度。
3. **用途不同**。通常在复制字符串时用 strcpy，而需要复制其他类型数据时则一般用 memcpy。

[https://www.cnblogs.com/codemagiciant/p/17544881.html](https://www.cnblogs.com/codemagiciant/p/17544881.html)

> strlen函数返回的是在字符串中’\0’前面出现的字符的个数；  
> strcat追加拷贝，追加到目标空间后面，目标空间必须足够大，能容纳下源字符串的内容；  
> strcmp比较两个字符串的大小，一个字符一个字符比较，按ASCLL码比较；

## 73.程序在执行int main(int argc, char *argv[])时的内存结构，你了解吗？
参数的含义是程序在命令行下运行的时候，需要输入 argc 个参数，每个参数是以char 类型输入的，依次存在数组里面，数组是 argv[]，**所有的参数在指针`char *` 指向的内存中，数组的中元素的个数为 argc个，第一个参数为程序的名称**。

## 74.如果有一个空类，它会默认添加哪些函数？
	1)  Empty(); // 缺省构造函数//
	2)  Empty( const Empty& ); // 拷贝构造函数//
	3)  ~Empty(); // 析构函数//
	4)  Empty& operator=( const Empty& ); // 赋值运算符//

## 75.C++中标准库是什么？
1.C++ 标准库可以分为两部分： 
 
- **标准函数库**：这个库是由通用的、独立的、不属于任何类的函数组成的。函数库继承自C语言；  

- **面向对象类库**：这个库是类及其相关函数的集合；

	- 输入/输出 I/O、字符串和字符处理、数学、时间、日期和本地化、动态分配、其他、宽字符函数;  
	- 标准的 C++  I/O 类、String 类、数值类、STL 容器类、STL 算法、STL 函数对象、STL 迭代器、STL 分配器、本地化库、异常处理类、杂项支持库


## 76.你知道 const char* 与 string 之间的关系是什么吗？
- string 是 C++ 标准库里面其中一个，封装了对字符串的操作，实际操作过程我们可以用`const char*`给string类初始化；
- `c_str()` 函数可以将 `const string*` 类型 转化为 `const char*` 类型；

> c_str() 这个函数转换后返回的是一个临时指针，不能对其进行操作；
> 
所以因为这个数据是临时的，所以当有一个改变这些数据的成员函数被调用后，该数据就会改变失效；


## 77.如何设计一个计算仅单个子类的对象个数？
1. 为类设计一个 static 静态变量 count 作为计数器；
2. 类定义结束后初始化 count;
3. 在构造函数中对 count 进行+1;
4. 设计拷贝构造函数，在进行拷贝构造函数中进行 count +1，操作；
5. 设计赋值构造函数，在进行赋值函数中对 count+1 操作；
6. 在析构函数中对 count 进行-1；


## 78.成员初始化列表会在什么时候用到？它的调用过程是什么？
1.当初始化一个引用成员变量时；  
2.当初始化一个非静态的常量成员时；  
3.当调用一个基类的构造函数，而构造函数拥有一组参数时；  
4.当调用一个成员类的构造函数，而他拥有一组参数；  
5.成员类型是没有默认构造函数的类。

编译器会一一操作初始化列表，以适当顺序在构造函数之内安插初始化操作，并且在任何显示用户代码前。<font color = blue>初始化列表中的项目顺序是由类中的成员声明顺序决定的，不是初始化列表中的排列顺序决定的。</font>

## 79.在进行函数参数以及返回值传递时，可以使用引用或者值传递，其中使用引用的好处有哪些？
对比值传递，引用传参的好处：

1. 在函数内部可以对此参数进行修改；
2. 提高函数调用和运行的效率（因为没有了传值和生成副本的时间和空间消耗）

**用引用作为返回值最大的好处就是在内存中不产生被返回值的副本**。

但是有以下的限制：

1. 不能返回局部变量的引用。因为函数返回以后局部变量就会被销毁；
2. 不能返回函数内部 new 分配的内存的引用。虽然不存在局部变量的被动销毁问题，可对于这种情况（返回函数内部new分配内存的引用），又面临其它尴尬局面。例如，被函数返回的引用只是作为一 个临时变量出现，而没有被赋予一个实际的变量，那么这个引用所指向的空间（由new分配）就无法释放，造成内存泄露；
3. 可以返回类成员的引用，但是最好是 const。因为如果其他对象可以获得该属性的非常量的引用，那么对该属性的单纯赋值就会破坏业务规则的完整性。

## 80.说一说 strcpy、sprintf 与 memcpy 这三个函数的不同之处？
1.操作对象不同

① strcpy 的两个操作对象均为字符串；  
② sprintf 的操作源对象可以是多种数据类型，目的操作对象是字符串；  
③ memcpy 的两个对象就是两个任意可操作的内存地址，并不限于何种数据类型。

2.复制的方法不同

①strcpy 不需要指定长度，它遇到被复制字符的串结束符"`\0`"才结束，所以容易溢出。  
②sprintf 如果失败，则返回一个负数。对于写入buffer（它可以指代缓存、缓冲区等）的字符数是没有限制的，这就存在了 buffer 溢出的可能性。  
③ memcpy 则是根据其第3个参数决定复制的长度。

3.执行效率不同  

memcpy最高，strcpy次之，sprintf的效率最低； 

4.实现功能不同

① strcpy 主要实现字符串变量间的拷贝；  
② sprintf 主要实现其他数据类型格式到字符串的转化；  
③ memcpy主要是内存块间的拷贝。

## 81.你知道数组和指针的区别吗？
1.数组在内存中是连续存放的，开辟一块连续的内存空间；数组所占存储空间：sizeof（数组名）；**数组大小：sizeof(数组名)/sizeof(数组元素数据类型)**；

2.用运算符 sizeof 可以计算出数组的容量（字节数）。**sizeof(p), p 为指针得到的是一个指针变量的字节数，而不是 p 所指的内存容量**。

3.编译器为了简化对数组的支持，实际上是利用指针实现了对数组的支持。具体来说，就是将**表达式中的数组元素引用转换为指针加偏移量的引用**。

4.在向函数传递参数的时候，如果实参是一个数组，那用于接受的形参为对应的指针。也就是**传递过去是数组的首地址而不是整个数组**，能够提高效率；

5.在使用下标的时候，两者的用法相同，都是原地址加上下标值，不过**数组的原地址就是数组首元素的地址是固定的，指针的原地址就不是固定的**。

## 82.如何禁止程序自动生成拷贝构造函数？
1. 为了阻止编译器默认生成拷贝构造函数和拷贝赋值函数，我们需要手动去重写这两个函数，某些情况﻿下，为了避免调用拷贝构造函数和﻿拷贝赋值函数，我们需要将他们设置成 `private`，防止被调用。
2. 类的成员函数和 `friend` 函数还是可以调用 private 函数，如果这个 private 函数只声明不定义，则会产生一个连接错误；
3. 针对上述两种情况，我们可以定一个 base 类，**在 base 类中将拷贝构造函数和拷贝赋值函数设置成 private**，那么派生类中编译器将不会自动生成这两个函数，且由于 base 类中该函数是私有的，因此，派生类将阻止编译器执行相关的操作。【muduo 就是这样实现的】

## 83.你知道 Debug 和 Release 的区别是什么吗？
**Debug**：调试版本，包含调试信息，所以容量比 Release 大很多，并且不进行任何优化（优化会使调试复杂化，因为源代码和生成的指令间关系会更复杂），便于程序员调试。Debug 模式下生成两个文件，除了`.exe`或`.dll`文件外，还有一个`.pdb`文件，该文件记录了代码中断点等调试信息 

**Release**：发布版本，不对源代码进行调试，编译时对应用程序的速度进行优化，使得程序在代码大小和运行速度上都是最优的。（调试信息可在单独的PDB文件中生成）。Release 模式下生成一个文件`.exe`或`.dll`文件

实际上，Debug 和 Release 并**没有本质的界限**，**他们只是一组编译选项的集合，编译器只是按照预定的选项行动**。事实上，我们甚至可以修改这些选项，从而得到优化过的调试版本或是带跟踪语句的发布版本。

[https://www.cnblogs.com/taiyonghai/p/6126074.html](https://www.cnblogs.com/taiyonghai/p/6126074.html)

## 84. main 函数的返回值有什么值得考究之处吗? 
**main 函数的返回值用于说明程序的退出状态**。如果返回 0，则代表程序正常退出。返回其它数字的含义则由系统决定。通常，返回非零代表程序异常退出。

既然 main 函数只有一种返回值类型，那么是不是可以不写？规定：不明确标明返回值的，默认返回值为 int，也就是说 main()等同于int main()，而不是等同于void main()。

main 也是个函数，它运行了自然也是有结果的，这个结果通常是告诉操作系统，自身是正常运行结束了（值为0），还是发生了异常（这个值就有很多了）。告诉操作系统值是多少，目的是后台或者SHELL可以从操作系统中取得这个程序的运行结果，从而可以进行进一步操作。

其实 **main 函数本身是可以调用这个返回值**的，这个的作用就在于多线程的编程中，另外一个线程等待这个程序执行完毕，等待的就是这个MAIN函数的执行结果。


[http://t.csdnimg.cn/pwJvm](http://t.csdnimg.cn/pwJvm)

## 85.成员函数里 memset(this,0,sizeof(*this)) 会发生什么？
- 类里面定义了很多int,char,struct等c语言里的那些类型的变量，我习惯在构造函数中将它们初始化为0，但是一句句的写太麻烦，所以直接就memset(this, 0, sizeof *this);将整个对象的内存全部置为0。

以下场景不可以使用：

- 类含有虚函数表：这么做**会破坏虚函数表**，后续对虚函数的调用都将出现异常【this指向的是一个对象，该对象中有一个指向虚表的指针，那么此操作会将虚表指针的值置为0，则无法索引到虚函数表】；
- 如果成员的类对象变量中如果有用到new的方法，例如 std::string内部 指针全部置空 ，这时确实会导致找不到开辟的内存的位置，会导致内存泄露，访问异常。因为**指针清零，但是指针指向的内存空间还没有释放**。

## 86.你知道回调函数吗？它的作用？
函数指针的调用，即是一个通过函数指针调用的函数；  
如果**把函数的指针（地址）作为参数传递给另一个函数**，当这个指针被用来调用其所指向的函数时，就说这是回调函数。

<font color=red>回到函数作用：“解耦”【因为可以把调用者与被调用者分开。调用者不关心谁是被调用者，所有它需知道的，只是存在一个具有某种特定原型、某些限制条件(如返回值为int)的被调用函数】，普通函数代替不了回调函数的这个特点。</font>

**使用回调函数，和普通函数调用区别：**  
1）在主入口程序中，把回调函数像参数一样传入库函数。这样一来，只要**改变传进库函数的参数，就可以实现不同的功能**，且不需要修改库函数的实现，变的很灵活，这就是解耦。  
2）主函数和回调函数是在同一层的，而库函数在另外一层。如果库函数对我们不可见，我们修改不了库函数的实现，也就是说不能通过修改库函数让库函数调用普通函数那样实现，那我们就只能通过传入不同的回调函数了。

**回调函数其实就是函数指针的一种用法**【使用回调函数会有间接调用，因此，会有一些额外的传参与访存开销，对于MCU代码中对时间要求较高的代码要慎用】

**回调函数的缺点：**    
1）回调函数固然能解决一部分系统架构问题但是绝不能再系统内到处都是，如果你发现你的系统内到处都是回调函数，那么你一定要重构你的系统。  
2）回调函数本身是**一种破坏系统结构的设计思路**，回调函数会绝对的变化系统的运行轨迹，执行顺序，调用顺序。回调函数的出现会让读到你的代码的人非常的懵头转向。



[https://blog.csdn.net/llzhang_fly/article/details/104933969](https://blog.csdn.net/llzhang_fly/article/details/104933969)


## 87.什么是一致性哈希？
分布式存储（每个节点数据不同）使用哈希算法有一个很致命的问题，如果节点数量发生了变化了映射关系的数据，否则会出现查询不到数据的问题。也就是在对系统做扩容或者缩容时，必须迁移改变。

一致性哈希是一种哈希算法，就是在**移除或者增加一个结点时，能够尽可能小的改变**已存在 key 的映射关系。  
一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。（也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值）     
映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。

<img src="https://cdn.xiaolincoding.com//mysql/other/83d7f363643353c92d252e34f1d4f687.png" alt="哈希环" width="300" height="300">

但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，会有大量的请求集中在一个节点上。

<img src ="https://cdn.xiaolincoding.com//mysql/other/d528bae6fcec2357ba2eb8f324ad9fd5.png"  width="300" height="300">

一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。

[https://www.xiaolincoding.com/os/8_network_system/hash.html#%E6%80%BB%E7%BB%93](https://www.xiaolincoding.com/os/8_network_system/hash.html#%E6%80%BB%E7%BB%93)

不再将真实节点映射到哈希环上，而是**将虚拟节点映射到哈希环上**，并**将虚拟节点映射到实际节点**，所以这里有「两层」映射关系。

## 88.C++从代码到可执行程序经历了什么?
<img src = "http://oss.interviewguide.cn/img/202205212343505.png" >

1、**预编译**  
主要处理源代码文件中的以“#”开头的预编译指令；  
2、**编译**  
把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。  
3、**汇编**  
将汇编代码转变成机器可以执行的指令(机器码文件)。  经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows 下)、xxx.obj(Linux下)。  
4、**链接**  
将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。

链接分为静态链接和动态链接：

- 静态链接：
函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，**链接器从库中复制**这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件；【在内存存在多个副本；需要重新进行编译链接；执行的时候运行速度快】
	- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
	- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

- 动态链接：
动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，**在程序运行时才将它们链接在一起**形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件，在 Linux 系统中通常用 .so 后缀来表示，windows 为 DLL。【共享库；更新时只需要替换原来的目标文件；链接推迟到了程序运行】

[http://t.csdnimg.cn/ZouMD](http://t.csdnimg.cn/ZouMD)

## 89.友元函数在类内部声明还是内外？
友元函数不一定要在类内声明，普通的友元函数可以在类外声明，也可以在类内声明。  
只有友元工厂才必须用到类内声明友元函数。

**如果友元函数是在类的内部声明的**，那么它可以直接访问类的私有成员和保护成员，即使这些成员在类的外部是不可见的。然而，如果友元函数在类的内部声明，它的**可见性只限于该类及其派生类，无法在其他地方直接使用**。

**如果友元函数是在类的外部声明的**，那么它仍然可以访问类的私有成员和保护成员，但是**需要使用类名来限定友元函数的可见性**。因为友元函数的声明和定义可以单独放在一个头文件中，而不需要与类的定义混合在一起。


[https://www.cnblogs.com/codemagiciant/p/17601831.html](https://www.cnblogs.com/codemagiciant/p/17601831.html)

## 90.友元函数和友元类的基本情况
友元是一种定义在类外部的普通函数，但它需要在类体内进行声明，为了与该类的成员函数加以区别，在声明时前面加以关键字friend。

友元不是成员函数，但是它**可以访问类中的私有成员**。  
友元的作用在于提高程序的运行效率，但是，它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的私有成员。


- 友元函数可访问类的私有成员，但不是类的成员函数
- 友元函数不能用const修饰
- 友元函数可以在类定义的任何地方声明，不受类访问限定符限制
- 一个函数可以是多个类的友元函数
- 友元函数的调用与普通函数的调用和原理相同


友元除了友元函数以外，友元还可以是类——**友元类**，即一个类可以作另一个类的友元。当一个类作为另一个类的友元时，这就意味着这个类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的非公有成员。

- **友元关系是单向的，不具有交换性。**  
- **友元关系不能被继承，但对已有的方法来说访问权限不改变**。


## 91.介绍一下几种典型的锁
**读写锁**

- 多个读者可以同时进行读；
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）；
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）；

**互斥锁**：一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以**互斥锁在加锁操作时涉及上下文的切换**。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁；

**条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而**条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件**。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。

**自旋锁**

**如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止**。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

## 92.为什么C++没有垃圾回收机制?
- 首先，实现一个**垃圾回收器会带来额外的空间和时间开销**。你需要开辟一定的空间保存指针的引用计数和对他们进行标记 `mark`。然后需要单独开辟一个线程在空闲的时候进行 free 操作。

- 垃圾回收会使得C++不适合进行很多底层的操作。


## 93.类的对象存储空间?
类所占内存的大小主要是由**成员变量（静态变量除外）决定的**，成员函数（虚函数除外）是不计算在内的。

类内部的成员变量：

- 普通的变量：是要占用内存的，但是要注意<font color = red>**对齐原则**</font>（这点和struct类型很相似）。
- static修饰的静态变量：不占用内容，原因是编译器将其放在全局变量区。

类内部的成员函数：

- 普通函数：不占用内存。这是因为所有的函数都是存放在代码区的，不管是全局函数，还是成员函数。
- 虚函数：要占用4个以上字节(在32位系统分配指针大小为4字节)，用来指定虚函数的虚拟函数表的入口地址。所以一个类的虚函数所占用的地址是不变的，和虚函数的个数是没有关系的。类继承自多个基类的时候可能有多个虚函数表指针，可能会占据多个内存空间。

<font color = red>空的类是会占用内存空间的，而且大小是1，原因是C++要求每个实例在内存中都有独一无二的地址。</font>空类也会被实例化，所以编译器会给空类隐含的添加一个字节。

> 带有虚函数的 C++ 类大小不为1，因为**每一个对象会有一个 vptr 指向虚函数表，具体大小根据指针大小确定**。

`可见子类的大小 = 本身成员变量的大小 + （父类成员变量的的大小 + 虚函数表指针）* n` , n 表示继承的类的个数。



[https://blog.csdn.net/leigelaile1/article/details/81982103](https://blog.csdn.net/leigelaile1/article/details/81982103)


## 94.简要说明C++的内存分区

- **栈**： 存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放。
- **堆**： 动态申请的内存空间，就是由 malloc 分配的内存块，由程序员控制它的分配和释放，如果程序执行结束还没有释放，操作系统会自动回收。
- **全局区/静态存储区**（.bss 段和 .data 段）： 存放全局变量和静态变量，程序运行结束操作系统自动释放，在 C 语言中，未初始化的放在 .bss 段中，初始化的放在 .data 段中，C++ 中不再区分了。
- **常量存储区**（.data 段）： 存放的是常量，不允许修改，程序运行结束自动释放。
- **代码区**（.text 段）： 存放代码，不允许修改，但可以执行。编译后的二进制文件存放在这里。

## 95.什么是内存池，如何实现？
内存池（Memory Pool） 是一种内存分配方式。通常我们习惯直接使用 new、malloc 等申请内存，这样做的缺点在于：**由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能**。

内存池则是**在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用**。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

**内存池的工作原理**

1. 在初始化时，从操作系统申请一块连续的物理内存，称为内存池。
1. 将内存池按照固定大小分成多个内存块。
1. 将这些内存块用链表、栈或其他数据结构连接起来，形成一个内存块池。
1. 当需要分配内存时，从内存块池中获取一个内存块，并将其标记为已分配。
1. 当不需要使用内存块时，将其标记为未分配，放回到内存块池中。
1. 当内存块池中无可用内存块时，可以选择动态扩展内存池。

## 96.关于this指针你知道什么？全说出来？
1. 每个对象都有一个隐藏的 this 指针，但**不属于对象，是编译器添加的**；
2. `this` 只能在成员函数中使用【实际上，成员函数默认第一个参数为T *const this】。全局函数、静态函数都不能使用 `this`；
3. 由此可见，**this 在成员函数的开始前构造，在成员函数的结束后清除**。这个生命周期同任何一个函数的参数是一样的，没有任何区别。当调用一个类的成员函数时，编译器将类的指针作为函数的 `this` 参数传递进去。

## 97.this指针存放在何处？堆、栈、全局变量，还是其他？
this 指针会因编译器不同而有不同的放置位置。可能是栈，也可能是寄存器，甚至全局变量。

## 98.this指针是如何传递类中的函数的？绑定？还是在函数参数的首参数就是this指针？那么，this指针又是如何找到“类实例后函数的”？
大多数编译器通过ecx（寄数寄存器）寄存器传递this指针。事实上，这也是一个潜规则。一般来说，不同编译器都会遵从一致的传参规则，否则不同编译器产生的obj就无法匹配了。

在call之前，编译器会把对应的对象地址放到eax中。this是通过函数参数的首参来传递的。this指针在调用之前生成，至于“类实例后函数”，没有这个说法。类在实例化时，只分配类中的变量空间，并没有为函数分配空间。自从类的函数定义完成后，它就在那儿，不会跑的。

## 99.我们只有获得一个对象后，才能通过对象使用this指针。如果我们知道一个对象this指针的位置，可以直接使用吗？
**this 指针只有在成员函数中才有定义**。因此，你获得一个对象后，也不能通过对象使用 this 指针。所以，我们无法知道一个对象的this指针的位置（只有在成员函数里才有this指针的位置）。当然，在成员函数里，你是可以知道this指针的位置的（可以通过&this获得），也可以直接使用它。


[http://blog.chinaunix.net/uid-21411227-id-1826942.html](http://blog.chinaunix.net/uid-21411227-id-1826942.html)

## 100.每个类编译后，是否创建一个类中函数表保存函数指针，以便用来调用函数？

普通的类函数（不论是成员函数，还是静态函数）都不会创建一个函数表来保存函数指针。只有虚函数才会被放到函数表中。但是，即使是虚函数，**如果编译器能明确知道调用的是哪个函数，编译器就不会通过函数表中的指针来间接调用，而是会直接调用该函数**。

## 101.在成员函数中调用delete this会出现什么问题？对象还可以使用吗？
在类对象的内存空间中，**只有数据成员和虚函数表指针**，并不包含代码内容，类的成员函数单独放在代码段中。  
在调用成员函数时，隐含传递一个 this 指针，让成员函数知道当前是哪个对象在调用它。    
**当调用 delete this 时，类对象的内存空间被释放**。在 delete this 之后进行的其他任何函数调用，只要不涉及到 this 指针的内容，都能够正常运行。一旦涉及到this 指针，如操作数据成员，调用虚函数等，就会出现不可预期的问题。


## 102. C++11 有哪些新特性

[https://cloud.tencent.com/developer/article/1745592](https://cloud.tencent.com/developer/article/1745592)


## 103.auto、decltype和decltype(auto)的用法
编程时常常需要把表达式的值赋给变量，这就要求声明变量时清楚的知道表达式的类型。然而有些情况是**声明的变量的类型我们并不知道**，比如在模板编程时。  
为了解决这个问题，C++11引入了**auto类型说明符，用它来让编译器替我们去分析表达式所属的类型**。

decltype是C++11新增的关键字，主要用于提取变量和表达式的类型。  
decltype的语法形式为：`decltype(e)`，这里e是一个表达式，而`decltype(e)`是一个类型指示符。decltype的结果不是值，而是一个类型。**编译器只是分析表达式并得到它的类型，却不进行实际的计算表达式的值。  
**

`decltype(auto)`是C++14新增的类型指示符，可以**用来声明变量以及指示函数返回类型**。  
使用时，会将”=”号右边的表达式替换掉auto，再根据decltype的语法规则来确定类型

	int e = 4;
	const int* f = &e; // f是底层const
	decltype(auto) j = f;//j的类型是const int* 并且指向的是e

## 104. C++中NULL和nullptr区别
- NULL是一个宏定义，C++中通常将其定义为0，编译器一般优先把它当作一个整型常量(C标准下定义为(void*）0)；
- nullptr是一个编译期常量，其类型为nullptr_t。它**既不是整型类型，也不是指针类型**；
- 在模板推导中，nullptr被推导为nullptr_t类型，仍可隐式转为指针。但0或NULL则会被推导为整型类型；
- 要避免在整型和指针间进行函数重载。因为NULL会被匹配到整型形参版本的函数，而不是预期的指针版本。

[https://blog.csdn.net/qq_38410730/article/details/105183769](https://blog.csdn.net/qq_38410730/article/details/105183769)

## 105. 智能指针理解
[http://t.csdnimg.cn/et0ON](http://t.csdnimg.cn/et0ON)

动态内存管理经常会出现两种问题：
（1）一种是忘记释放内存，会造成内存泄漏；
（2）一种是尚有指针引用内存的情况下就释放了它，就会产生引用非法内存的指针。

为了更加容易（更加安全）的使用动态内存，**引入了智能指针**的概念。智能指针的行为类似常规指针，重要的区别是它负责自动释放所指向的对象。

`auto_ptr` 是c++11以前的最原始的智能指针，可以将 new 获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用 delete 来释放内存。但是在c++11中已经被弃用（使用的话会被警告）了。

原因：

1. 复制或者赋值都会改变资源的所有权；
2. 在STL容器中使用auto_ptr存在着重大风险，因为容器内的元素必须支持可复制和可赋值；
3. 不支持对象数组的内存管理；

`unique_ptr`：`unique_ptr` 和 `auto_ptr` 用法几乎一样，除了一些特殊

特性：

1. 基于排他所有权模式：**两个指针不能指向同一个资源**
1. 无法进行左值 `unique_ptr` 复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值；
1. 保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象；
1. 在容器中保存指针是安全的；


`shared_ptr`：:它所指向的资源具有共享性，即多个shared_ptr可以指向同一份资源，并在内部使用引用计数机制来实现这一点。可以记录引用特定内存对象的智能指针数量，当复制或拷贝时，引用计数加 1，当智能指针析构时，引用计数减 1，如果计数为零，代表已经没有指针指向这块内存，那么就释放它。

<font color = "#FA1000">`shared_ptr` 的构造函数和拷贝构造函数做的事情，导致虽然都是指向同一个资源，但是**对于引用计数对象的管理方式**，这两个函数是不一样的，构造函数是**新分配引用计数对象**，拷贝构造函数只做引用**计数增减**。</font>

> 当新的 `shared_ptr` 对象与指针关联时，则在其构造函数中，将与此指针关联的引用计数增加1。

> 当任何 `shared_ptr` 对象超出作用域时，则在其析构函数中，它将关联指针的引用计数减1。如果引用计数变为0，则表示没有其他 `shared_ptr` 对象与此内存关联，在这种情况下，它使用delete函数删除该内存。


最安全的分配和使用动态内存的方法就是调用一个名为 `make_shared` 的标准库函数，此函数在动态内存中分配一个对象并初始化它，返回指向此对象的 `shared_ptr`。


<font color = "#F100">可以说，当生命控制权没有彼此互相掌握时，才能正确解决循环引用问题，而弱引用的使用可以使生命控制权互相掌握的情况消失。</font>

我们在 `enable_shared_from_this<A>` 基类中继承一个成员变量 `_Wptr`，当定义第一个智能指针对象的时候： `shared_ptr< A > ptr1(new A())`，调用 `shared_ptr` 的普通构造函数，就会初始化 `A` 对象的成员变量 `_Wptr`，作为观察 `A` 对象资源的一个弱智能指针观察者。

`weak_ptr` :设计的目的是为配合 `shared_ptr` 而引入的一种智能指针来协助 `shared_ptr` 工作, 它只提供了对管理对象的一个访问手段，同时也可以实时动态地知道指向的对象是否存活。它只可以从一个 `shared_ptr` 或另一个 `weak_ptr` 对象构造, 它的**构造和析构不会引起引用记数的增加或减少**。 同时 `weak_ptr` 没有重载`*`和`->`，，所以并不能直接使用资源，但可以使用 lock 获得一个可用的 `shared_ptr` 对象。

`shared_from_this()` 函数，是直接返回了一个 `shared_ptr<_Ty>(_Wptr)`，该语法在 shared_ptr 中也有相应的构造函数，其主要作用就是**把一个弱智能指针提升为一个强智能指针**，可以在多线程环境中判断对象是否存活或者已经析构释放.

[C/C++｜智能指针的 shared\_ from \_ this 和enable\_ shared\_ from\_ this](http://t.csdnimg.cn/sNhIH)

## 106.智能指针出现循环引用怎么解决?
一般来讲，解除这种循环引用有下面有三种可行的方法(参考)：

1. 当只剩下最后一个引用的时候需要手动打破循环引用释放对象。
2. 当A的生存期超过B的生存期的时候，B改为使用一个普通指针指向A。
3. 使用弱引用的智能指针打破这种循环引用。
虽然这三种方法都可行，但方法1和方法2都需要程序员手动控制，麻烦且容易出错。我们一般使用第三种方法：弱引用的智能指针weak_ptr。

weak_ptr除了对所管理对象的基本访问功能（通过get()函数）外，还有两个常用的功能函数：   
`expired()` 用于检测所管理的对象是否已经释放；  
`lock()` 用于获取所管理的对象的强引用指针。不能直接通过 weak_ptr 来访问资源。那么**如何通过weak_ptr来间接访问资源呢？答案是：在需要访问资源的时候weak_ptr为你生成一个shared_ptr，shared_ptr能够保证在shared_ptr没有被释放之前，其所管理的资源是不会被释放的**。`创建shared_ptr的方法就是lock()方法。`

                        
[https://blog.csdn.net/daniel_ustc/article/details/23096229](https://blog.csdn.net/daniel_ustc/article/details/23096229)  
[http://t.csdnimg.cn/G5HAZ](http://t.csdnimg.cn/G5HAZ)

## 107.Lambda 表达式
类似匿名函数（需要函数体，不需要函数名），可以理解为简易版函数。  
**基本格式**： `[捕获方式] (参数) -> 返回值类型 {函数体}`（可以忽略返回类型，lambda自动推断出返回类型）。

`[ ]`：闭包形式(closure type)，即定义一个lambda表达式后，编译器会自动生成一个重载()运算符的匿名类。优势在于可以通过传值或引用的方式捕获其封装作用域内的变量（即捕获方式中存在的变量）

lambda 的性能优势：

1. 内联函数：
编译器自动将 lambda 表达式内联，这意味着代码直接插入到调用函数中。
可以减少函数调用的开销，并提高性能。

2. 避免命名函数的开销：
lambda 表达式没有名称，因此不必被声明和存储在符号表中，
可以减少开销，并提高性能。

3. 改善高速缓存局部性：
lambda 表达式可以在同一个函数中定义和使用，这意味着 lambda 使用的代码和数据
存储在与调用代码相同的高速缓存行中。
可以改善高速缓存局部性并降低高速缓存失效的成本。

4. 减小代码大小：
lambda 表达式通常比命名函数小，并不需要外部函数调用，
这可以减小编译代码的大小并提高性能。

5. 增加灵活性：
lambda 表达式可以用来将函数作为参数传递给其他函数，


## 108.什么是STL?
C++ STL从广义来讲包括了三类：算法，容器和迭代器。

- 算法包括排序，复制等常用算法，以及不同容器特定的算法。
- 容器就是数据的存放形式，包括序列式容器和关联式容器，序列式容器就是 list，vector 等，关联式容器就是set，map等
- 迭代器就是在不暴露容器内部结构的情况下对容器的遍历。

## 109.解释一下什么是trivial destructor
在C++中，当一个类的析构函数**不需要做任何额外的工作**时，我们称这个类的析构函数为 trivial destructor。也就是说，如果这个类不持有任何资源，比如堆内存、文件句柄等等，那么它的析构函数就是 trivial destructor。

当一个类的析构函数是 trivial destructor 时，**编译器会对其进行优化**，使得在该类对象被销毁时，不会调用析构函数。这种优化被称为trivial destructor优化，它可以提高程序的性能和效率。

需要注意的是，如果一个类的析构函数不是trivial destructor，那么在该类对象被销毁时，析构函数必须被调用。这是因为该类对象可能持有一些资源，需要在销毁时释放。如果析构函数没有被调用，这些资源可能会泄漏，导致程序出现严重的错误。


[https://www.nowcoder.com/discuss/541403936406691840](https://www.nowcoder.com/discuss/541403936406691840)

## 110.使用智能指针管理内存资源，RAII是怎么回事？
1)RAII全称是“Resource Acquisition is Initialization”，直译过来是“**资源获取即初始化**”，也就是说**在构造函数中申请分配资源，在析构函数中释放资源**。

因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定。

2)**智能指针（std::shared_ptr和std::unique_ptr）**即RAII最具代表的实现，使用智能指针，可以实现自动的内存管理，再也不需要担心忘记delete造成的内存泄漏。

## 111.说一下C++左值引用和右值引用
当一个对象被用作右值的时候，用的是对象的值（内容）；当对象被用作左值的时候，用的是对象的身份（在内存中的位置）。

所以当一个左值被当成右值使用时，实际使用的是它的内容（值）。**在需要右值的地方可以用左值来代替，但是不能把右值当成左值（也就是位置）使用**。比如取地址符` &`，就是对一个左值取地址，取出来的地址是个右值，因为右值只有内容，在内存中没有位置。而对一个地址解引用 `*p`，或者对一个数组取下标` arr[0]`，就获得了左值。


C++11 引入了 **右值引用 &&** 的概念，允许将右值绑定到一个引用上，并且可以修改其内容，这提供了更多的灵活性和效率。

	int i = 10;
	int& j = i;           // 正确：左值引用
	int& k = i * 1;       // 错误：左值引用不能绑定右值
	int&& m = i * 1;      // 正确：右值引用
	int&& n = i;          // 错误：右值引用不能绑定左值
	const int& p = i * 1; // 正确：const左值引用可以绑定右值

如果说变量是左值，那么问题来了，右值引用的变量也是变量，这个变量是左值么，比如这里的 m。

答案为左值，所以下面这个表达式是错误的：

	int&& q = m;          // 错误：右值引用不能绑定左值，即使这个左值是右值引用类型的变量
虽然直接把右值引用类型的变量绑定到变量上，但可以使用 move 来获取绑定到左值上的右值引用。

	int&& q = std::move(m);    // 正确：std::move可以将左值转换为右值


[https://segmentfault.com/a/1190000044307595](https://segmentfault.com/a/1190000044307595)


**左值引用**：传统的 C++ 中引用被称为左值引用；  
**右值引用**：C++11 中增加了右值引用，右值引用关联到右值时，右值被存储到特定位置，右值引用指向该特定位置，也就是说，**右值虽然无法获取地址，但是右值引用是可以获取地址的**，该地址表示临时对象的存储位置；


### 112.STL中 hashtable 的实现？
STL中的 hashtable 使用的是**开链法**解决hash冲突问题；

hashtable中 的 bucket 所维护的 list 既不是 list 也不是 slist，而是其自己定义的由hashtable_node 数据结构组成的 linked-list，而 bucket 聚合体本身使用 vector 进行存储。**hashtable 的迭代器只提供前进操作，不提供后退操作**。

在hashtable设计bucket的数量上，其**内置了28个质数**[53, 97, 193,...,429496729]，在创建hashtable时，会**根据存入的元素个数选择大于等于元素个数的质数作为 hashtable 的容量**（vector的长度），其中**每个 bucket 所维护的 linked-list 长度也等于hashtable的容量**。如果插入 hashtable 的元素个数超过了 bucket 的容量，就要进行重建 table 操作，即找出下一个质数，创建新的 buckets vector，重新计算元素在新 hashtable 的位置。

<img src = "http://oss.interviewguide.cn/img/202205220035271.png"  weight="300" height = "200">

[https://github.com/Light-City/CPlusPlusThings/blob/master/src_analysis/stl/hashtable.md](https://github.com/Light-City/CPlusPlusThings/blob/master/src_analysis/stl/hashtable.md)

## 113.c++  traits 技法理解
**traits，又被叫做特性萃取技术**，说得简单点就是**提取“被传进的对象”对应的返回类型，让同一个接口实现对应的功能**。因为STL的算法和容器是分离的，两者通过迭代器链接。算法的实现并不知道自己被传进来什么。萃取器相当于在接口和实现之间加一层封装，来隐藏一些细节并协助调用合适的方法，这需要一些技巧（例如，偏特化）。

traits 技法利用“内嵌型别”的编程技巧与编译器的 template 参数推导功能，增强C++ 未能提供的关于型别认证方面的能力。常用的有 `iterator_traits` 和 `type_traits` 。

C++ 中的模板特性（Traits）是一种常见的技术，用于**在编译时提取或操作类型信息**。Traits类提供了一种灵活且可扩展的方法，用于实现类型特定的行为和元编程。Traits的主要作用包括：

- **类型信息提取**：提取类型的某些属性或信息，例如类型的基本类型、是否为指针、是否为某种类型的实例等。
- **类型操作**：定义某些类型转换或操作，例如从一种类型转换为另一种类型。
- **条件编译**：根据类型信息进行条件编译，以实现不同类型的特定行为。

[https://www.cnblogs.com/codemagiciant/p/17601959.html](https://www.cnblogs.com/codemagiciant/p/17601959.html)


## 114.STL的两级空间配置器

**为什么有适配器？**  
（1）小块内存带来的内存碎片问题；  
（2）小块内存频繁申请释放带来的性能问题；   
（3）小块空间太多会造成空间的浪费；

**STL里面的空间配置主要分为两级**：一级空间配置器(`__malloc_alloc_template`)和二级空间配置器(`__default_alloc_template`)。  
（1）在STL中默认**如果要分配的内存大于128个字节的话就是大块内存，调用一级空间配置器直接向系统申请**；  
直接采用malloc和free进行内存的申请和释放


（2）**如果小于等于128个字节的话则认为是小内存，则就去内存池中申请**。  
> `default_alloc_template` 维护着一个内存池，内存池每次分配内存都会分配一大块内存，并维护 free_list，free_list 是一个指针数组，free_list有16项，每一项都维护一个对应大小的内存块链表，大小分别为8、16、24、32、40、48、56、64、72、80、88、96、104、112、120、128；
> 
> 从 `free_list` 找到管理指定内存块大小的链表，如果该链表上没有内存块，那么就重新填充（从缓存块中获取内存，填充free_list对应的链表），之后将分配得到的内存块从链表中删除，再返回此内存块。

## 115.STL 中vector删除其中的元素，迭代器如何变化？为什么是两倍扩容？释放空间？

 C++ vector 容器利用类似于数组的连续内存空间来存储其元素，当利用其 `erase` 函数删除相应的元素之后，该容器会重新分配所有剩下的元素，同时 **erase 函数会返回指向已经删除的那些元素的下一个元素的迭代器**，**以前所有指向被删除元素以后的元素的迭代器会失效**。

size()函数返回的是已用空间大小，capacity()返回的是总空间大小，capacity()-size()则是剩余的可用空间大小。当size()和capacity()相等，说明vector目前的空间已被用完，如果再添加新元素，则会引起vector空间的动态增长。

可以使用`reserve(n)`预先分配一块较大的指定大小的内存空间，这样当指定大小的内存空间未使用完时，是不会重新分配内存空间的，这样便提升了效率。

整体的一个**扩容流程**为：  
申请新的内存空间（空间大小为原空间的两倍或一点五倍）—> 把原空间的元素拷贝到新的空间里 —> 释放原空间 —> 数组指针指向新空间。

使用k=2增长因子的问题在于，**每次扩展的新尺寸必然刚好大于之前分配的总和**，也就是说，之前分配的内存空间不可能被使用。

## 116.Vector如何释放空间?
1. **清空vector** ：用vector的clear()方法可以清空vector中的元素，但是并不会释放vector所占用的内存空间。这意味着，如果之后还需要往vector中添加元素，vector会尝试使用之前已经分配的内存空间，而不是重新分配内存空间。【如果需要释放vector占用的内存空间，<font color=blue>可以**在调用clear()方法之后再调用vector的shrink_to_fit()方法，该方法会将vector的容量减小到与其大小相等，从而释放多余的内存空间**。</font>】
2. **重新分配vector大小**：
可以使用resize()方法重新分配vector的大小，从而释放多余的内存空间。
3. **使用swap()方法**：
可以使用swap()方法交换两个vector的内容，从而释放一个vector占用的内存空间。
4. **使用移动语义**：
C++11引入了移动语义，可以通过将一个 vector **移动** 到另一个 vector 来释放内存空间。具体方法是，使用`std::move()`函数将一个vector移动到另一个vector中，然后将原vector置为空。


[https://www.cnblogs.com/ybqjymy/p/18054639](https://www.cnblogs.com/ybqjymy/p/18054639)

## 117.容器内部删除一个元素？
- **关联容器的删除**  
对于关联容器(如map, set,multimap,multiset)，**删除当前的iterator，仅仅会使当前的iterator失效**，只要在erase时，递增当前iterator即可。这是因为map之类的容器，使用了红黑树来实现，插入、删除一个结点不会对其他结点造成影响。erase迭代器只是被删元素的迭代器失效，但是返回值为void，所以要采用erase(iter++)的方式删除迭代器。
- **顺序容器的删除**  
顺序容器就是数组式容器，删除当前的iterator会使后面所有元素的iterator都失效。这是因为vetor，deque使用了连续分配的内存，删除一个元素导致后面所有的元素会向前移动一个位置。所以不能使用erase(iter++)的方式，还好erase方法可以返回下一个有效的iterator。
- **链表式容器的删除**  
对于list型的数据结构，使用了不连续分配的内存，删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器。解决办法两种，erase(*iter)会返回下一个有效迭代器的值，或者erase(iter++)。

## 118.STL迭代器如何实现？
1. 迭代器是一种抽象的设计理念，**通过迭代器可以在不了解容器内部原理的情况下遍历容器**，除此之外，STL中迭代器一个最重要的作用就是作为容器与STL算法的粘合剂。
2.  迭代器的作用就是**提供一个遍历容器内部所有元素的接口**，**因此迭代器内部必须保存一个与容器相关联的指针**，然后**重载各种运算操作来遍历**，其中最重要的是*运算符与->运算符，以及++、--等可能需要重载的运算符重载。这和C++中的智能指针很像，智能指针也是将一个指针封装，然后通过引用计数或是其他方法完成自动释放内存的功能。
3. 最常用的迭代器的相应型别有五种:value type、difference type、pointer、reference、iterator catagoly;

## 119.map、set是怎么实现的，红黑树是怎么能够同时实现这两种容器?为什么使用红黑树？
- 他们的底层都是以红黑树的结构实现，因此插入删除等操作都在O(logn)时间内完成，因此可以完成高效的插入删除；
- 在这里定义了一个模版参数，如果它是 key 那么它就是 set，如果它是map，那么它就是 map；底层是红黑树，实现 map 的红黑树的节点数据类型是key+value，而实现 set 的节点数据类型是value
- 因为 map 和 set 要求是自动排序的，红黑树能够实现这一功能，而且时间复杂度比较低。


> 红黑树和AVL树都是高效的平衡二叉树，复杂度都一样。**红黑树不追求绝对平衡，其只需保证最长路径不超过最短路径的2倍**，相对而言，**降低了插入和旋转的次数**，所以在经常进行增删的结构中性能比AVL树（当需要大量增删的时候，AVL树旋转次数太多，效率并不高）更优，而且红黑树实现比较简单，所以实际运用中红黑树更多。

## 120.如何在共享内存上使用STL标准库？
1. 一个最笨拙的办法是**在堆上构造STL容器，然后把容器复制到共享内存**，并且确保所有容器的内部分配的内存指向共享内存中的相应区域，这基本是个不可能完成的任务。
2. 进程A把容器放在共享内存中的确定地址上（fixed offsets），则进程B可以从该已知地址上获取容器。
3. 进程A先在共享内存**某块确定地址上放置一个map容器，然后进程A再创建其他容器，然后给其取个名字和地址一并保存到这个map容器里**。进程B知道如何获取该保存了地址映射的map容器，然后同样再根据名字取得其他容器的地址。

## 121.map插入方式有哪几种？
1. 用insert函数插入pair数据

    	mapStudent.insert(pair<int, string>(1, "student_one")); 

2. 用insert函数插入value_type数据

    	mapStudent.insert(map<int, string>::value_type (1, "student_one"));

3. 在insert函数中使用make_pair()函数

    	mapStudent.insert(make_pair(1, "student_one")); 

4. 用数组方式插入数据

    	mapStudent[1] = "student_one"; 

## 122.STL 中 unordered_map(hash_map) 和 map 的区别，hash_map 如何解决冲突以及扩容？
1、**需要引入的头文件不同**  
map: #include < map >  
unordered_map: #include < unordered_map >  

2、内部实现机理不同   
 map内部实现了一个红黑树，具有 **自动排序** 的功能，因此 map 内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素。因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行的操作。map中的元素是按照二叉搜索树存储的，使用 **中序遍历** 可将键值按照从小到大遍历出来。  
unordered_map内部实现了一个 **哈希表**（也叫散列表，通过把关键码值映射到Hash表中一个位置来访问记录，查找的时间复杂度可达到O(1)，其在海量数据处理中有着广泛应用）。因此，其元素的排列顺序是无序的。  

3、使用时 map 的 key 需要定义`operator<`。而unordered_map需要定义`hash_value`函数并且重载`operator=`=    
std::map 是一个 **排序的关联容器**，需要对键值进行比较，以确定元素的存储位置。默认情况下，std::map使用`operator<`来比较键；  
std::unordered_map是一个基于哈希的关联容器，它使用哈希函数来确定元素的存储位置，同时也需要一个比较函数来处理哈希冲突。默认情况下，std::unordered_map使用`std::hash`作为哈希函数，`operator==`作为比较函数。


**hash_map如何解决冲突？**

- 开放地址法：线性探测再散列、平方探测再散列；
- 拉链法：如果发生冲突，就继续往前一个元素上链接；
- 再哈希：如果发生冲突，就用另一个方法计算hashcode，两次结果值不一样就不会发生hash冲突；
- 建立公共溢出区：将哈希表分为基本表和溢出表两部分，与基本表发生冲突的元素，一律填入溢出表。


[https://blog.csdn.net/qq_43434328/article/details/115876864](https://blog.csdn.net/qq_43434328/article/details/115876864)



**hash_map如何扩容？**

哈希表（如std::unordered_map）的扩容是一个重要的过程，在 **装载因子（即哈希表中当前元素数量与哈希表大小的比值）** 达到或超过某个阈值（例如0.75）时发生。装载因子过高会增加哈希冲突的可能性，从而降低哈希表的性能。

1、**分配新内存**：首先，哈希表会分配一个新的、更大的内存块。新哈希表的大小通常是原来的两倍，但具体的扩展策略可能因具体的哈希表实现和特定的应用需求而不同。

2、**元素重新哈希**：然后，哈希表会遍历原来的所有元素，并使用哈希函数重新计算每个元素的哈希值。由于哈希表的大小已经改变，这通常会导致元素的哈希值也随之改变。

3、**元素迁移**：接着，哈希表会根据每个元素新的哈希值，将元素移动到新哈希表的相应位置。

4、**释放旧内存**：最后，一旦所有的元素都被成功地迁移到新的哈希表，就可以释放旧的哈希表占用的内存。

哈希表的扩容操作需要对所有元素进行重新哈希和迁移，因此时间复杂度为`O(n)`，其中`n`是哈希表中的元素数量。


## 123.vector越界访问下标，map越界访问下标？
- 在C++中，如果你 **使用operator[]来访问std::vector的元素，当下标越界时，编译器不会抛出任何错误或异常** ，而且它通常会**返回一个未定义的值**，这可能导致程序行为异常或崩溃。这种情况下，错误可能很难被检测到，因为程序可能会在某些情况下正常运行，但在其他情况下出现错误。  
【为了避免这种情况，C++提供了`std::vector::at()`成员函数，这个函数在访问超出std::vector范围的索引时 **会抛出std::out_of_range异常**。】


- 在C++的std::map中，使用operator[]**访问一个不存在的键会创建一个具有该键和默认值（通常为0或等效初始化值）的新元素**。  
【如果不希望在键不存在时创建新元素，你应该使用`std::map::find()`。（用 key 执行查找，找到了返回该位置的迭代器；如果不存在这个关键码，就返回尾迭代器）】

## 124.STL中list与queue之间的区别？
1. **容器类型**：std::list 是一个**双向链表**，而 std::queue 是一个队列，可以使用多种实现方式（如顺序容器、优先队列等）。
1. **插入和删除元素**：在 std::list 中，可以在任何位置插入和删除元素，而在 std::queue 中，只能在队尾插入元素，从队头删除元素。
1. **访问元素**：在 std::list 中，可以随机访问元素，而在 std::queue 中，只能顺序访问元素。
1. **存储方式**：std::list 采用链表存储元素，而 std::queue 采用顺序容器或优先队列等实现方式存储元素。
1. **适用场景**：std::list 适用于需要在任意位置进行插入和删除操作的场景，而 std::queue 适用于进行先进先出操作的场景。


## 125.常见容器性质总结？
C++ STL（Standard Template Library）提供了多种容器，用于存储和操作各种类型的数据。以下是一些常见容器的特性总结：

1.std::vector：动态数组，能高效地在末尾进行插入和删除操作，能直接访问任何元素。但在中间位置进行插入或删除操作则需要移动元素，效率较低。此外，当插入的元素超过当前分配的空间时，会重新分配内存，可能导致大规模元素移动。底层数据结构为数组

2.std::deque：双端队列，支持高效的头部和尾部插入和删除操作，并能直接访问任何元素。与std::vector相比，std::deque不保证元素在内存中的连续存储，因此当插入的元素超过当前分配的空间时，不需要移动其他元素。

3.std::queue：基于其它容器（如std::deque）实现的队列，支持两端的插入和删除操作。

4.std::priority_queue：基于其它容器（如std::vector）实现的优先队列，堆（heap）为处理规则来管理底层容器实现，元素按优先级排序。

5.std::list：底层数据结构为双向链表，能在任何位置高效地进行插入和删除操作。但不支持直接访问元素，只能通过迭代器进行访问。

6.std::forward_list：单向链表，只能从头部开始遍历，并只支持头部和后面的高效插入和删除操作。

7.std::array：固定大小的数组，提供与std::vector类似的接口，但其大小在编译时确定，无法动态改变。

8.std::set：底层数据结构为红黑树实现的有序集合，元素按排序顺序存储，每个元素只能出现一次。插入和查找操作的复杂度为对数级别。

9.std::multiset：与std::set类似，底层数据结构为红黑树，有序，允许元素重复。

10.std::map：底层数据结构为红黑树实现的有序映射表，存储键值对，键是唯一的，插入和查找操作的复杂度为对数级别。

11.std::unordered_map：基于哈希表实现的无序映射表，存储键值对，键是唯一的。在理想情况下，插入和查找操作的复杂度为常数级别。

12.std::multimap：与std::map类似，但允许键重复。

13.std::unordered_multimap：与std::unordered_map类似，但允许键重复。

14.std::unordered_set：基于哈希表实现的无序集合，每个元素只能出现一次。在理想情况下，插入和查找操作的复杂度为常数级别。

15.std::unordered_multiset：与std::unordered_set类似，但允许元素重复。

16.std::stack：基于其它容器（如std::deque）实现的栈，只支持顶部的插入和删除操作。


## 126.STL中的 allocator、deallocator
1) 第一级配置器直接使用malloc()、free()和relloc()，第二级配置器视情况采用不同的策略：当配置区块 超过128bytes时，视之为足够大，便调用第一级配置器；当配置器区块小于128bytes时，为了降低额外负担，使用复杂的内存池整理方式，而不再用一级配置器；

2) 第二级配置器主动将任何小额区块的内存需求量上调至8的倍数，并维护16个free-list，各自管理大小 为8~128bytes的小额区块。

3) 空间配置函数`allocate()`，首先判断区块大小，大于128就直接调用第一级配置器，小于128时就检查对 应的free-list。如果 free-list 之内有可用区块，就直接拿来用，如果没有可用区块，就将区块大小调整至8 的倍数，然后调用refill()，为free-list重新分配空间；

4) 空间释放函数`deallocate()`，该函数首先判断区块大小，大于128bytes 时，直接调用一级配置器，小于 128bytes 就找到对应的 free-list 然后释放内存。



## 127.STL 中 hash table 扩容发生什么?
当哈希表的元素数量增长到某个阈值时，就需要进行扩容。这个阈值通常是哈希表容量（bucket count）和装载因子（load factor）的乘积。装载因子是一个浮点数，它决定了哈希表元素数与容量之间的比例。默认装载因子通常是1.0。

当需要扩容时，STL会执行以下步骤：

1.创建一个新的、更大的哈希表。新的大小通常是原来大小的两倍。  
2.遍历原有哈希表中的所有元素，并重新计算它们在新哈希表中的位置（这个位置由元素的哈希值和新的哈希表大小决定）。  
3.将每个元素从旧的哈希表移动到新的哈希表的对应位置。

这个过程被称为 **rehashing**。这是一个相当消耗资源的操作，因为它涉及到重新计算每个元素的哈希值，并可能涉及到大量的内存操作。但是，通过这种方式，可以保证哈希表的性能，因为它能保证元素在哈希表中的分布更均匀，减少哈希冲突，提高查找效率。

注意，虽然扩容可以提高哈希表的性能，但是频繁的扩容操作会消耗大量的资源，影响程序的性能。因此，如果你预先知道哈希表需要存储大量的元素，可以通过 rehash 或 reserve 方法预先分配足够的空间，避免频繁的扩容操作。

[https://www.cnblogs.com/codemagiciant/p/17602267.html](https://www.cnblogs.com/codemagiciant/p/17602267.html)

## 128.hashtable 中解决冲突有哪些方法？

1. **开放定址法**；
	- 线行探查法：  
	使用 hash 函数计算出的位置如果已经有元素占用了，则向后依次寻找，找到表尾则回到表头，直到找到一个空位
	- 平方探查法：  
	使用hash函数计算出的位置如果已经有元素占用了，按照 $1^2$ 、$2^2$、$3^2...的步长依次寻找，如果步长是随机数序列，则称之为伪随机探测
	- 双散列函数探查法：  
	使用两个散列函数hl和h2，其探查序列的步长值是同一关键字的另一散列函数的值
2. **链地址法（拉链法）**：  
每个表格维护一个list，如果hash函数计算出的格子相同，则按顺序存在这个list中
3. **再哈希法**：  
发生冲突时使用另一种hash函数再计算一个地址，直到不冲突
4. **建立公共溢出区**：  
一旦hash函数计算的结果相同，就放入公共溢出区







## 129.C++的多态如何实现？
 在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将会根据所指对象的实如果对象类型是派生类，就调用派生类的函数，如果对象类型是际类型来调用相应的函数，基类，就调用基类的函数。

**具体过程：**

>**虚表**：虚函数表的缩写，类中含有 `virtual` 关键字修饰的方法时，编译器会自动生成；  
>**虚表虚表指针**：在含有虚函数的类实例化对象时，对象地址的前四个字节存储的指向虚表的指针。

（1）编译器在发现基类中有虚函数时，会自动**为每个含有虚函数的类生成一份虚表**，该表是一个一维数组，虚表里保存了虚函数的入口地址；  
（2）编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr，指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚指针 vptr，从而让 vptr 指向正确的虚表，从而在调用虚函数时，能找到正确的函数；  
（3）所谓的合适时机，在派生类定义对象时，程序运行会自动调用构造函数，在构造函数中创建虚表并对虚表初始化。在构造子类对象时，会先调用父类的构造函数，此时，编译器只“看到了"父类，并为父类对象初始化虚表指针，令它指向父类的虚表；当调用子类的构造函数时，为子类对象初始化虚表指针，令它指向子类的虚表。    
（4）**当派生类对基类的虚函数没有重写时，派生类的虚表指针指向的是基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向的是自身的虚表；**当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面。

这样指向派生类的基类指针在运行时，就可以根据派生类对虚函数重写情况动态的进行调用，从而实现多态性。

> C++中虚函数表位于只读**数据段(.rodata)**，也就是C++内存模型中的**常量区**；而虚函数则位于**代码段(.text)**，也就是C++内存模型中的**代码区**。

## 130.为什么析构函数一般写成虚函数？
由于类的多态性，基类指针可以指向派生类的对象，如果删除该基类的指针，就会调用该指针指向的派生类析构函数，而派生类的析构函数又自动调用基类的析构函数，这样整个派生类的对象完全被释放。

如果析构函数不被声明成虚函数，则编译器实施**静态绑定**，**在删除基类指针时，只会调用基类的析构函数而不调用派生类析构函数，这样就会造成派生类对象析构不完全，造成内存泄漏**。

## 131.模板函数和模板类的特例化
**引入原因**：
编写单一的模板，它能适应多种类型的需求，使每种类型都具有相同的功能，但对于某种特定类型，如果要实现其特有的功能，单一模板就无法做到，这时就需要**模板特例化**。


**定义**：
对单一模板提供的一个特殊实例，它将一个或多个模板参数绑定到特定的类型或值上。

**（1）模板函数特例化**  
必须为原函数模板的每个模板参数都提供实参，且使用关键字 `template` 后跟一个空尖括号对表明将原模板的所有模板参数提供实参。

	template<typename T> //模板函数
	int compare(const T &v1,const T &v2)
	{
	    if(v1 > v2) return -1;
	    if(v2 > v1) return 1;
	    return 0;
	}
	//模板特例化,满足针对字符串特定的比较，要提供所有实参，这里只有一个T
	template<> 
	int compare(const char* const &v1,const char* const &v2)
	{
	    return strcmp(p1,p2);
	}

特例化的本质是实例化一个模板，而非重载它。特例化不影响参数匹配。参数匹配都以最佳匹配为原则。

**（2）模板类特例化**   
原理类似函数模板，**不过在类中，我们可以对模板进行特例化，也可以对类进行部分特例**对类进行特例化时，仍然用`template<>`表示是一个特例化版本。

	template<>
	class hash<sales_data>
	{
		size_t operator()(sales_data& s);
		//里面所有T都换成特例化类型版本sales_data
		//按照最佳匹配原则，若T != sales_data，就用普通类模板，否则，就使用含有特定功能的特例化版本。
	};

特例化类中的部分成员，**可以特例化类中的部分成员函数而不是整个类**。

	template<typename T>
	class Foo
	{
	    void Bar();
	    void Barst(T a)();
	};
	
	template<>
	void Foo<int>::Bar()
	{
	    //进行int类型的特例化处理
	    cout << "我是int型特例化" << endl;
	}
	
	Foo<string> fs;
	Foo<int> fi;//使用特例化
	fs.Bar();//使用的是普通模板，即Foo<string>::Bar()
	fi.Bar();//特例化版本，执行Foo<int>::Bar()
	//Foo<string>::Bar()和Foo<int>::Bar()功能不同


## 132.C++模板是什么，你知道底层怎么实现的？
编译器并不是把函数模板处理成能够处理任意类的函数；**编译器从函数模板通过具体类型产生不同的函数**；  
编译器会对函数模板进行**两次编译**：在声明的地方对模板代码本身进行编译，在调用的地方对参数替换后的代码进行编译。

这是因为函数模板要被实例化后才能成为真正的函数，在使用函数模板的源文件中包含函数模板的头文件，如果该头文件中只有声明，没有定义，那编译器无法实例化该模板，最终导致链接错误。

## 133.构造函数析构函数可否抛出异常？
C++**只会析构已经完成的对象**，对象只有在其构造函数执行完毕才算是完全构造妥，当在构造函数中发生异常，控制权转出构造函数之外。  
因此，在对象 b 的构造函数中发生异常，对象 b 的析构函数不会被调用。因此会造成内存泄漏。

用 `auto_ptr` 对象来取代指针类成员，便对构造函数做了强化，免除了抛出异常时发生资源泄漏的危机，不再需要在析构函数中手动释放资源；

**如果控制权基于异常的因素离开析构函数**，而此时正有另一个异常处于作用状态 C++ 会调用 terminate 函数让程序结束；

如果异常从析构函数抛出，而且没有在当地进行捕捉，那个析构函数便是执行不全的。  
如果析构函数执行不全，就是没有完成他应该执行的每一件事情。


## 134.构造函数或者析构函数中可以调用虚函数吗？
可以，虚函数底层实现原理(但是最好不要在构造和析构函数中调用) 可以，但是**没有动态绑定的效果**，父类构造函数中调用的仍然是父类版本的函数，子类中调用的仍然是子类版本的函数。

a) 如果有继承，构造函数会先调用父类构造函数，而如果构造函数中有虚函数，此时子类还没有构造，所以此时的对象还是父类的，不会触发多态。更容易记的是基类构造期间，virtual 函数不是 virtual 函数。

b) 析构函数也是一样，子类先进行析构，这时，如果有 virtual 函数的话，子类的内容已经被析构了，C++会视其父类，执行父类的 virtual 函数。

## 135.构造函数的几种关键字
- `default` 关键字可以显式要求编译器生成合成构造函数，防止在调用时相关构造函数类型没有定义而报错；
- `delete` 关键字可以删除构造函数、赋值运算符函数等，这样在使用的时候会得到友善的提示；
- `0` 将虚函数定义为纯虚函数（纯虚函数无需定义），`=0`只能出现在类内部虚函数的声明语句处；当然，也可以为纯虚函数提供定义，函数体可以定义在类的外部也可以定义在内部。它在基类中没有定义，但**要求任何派生类都要定义自己的实现方法**。


## 136.拷贝构造函数和赋值运算符重载的区别？
- 拷贝构造函数是函数，赋值运算符是运算符重载。
- 拷贝构造函数会生成新的类对象，赋值运算符不能。
- 拷贝构造函数是直接构造一个新的类对象，所以在初始化对象前不需要检查源对象和新建对象是否相同；赋值运算符需要上述操作并提供两套不同的复制策略，另外赋值运算符中如果原来的对象有内存分配则需要先把内存释放掉。
- 形参传递是调用拷贝构造函数(调用的被赋值对象的拷贝构造函数)，但并不是所有出形参传递是调用拷贝构造函数(调用的被赋值对象的拷贝构造函数)，但并不是所有出。


## 137.什么是虚拟继承？
由于C++支持多重继承，那么在这种情况下会出现重复的基类这种情况，也就是说可能出现将一个类两次作为基类的可能性。如：类D继承自类B1、B2，而类B1、B2都继 承自类A，因此在类D中两次出现类A中的变量和函数。

为了节省内存空间，可以将B1、B2对A的继承定义为虚拟继承，而A就成了虚拟基类。

虚拟继承是多重继承中特有的概念。**虚拟基类是为解决多重继承而出现的**。

<font color=blue>虚继承的特点是，在任何派生类中的 `virtual` 基类总用同一个（共享）对象表示。</font>

**引入虚继承和直接继承会有什么区别呢**

由于有了间接性和共享性两个特征，所以决定了虚继承体系下的对象在访问时必然会在时间和空间上与一般情况有较大不同。

**时间**：在通过继承类对象访问虚基类对象中的成员（包括数据成员和函数成员）时，都必须通过某种间接引用来完成，这样会增加引用寻址时间（就和虚函数一样），其实就是调整 this 指针以指向虚基类对象，只不过这个调整是运行时间接完成的。

**空间**：由于共享所以不必要在对象内存中保存多份虚基类子对象的拷贝，这样较之多继承节省空间。虚拟继承与普通继承不同的是，虚拟继承可以防止出现 diamond 继承时，一个派生类中同时出现了两个基类的子对象。也就是说，为了保证 这一点，在虚拟继承情况下，基类子对象的布局是不同于普通继承的。因此，它**需要多出一个指向基类子对象的指针**。


    第一种情况：　　　　　　　　 第二种情况：　　　　　　　　　　第三种情况　　　　　　　　　　　　第四种情况：
	class a　　　　　　　　　　　class a　　　　　　　　　　　　  class a　　　　　　　　　　　　　　class a
	{　　　　　　　　　　　　　 {　　　　　　　　　　　　　　　 {　　　　　　　　　　　　　　　　　{
	    virtual void func();　　　　　　virtual void func();　　　　　　　virtual void func();　　　　　　　　virtual void func();
	};　　　　　　　　　　　　　 };　　　　　　　　　　　　　　　　　 char x;　　　　　　　　　　　　　　char x;
	class b:public virtual a　　　class b :public a　　　　　　　    };　　　　　　　　　　　　　　　　};
	{　　　　　　　　　　　　　　{　　　　　　　　　　　　　　 　class b:public virtual a　　　　　 class b:public a
	    virtual void foo();　　　　　　  virtual void foo();　　　　　{　　　　　　　　　　　　　　　　 {
	};　　　　　　　　　　　　　 };　　　　　　　　　　　　　　　　　　virtual void foo();　　　　　　　　virtual void foo();
	　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　};　　　　　　　　　　　　　　　　};
如果对这四种情况分别求sizeof(a）,  sizeof(b)。结果是什么样的呢？下面是输出结果：（在vc6.0中运行）
第一种：4，12
第二种：4，4
第三种：8，16
第四种：8，8

因为**每个存在虚函数的类都要有一个4字节的指针指向自己的虚函数表**，所以每种情况的类a所占的字节数应该是没有什么问题的，那么类b的字节数怎么算呢？看“第一种”和“第三种”情况采用的是虚继承，那么这时候就要有这样的一个指针 `vptr_b_a`，这个指针叫**虚类指针**，也是**四个字节**；**还要包括类a的字节数**，所以类b的字节数就求出来了。而“第二种”和“第四种”情况则不包括 `vptr_b_a` 这个指针。

[https://www.cnblogs.com/heyonggang/p/3255155.html](https://www.cnblogs.com/heyonggang/p/3255155.html)


## 138.什么情况会自动生成默认构造函数？
1. 带有默认构造函数的类成员对象，如果一个类没有任何构造函数，但它含有一个成员对象，而后者有默认构造函数，那么编译器就为该类合成出一个默认构造函数；
2. 带有默认构造函数的基类，如果一个没有任务构造函数的派生类派生自一个带有默认构造函数基类，那么该派生类会合成一个构造函数调用上一层基类的默认构造函数；
3. 带有一个虚函数的类；
4. 带有一个虚基类的类（ 虚基类是用关键字 `virtual` 声明继承的父类）；
5. 合成的默认构造函数中，只有基类子对象和成员类对象会被初始化。所有其他的非静态数据成员都不会被初始化。


## 139.抽象基类为什么不能创建对象？
抽象类是一种特殊的类，它是为了抽象和设计的目的为建立的，它处于继承层次结构的较上层。

（1）抽象类的定义：称带有纯虚函数的类为抽象类。

（2）抽象类的作用：抽象类的主要作用是**将有关的操作作为结果接口组织在一个继承层次结构中，由它来为派生类提供一 个公共的根，派生类将具体实现在其基类中作为接口的操作**。所以派生类实际上刻画了一组子类的操作接口的通用语义，这些语义也传给子类，子类可以具体实现这些语义，也可以再将这些语义传给自己的子类。

（3）使用抽象类时注意：抽象类只能作为基类来使用，其纯虚函数的实现由派生类给出。如果派生类中没有重新定义纯虚函数，而只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体的类。

## 140.模板类和模板函数的区别是什么？
函数模板的实例化是**由编译程序在处理函数调用时自动完成的**，而类模板的实例化必须**由程序员在程序中显式地指定**。

即**函数模板允许隐式调用和显式调用**而**类模板只能显示调用**。在使用时类模板必须加`<T>`，而函数模板不必。


## 141.无论是系统默认还是自定义的拷贝构造函数，都是传一个引用，而不是值，这是为什么呢？
若拷贝构造函数参数为值传递，当**实参赋值给形参时，又发生了一次拷贝函数的调用**，无限递归下去，导致爆栈。

拷贝构造函数用来初始化一个非引用类类型对象，如果用传值的方式进行传参数，那么**构造实参需要调用拷贝构造函数**，而拷贝构造函数需要传递实参，所以会一直递归。

拷贝构造函数参数为引用，不为值传递是为了**防止拷贝构造函数的无限递归**，最终导致栈溢出。


[https://pabebezz.github.io/article/c13c7aad/](https://pabebezz.github.io/article/c13c7aad/)


## 142.静态函数能定义为虚函数吗？常函数呢？说说你的理解？
1、static成员不属于任何类对象或类实例，所以即使给此函数加上virutal也是没有任何意义的；

2、静态与非静态成员函数之间有一个主要的区别，那就是静态成员函数没有this指针。它没有this指针，所以无法访问vptr【static 函数不能为 virtual 】。

## 143.虚函数的代价是什么?
- 带有虚函数的类，每一个类会**产生一个虚函数表**，用来存储指向虚成员函数的指针，增大类；
- 带有虚函数的类的每一个对象，都会有有一个指向**虚表的指针**，会增加对象的空间大小；
- 不能再是内联的函数，因为内联函数在编译阶段进行替代，而虚函数表示等待，在运行阶段才能确定到低是采用哪种函数，**虚函数不能是内联函数**。

## 144.哪些函数不能是虚函数？把你知道的都说一说？
1. **构造函数**，构造函数初始化对象，派生类必须知道基类函数干了什么，才能进行构造当有虚函数时，每一个类有一个虚表，每一个对象有一个虚表指针，虚表指针在构造函数中初始化;
2. **内联函数**，内联函数表示在编译阶段进行函数体的替换操作，而虚函数意味着在运行期间进行类型确定，所以内联函数不能是虚函数；
3. **静态函数**，静态函数不属于对象属于类，静态成员函数没有 `this` 指针，因此静态函数设置为虚函数没有任何意义。
4. **友元函数**，友元函数不属于类的成员函数，不能被继承。对于没有继承特性的函数没有虚函数的说法。
5. **普通函数**，普通函数不属于类的成员函数，不具有继承特性，因此普通函数没有虚函S数。


## 145.什么是纯虚函数，与虚函数的区别？
虚函数是有实现的，而纯虚函数没有实现。** 虚函数在基类中有默认实现，子类可以重写它，也可以不重写，但纯虚函数必须在子类中实现**。   
如果一个类中包含至少一个纯虚函数，那么这个类就是抽象类，不能直接实例化对象。 而虚函数不会强制一个类成为抽象类。

## 146.构造函数的执行顺序是什么?
1. 在派生类构造函数中，所有的虚基类及上一层基类的构造函数调用；
2. 对象的 `vptr` 被初始化；
3. 如果有成员初始化列表，将在构造函数体内扩展开来，这必须在 `vptr` 被设定之后才做；
4. 执行程序员所提供的代码；

---

# 操作系统

## 1.将字符串 “hello world" 从开始到打印到屏幕上的全过程？

1. 用户告诉操作系统执行 HelloWorld 程序（通过键盘输入等）
2. 操作系统：找到 helloworld 程序的相关信息，检查其类型是否是可执行文件；并通过程序首部信息，确定代码和数据在可执行文件中的位置并计算出对应的磁盘块地址;
3. 操作系统：**创建一个新进程**，将 HelloWorld 可执行文件**映射到该进程**结构，表示由该进程执行 helloworld 程序。

4. 操作系统：为 helloworld 程序**设置 cpu 上下文环境**，并**跳到程序开始处**。

5. 执行 helloworld 程序的第一条指令，发生**缺页异常**；

6. 操作系统：分配一页物理内存，并将代码**从磁盘读入内存**，然后继续执行helloworld程序;

7. helloword 程序**执行 puts 函数（系统调用）**，在显示器上写一字符串；

8. 操作系统：找到要**将字符串送往的显示设备**，通常设备是由一个进程控制的，所以，**操作系统将要写的字符串送给该进程**

9. 操作系统：控制设备的进程告诉设备的窗口系统，它要显示该字符串，窗口系统确定这是一个合法 的操作，然后将字符串转换成像素，**将像素写入设备的存储映像区**；

10. 视频硬件将像素转换成显示器可接收和一组控制数据信号；

11. 显示器解释信号，激发液晶屏；

12. OK，我们在屏幕上看到了HelloWorld；

## 2.进程、线程和协程的区别和联系
- **进程**： 是操作系统进行 **资源分配的基本单位** ，每个进程都有自己的独立内存空间。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。  
对于操作系统来说，***一个任务就是一个进程（Process）***；

- **线程**： 又叫做轻量级进程，是进程的一个实体，是 **处理器任务调度和执行的基本单位** 。它是比进程更小的能独立运行的基本单位。线程只拥有一点在运行中必不可少的资源(**如程序计数器，一组寄存器和栈**)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。  
由于每个进程至少要干一件事，所以， ***一个进程至少有一个线程***。

- **协程** ：又称微线程，是一种用户态的轻量级线程，协程的 **调度完全由用户控制** （也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。  **线程是抢占式，而协程是非抢占式的**，所以需要用户代码释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。
因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和线程切换相比，**线程数量越多，协程的性能优势就越明显**。



[https://cloud.tencent.com/developer/article/1839604](https://cloud.tencent.com/developer/article/1839604)

## 3.线程和进程的区别？
- 调度：线程是调度的基本单位(PC，状态码，通用寄存器，线程栈及栈指针)；进程是拥有资源的基本单位(打开文件，堆，静态区，代码段等)。
- 并发性：一个进程内多个线程可以并发(最好和CPU核数相等)；多个进程可以并发。
- 拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享隶属进程的资源；进程是拥有资源的独立单位。
- 系统开销：线程创建销毁只需要处理 PC 值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁 `task_struct` 结构。

## 4.一个进程可以创建多少线程，和什么有关？
- 如果是32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 如果是 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制而会受系统的参数或性能限制。

过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负
面影响，无用线程要及时销毁。

## 5.外中断和异常有什么区别？
外中断是指**由 CPU 执行指令以外的事件引起**，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

而异常时**由 CPU 执行指令的内部事件引起**，如非法操作码、地址越界、算术溢出等。

[https://www.cnblogs.com/codemagiciant/p/17707137.html](https://www.cnblogs.com/codemagiciant/p/17707137.html)


## 6.进程线程模型你知道多少？

**多线程**

同一个进程内部有多个线程，所有的线程共享同个进程的内存空间，进程中定义的全局变量会被所有的线程共享；

除了标识线程的`tid`，**每个线程还有自己独立的栈空间**，线程彼此之间是无法访问其他线程栈上内容的。

原先顺序执行的程序（暂时不考虑多进程）可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务（最好这些任务是不相关的）。

而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和PC即可，相比进程切换开销要小很多。


- 线程之间有无先后访问顺序(线程依赖关系)
- 多个线程共享访问同一变量(同步互斥问题)


**多进程**

每一个进程是资源分配的基本单位。

进程结构由以下几个部分组成：代码段、堆栈段、数据段。**代码段是静态的二进制代码，多个程序可以共享**。

实际上在父进程创建子进程之后，父、子进程除了 pid 外，几乎所有的部分几乎一样。

父、子进程共享全部数据，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过**写时复制机制将公共的数据重新拷贝一份**，之后在拷贝出的数据上进行操作。

如果子进程想要运行自己的代码段，还可以通过调用`execv()`函数重新加载新的代码段，之后就和父进程独立开了。



每个线程都是一个轻量级进程(Light Weight Process)，都有自己的唯一PID和一个**TGID**(Thread group ID)。TGID是启动整个进程的thread的PID。例如，当一个进程被创建的时候，它其实是一个PID和TGID数值相同线程。当线程A启动线程B时，线程B会有自己的唯一PID，但它的TGID会从A继承而来。这样通过PID线程可以独立得到调度，而**相同的TGID可以知道哪些线程属于同一个进程，这样可以共享资源(RAM，虚拟内存、文件等)**。

线程进程的区别体现在6个方面：

1. **根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
1. **资源开销**：每个进程都有独立的代码和数据空间，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一进程的线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
1. **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的。
1. **内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。
1. **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
1. **执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。两者均可并发执行。


## 7.进程调度算法你了解多少？
- **先来先服务**：按照请求的顺序进行调度。 这种调度方式简单，但是能导致较长作业阻塞较短作业。
- **最短作业优先**：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。 但是如果一直有短作业到来，那么长作业永远得不到调度，造成长作业“饥饿”现象。
- **高响应比优先**：既考虑作业的执行时间也考虑作业的等待时间，综合了先来先服务和最短作业优先两种算法的特点。先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行；优先权 = （等待时间 + 要求服务时间）/ 要求服务时间；
- **最短剩余时间优先**：基于最短作业优先改进，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。
- **优先级调度**：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
- **时间片轮转**：为每个进程分配一个时间片，进程轮流执行，时间片用完后切换到下一个进程。
- **多级反馈队列**：时间片轮转算法」和「最高优先级算法」的综合和发展。【多级】表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。【反馈】表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

## 8.进程间的通信方式(IPC)有哪些？
每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）。

- **管道**：一种半双工（即数据只能在一个方向上流动）的通信方式，数据只能单向流动，通信的数据是无格式的流并且大小受限，而且只能在具有亲缘关系（兄弟、父子）的进程间使用。进程写入的数据都是 **缓存在内核** 中，另一个进程读取数据时候也是从内核中获取。同时通信数据都遵循 **先进先出** 原则，不支持 `lseek` 之类的文件定位操作。
- **消息队列**：消息队列的消息体是**可以用户自定义的数据类型**，发送数据时，会被分成一个一个独立的消息体，由消息的**链表**，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列通信的速度不是最及时的，毕竟 **每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程** 。
- **共享内存**：解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销， **直接分配一个共享空间，每个进程都可以直接访问** 。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制（如信号量）配合使用来实现进程间的同步和通信。共享内存是**临界资源**，所以需要操作时必须要保证原子性。使用信号量或者互斥锁都可以。
- **信号量**：一个计数器，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作（p 操作为申请资源，会将数值减去M，v 操作是归还资源操作），可以用来控制多个进程对共享资源的访问。它常作为一种**锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
- **信号**：是软件中断产生，用于进程间异步传递信息。信号可以用来直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。进程有三种方式响应信号 **1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`；一共有`64`种信号，在shell中输入` kill -l `可查阅
- **套接字(socket)**：套接字允许两个进程进行通讯，这两个进程可能运行在同一个机器上，也可能运行在不同机器上。套接字只能一对一。此外由于**序列化等操作占用大量资源**，相对于共享内存，套接字更适合传输少量数据。


## 9.解释一下进程同步和互斥，以及如何实现进程同步和互斥？
**进程同步**是指多个并发执行的进程之间协调和管理它们的执行顺序，以确保它们按照一定的顺序或时间间隔执行。

**互斥**指的是在某一时刻只允许一个进程访问某个共享资源。当一个进程正在使用共享资源时，其他进程不能同时访问该资源。

解决进程同步和互斥的问题有很多种方法，其中一种常见的方法是使用**信号量和 PV 操作**。信号量是一种特殊的变量，它表示系统中某种资源的数量或者状态。PV 操作是一种对信号量进行增加或者减少的操作，它们可以用来控制进程之间的同步或者互斥。

- P操作：相当于“检查”信号量，如果资源可用，就减少计数，然后使用资源。
- V操作：相当于“归还”资源，增加信号量的计数，并可能唤醒等待的进程。

除此之外，下面的方法也可以解决进程同步和互斥问题：

- **临界区**：将可能引发互斥问题的代码段称为临界区，里面包含了需要互斥访问的资源。进入这个区域前需要先获取锁，退出临界区后释放该锁。这确保同一时间只有一个进程可以进入临界区。
- **互斥锁（Mutex）**：互斥锁是一种同步机制，用于实现互斥。每个共享资源都关联一个互斥锁，进程在访问该资源前需要先获取互斥锁，使用完后释放锁。只有获得锁的进程才能访问共享资源。
- **条件变量**：条件变量**用于在进程之间传递信息**，以便它们在特定条件下等待或唤醒。通常与互斥锁一起使用，以确保等待和唤醒的操作在正确的时机执行。


<font color = red>
POSIX 信号量：可用于进程同步，也可用于线程同步。  
**POSIX 互斥锁 + 条件变量：只能用于线程同步。**
</font>

## 10.如果系统中具有快表后，那么地址的转换过程变成什么样了?
**快表**， 又称联想寄存器（TLB， translation lookaside buffer ） ， 是一种访问速度比内存快很多的**高速缓存**（TLB不是内存！） ， 用来<font color=red>存放最近访问的页表项的副本</font>， 可以加速地址变换的速度。与此对应， **内存中的页表常称为慢表**。


**引入快表后，地址的变换过程**

1. CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较；
1. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。
1. 因此，**若快表命中，则访问某个逻辑地址仅需一次访存即可**。
1. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。
1. 因此，**若快表未命中，则访问某个逻辑地址需要两次访存**（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但**若快表已满，则必须按照一定的算法对旧的页表项进行替换**）。


[http://t.csdnimg.cn/Lfdji](http://t.csdnimg.cn/Lfdji)  
[https://blog.csdn.net/qq_41375318/article/details/102851088](https://blog.csdn.net/qq_41375318/article/details/102851088)

## 11.内存交换和覆盖有什么区别？
**交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中**。 覆盖和交换技术是在多道程序环境下用来扩充内存的两种方法。 覆盖技术主要用在早期的操作系统中，而交换技术则在现代操作系统中仍具有较强的生命力。

1、内存覆盖（Overlay）

在早期的计算机系统中，主存容量很小。虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生。这一矛盾可以用覆盖技术来解决。覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序）， 因此**可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。**  

2、内存交换（Swapping）

交换（对换）的基本思想是：

**把处于等待（阻塞）状态（或在CPU调度原则下被剥夺运行权利）的程序（进程）从内存移到辅存（外存）**，把内存空间腾出来，这一过程又叫换出。把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。中级调度（策略）就是釆用交换技术。

## 12.动态分区分配算法有哪几种?可以分别说说吗?
**1、首次适应算法**

**算法思想**：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。  
**如何实现**：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链（ 或空闲分［表），找到大小能满足要求的第一个空闲分区。

<img src ="http://oss.interviewguide.cn/img/202205220001798.png">

**2、最佳适应算法**

**算法思想**：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。

**如何实现**：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001901.png">

**3、最坏适应算法**

又称最大适应算法（Largest Fit）

**算法思想**：为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

**如何实现**：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001434.png">

**4、邻近适应算法**

**算法思想**：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

**如何实现**：空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001500.png">


## 13.虚拟技术你了解吗？
虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

**多进程与多线程**：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

**虚拟内存使用了空分复用技术**，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。


## 14.进程状态的切换你知道多少？
<img src="http://oss.interviewguide.cn/img/202205220001439.png">

就绪状态(ready)：等待被调度；  
运行状态(running)；  
阻塞状态(waiting)：等待资源；  

1. **只有就绪态和运行态可以相互转换**，**其它的都是单向转换**。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。

2. **阻塞状态是缺少需要的资源从而由运行状态转换而来**，但是该资源不包括 CPU 时间，缺少 CPU 时间 会从运行态转换为就绪态。

## 15.通过例子讲解逻辑地址转换为物理地址的基本过程？
**逻辑地址（Logical Address）**：在计算机体系结构中是指应用程序角度看到的内存单元（memory cell）、存储单元（storage element）、网络主机（network host）的地址，又叫**相对地址**。 是在网络层及以上使用的地址（ip地址就是其中一种）。  `逻辑地址=页号地址+页内地址`

**物理地址（Physical Address）**：是在存储器里以字节为单位存储信息，为正确地存放或取得信息，每一个字节单元给以一个唯一的存储器地址，又叫实际地址、绝对地址、mac 地址或硬件地址。是在数据链路层和物理层使用的地址。  `物理地址=块号地址+块内地址=块号地址+页内地址`  `块号地址=块号∗块大小`     

<font color = blue> 逻辑地址和物理地址相互转换的本质是块号地址和页号地址的相互转换。</font>

可以借助进程的页表将逻辑地址转换为物理地址

通常会在系统中设置一个**页表寄存器(PTR)**，存放页表在内存中的起始地址 F 和页表长度 M。**进程未执行时，页表的始址和页表长度放在进程控制块(PCB)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。**

<img src="http://oss.interviewguide.cn/img/202205220001941.png">

①计算页号、页内偏移量 页号` P=A/L=2500/1024=2`；页内偏移量    `W= A%L
=2500%1024=452`  ；
②根据题中条件可知，页号 2 没有越界，其存放的内存块号`b=8` ；   
③物理地址 `E=b*L+W=8*1024+425=8644`。

在分页存储管理（页式管理）的系统中，只要确定了每个页面的大小，逻辑地址结构就确定了。因此，**页式管理中地址是一维的**。即，**只要给出一个逻辑地址，系统就可以自动地算出页号、页内偏移量两个部分**，并不需要显式地告诉系统这个逻辑地址中，页内偏移量占多少位。

## 16.进程同步的四种方法？
1. 临界区：为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查；
2. 同步与互斥：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系，多个进程在同一时刻只有一个进程能进入临界区；
3. 信号量：down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断；
4. 管程；

管程的两个主要功能：

- **互斥访问**：管程确保多个线程对共享变量的访问互斥，即同一时间只有一个线程可以访问共享资源，以避免竞态条件和数据不一致性问题。
- **条件等待和通知**：管程提供了等待线程满足特定条件的机制，线程可以通过条件变量等待某个条件满足后再继续执行，或者通过条件变量通知其他线程某个条件已经满足。


管程有一个重要特性：**在一个时刻只能有一个进程使用管程**。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程由以下几个主要部分组成：

- **共享变量**：管程中包含了共享的变量或数据结构，多个线程或进程需要通过管程来访问和修改这些共享资源。
- **互斥锁（Mutex）**：互斥锁是管程中的一个关键组成部分，用于确保在同一时间只有一个线程或进程可以进入管程。一旦一个线程或进程进入管程，其他线程或进程必须等待，直到当前线程或进程退出管程。
- **条件变量（Condition Variables）**：条件变量用于实现线程或进程之间的等待和通知机制。当一个线程或进程需要等待某个条件满足时（比如某个共享资源的状态），它可以通过条件变量进入等待状态。当其他线程或进程满足了这个条件时，它们可以通过条件变量发送信号来唤醒等待的线程或进程。
- **管程接口（对管程进行操作的函数）**：管程还包括了一组操作共享资源的接口或方法。这些接口定义了对共享资源的操作，并且在内部实现中包含了互斥锁和条件变量的管理逻辑。其他线程或进程通过调用这些接口来访问共享资源，从而确保了对共享资源的有序访问。

[http://t.csdnimg.cn/oZeJL](http://t.csdnimg.cn/oZeJL)



## 17.操作系统在对内存进行管理的时候需要做些什么？
- 操作系统负责**内存空间的分配与回收**；
- 操作系统需要提供某种技术**从逻辑上对内存空间进行扩充**；
- 操作系统需要提**地址转换功能**，负责程序的逻辑地址与物理地址的转；
- 操作系统需要提供**内存保护功能**。保证各进程在各自存储空间内运行，互不干扰。


## 18.虚拟内存的目的是什么？
- 第一，虚拟内存可以使得进**程对运行内存超过物理内存大小**，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了**多进程之间地址冲突**的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了**更好的安全性**。
> **局部性原理**是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。


## 19.说一下你理解中的内存?他有什么作用呢？
内存（Memory）是计算机中最重要的部件之一，它是 **程序与CPU进行沟通的桥梁**。计算机中所有程序的运行都是在内存中进行的，因此内存对计算机的影响非常大，内存又被称为**主存**，其作用是**存放 CPU 中的运算数据，以及与硬盘等外部存储设备交换的数据**。只要计算机在运行中，CPU 就会把需要运算的数据调到主存中进行运算，当运算完成后CPU再将结果传送出来，主存的运行也决定了计算机的稳定运行。

## 20.介绍一下几种典型的锁？
**1.读写锁**

- 多个读者可以同时进行读
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）

**2.互斥锁**

- 一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以**互斥锁在加锁操作时涉及上下文的切换**。互斥锁实际的效率还是可以让人接受的，加锁的时间大概 100ns 左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁。

**3.条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而**条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足**，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。**总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制**。

**4.自旋锁**

如果进线程无法取得锁，进线程不会立刻放弃 CPU 时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁那么自旋就是在浪费 CPU 做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。


## 21.操作系统中的逻辑地址和物理地址
- **逻辑地址**  
是在**程序运行时由 CPU 生成的**。逻辑地址是虚拟地址，因为它在物理上不存在，因此也称为虚拟地址。此地址用作 CPU 访问物理内存位置的参考。术语逻辑地址空间用于由程序的角度生成的所有逻辑地址的集合。 内存管理单元的硬件设备用于将逻辑地址映射到其相应的物理地址。
 
- **物理地址**  
 标识内存中所需数据的物理位置。**用户从不直接处理物理地址，但可以通过其对应的逻辑地址进行访问**。用户程序生成逻辑地址，认为程序运行在这个逻辑地址上，但程序需要物理内存来执行，因此，**逻辑地址必须通过MMU映射到物理地址才能使用**。术语物理地址空间用于与逻辑地址空间中的逻辑地址对应的所有物理地址。

## 22.怎么回收线程？有哪几种方法？
线程的资源回收通常包括两个方面：

1. 线程的**内存资源回收**：当一个线程执行完毕或被终止时，系统会自动回收该线程的内存资源，将其占用的内存空间交还给操作系统。
2. 线程的**句柄资源回收**：系统中的每个线程都有一个唯一的线程句柄，用于标识线程、控制线程的执行等。当线程执行完毕或被终止后，需要将其句柄资源回收，以便其他线程可以使用该句柄。


**1.等待线程结束**：`int pthread_join(pthread_t tid, void** retval);`

主线程调用，等待子线程退出并回收其资源，类似于进程中 `wait/waitpid` 回收僵尸进程，调用 `pthread_join` 的线程会被阻塞。   
`tid`：创建线程时通过指针得到 `tid` 值。  
`retval`：指向返回值的指针。

**2.结束线程**：`pthread_exit(void *retval);`

子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过 `pthread_join` 获得。  
`retval`：指向返回值的指针。

**3.分离线程**：`int pthread_detach(pthread_t tid);`

主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中 `pthread_detach(pthread_self())`，调用后和主线程分离，子线程结束时自己立即回收资源。  
`tid`：创建线程时通过指针得到 `tid` 值。

可结合的线程的几种退出方式：

1. 子线程使用 `return` 退出，主线程中使用 `pthread_join` 回收线程；
2. 子线程使用 `pthread_exit` 退出，主线程中使用 `pthread_join` 接收 `pthread_exit` 的返回值，并回收线程；
3. 主线程中调用 `pthread_cancel`，然后调用 `pthread_join` 回收线程；


[http://t.csdnimg.cn/K2B7j](http://t.csdnimg.cn/K2B7j)

## 23.终端退出，终端运行的进程会怎样？
在 linux 上作业的**终端对应了一个 bash 进程，在其上运行的命令和程序都是 bash的子进程，或由bash的子进程衍生**。

在 linux 下，**一个 session 是由一组进程组构成的**，每个进程组又由多个进程构成。
在一个 bash 上运行的程序都归属于一个 session（除非特别处理），而这个 **bash 就是这个 session 的leader**。每个 session 又可以关联一个控制终端（Controlling Terminal）。

终端在退出时会发送 `SIGHUP` 给对应的 `bash` 进程，`bash` 进程收到这个信号后首先将它发给 `session` 下面的进程【bash 在第一次收到 SIGHUP 时先把信号发给 session 内其他进程，然后再次发送SIGHUP命令给自己，将自己杀死】，如果程序没有对 `SIGHUP` 信号做特殊处理，那么进程就会随着终端关闭而退出。

> 在 Linux 系统中，kill -SIGHUP 是发送 SIGHUP 信号给进程的命令。 **SIGHUP 是一种用于通知进程重新读取配置文件或重新加载的信号，通常用于重新启动服务或重新加载配置**。 当进程收到 SIGHUP 信号时，它会尝试重新读取其配置文件或重新加载，以使最新的配置生效。

> Shell session 是终端中当前的状态，在终端中只能有一个 session。当我们打开一个新的终端时，总会创建一个新的 shell session。

[http://t.csdnimg.cn/lLgP4](http://t.csdnimg.cn/lLgP4)  
[https://www.cnblogs.com/sparkdev/p/12146305.html](https://www.cnblogs.com/sparkdev/p/12146305.html)

## 24.如何让进程后台运行？
当我们在终端或控制台工作时，可能不希望由于运行一个作业而占住了屏幕。
为了使这些进程能够在后台运行，也就是说不在终端屏幕上运行，有几种选择方法可供使用：

- **命令后面加上 `&` 即可**，实际上，这样是将命令放入到一个作业队列中了，`e.g. sh test.sh &`；
- **`ctrl + z `命令**：将一个正在前台执行的命令放到后台，并且处于暂停状态；
- `nohup +&`，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断(SIGHUP)信号；
- **运行指令前面 +setsid**，使其父进程编程 init 进程，不受 HUP 信号的影响；
- 将命令`+&`放在 `()` 括号中，也可以是进程不受 HUP 信号的影响；

> 使用 & 命令后，作业被提交到后台运行，当前控制台没有被占用，但是一但把当前控制台关掉(退出帐户时)，作业就会停止运行。nohup 命令可以在你退出帐户之后继续运行相应的进程。nohup 就是不挂起的意思( no hang up / ignoring hangup signals) 即忽略挂起信号一直在后台执行。



**查看后台运行的命令：** `ps` 和 `jobs`。区别在于 `jobs` 只能查看当前终端后台执行的任务，换了终端就看不见了；而 `ps` 命令适用于查看瞬时进程的动态，可以看到别的终端的任务。  

**前后台进程的切换与控制：**  
`fg` 将后台中的命令调至前台继续运行。如果后台中有多个命令，可以用 `fg %jobnumber`（是命令编号，不是进程号）将选中的命令调出；  
`bg`  将一个在后台暂停的命令，变成在后台继续执行。如果后台中有多个命令，可以用`bg %jobnumber`将选中的命令调出。



[https://www.cnblogs.com/FLY_DREAM/p/13881674.html](https://www.cnblogs.com/FLY_DREAM/p/13881674.html)


## 25.守护进程、僵尸进程和孤儿进程？
**1.孤儿进程**  
一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 init 进程(进程号为1)所收养，并由 init 进程对它们完成状态收集工作。  
由于孤儿进程会被 init 进程给收养，所以孤儿进程不会对系统造成危害

**2.僵尸进程**    
一个进程使用 `fork` 创建子进程，如果子进程退出，而父进程并没有调用 `wait` 或 `waitpid` 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

**3.守护进程**  
Linux Daemon（守护进程）是运行在后台的一种特殊进程。它**独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件**。它不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。Linux 系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程 syslogd、 web 服务器 httpd、邮件服务器 sendmail 和数据库服务器 mysqld 等。

**守护进程一般在系统启动时开始运行**，除非强行终止，否则直到系统关机都保持运行。守护进程经常以超级用户（root）权限运行，因为它们要使用特殊的端口（`1-1024`）或访问某些特殊的资源。

**一个守护进程的父进程是 init 进程**，因为它真正的父进程在fork出子进程后就先于子进程 exit 退出了，所以它是一个由 init 继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备 stdout还是标准出错设备stderr的输出都需要特殊处理。

**守护进程的名称通常以d结尾，比如sshd、xinetd、crond等**

**编写守护进程的一般步骤步骤：**  
（1）在父进程中执行 `fork` 并 `exit` 退出；  
（2）在子进程中调用 `setsid` 函数创建新的会话（成长为新的会话与进程组长，与原来的登录会话、进程组和控制终端脱离）；  
（3）在子进程中调用 `chdir` 函数，让根目录 ”`/`” 成为子进程的工作目录（进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录）；  
（4）在子进程中调用 `umask` 函数，设置进程的 `umask` 为 `0`（进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除）；  
（5）在子进程中关闭任何不需要的文件描述符（进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误） 。

**创建守护进程的三种方式**

- 使用nohup命令；
- 使用fork()函数按步骤创建；
- daemon() 函数直接创建守护进程；

[Linux 之守护进程、僵死进程与孤儿进程](https://liubigbin.github.io/2016/03/11/Linux-%E4%B9%8B%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%E3%80%81%E5%83%B5%E6%AD%BB%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/)




## 26.如何避免僵尸进程？
1.在 `fork` 后调用 `wait/waitpid` 函数取得子进程退出状态。

2.调用 `fork` 两次（第一次调用产生一个子进程，第二次调用`fork`是在第一个子进程中调用，同时将父进程退出（第一个子进程退出），此时的第二个子进程的父进程`id`为`init`进程id（注意：新版本Ubuntu并不是init的进程id））。

3.在程序中显示忽略 `SIGCHLD` 信号（子进程退出时会产生一个SIGCHLD信号，我们显示忽略此信号即可）。

4.捕获 `SIGCHLD` 信号并在捕获程序中调用`wait/waitpid`函数。 


[https://www.51cto.com/article/628082.html](https://www.51cto.com/article/628082.html)


## 27.局部性原理你知道吗？主要有哪两大局部性原理?各自是什么？
主要分为**时间局部性**和**空间局部性**。

**时间局部性**：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)；

**空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)。


<img src="http://oss.interviewguide.cn/img/202205212344455.png">

## 28.父进程、子进程、进程组、作业和会话
**1.进程&子进程**

进程是程序的一个具体实现。

**父进程**：已创建一个或多个子进程的进程

**子进程**：由 `fork` 创建的新进程被称为子进程(child process)。该函数被调用一次，但返回两次。两次返回的区别是 **子进程的返回值是 0** ，而 **父进程的返回值则是新进程(子进程)的进程id** 。

将子进程 id 返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程 id。对子进程来说，之所以 fork 返回 0 给它，是因为它随时可以调用`getpid(0)`来获取自己的`pid`；也可以调用`getppid()`来获取父进程的 id。(进程id 0总是由交换进程使用，所以一个子进程的进程 id 不可能为 0)。

fork 之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这 **2 个进程共亨代码空间**，但是**数据空间是互相独立的**，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（**两进程的程序计数器 pc（PC指向的是下一条指令指令） 值相同，也就是说，子进程是从fork返回处开始执行的**），但有一点不同，如果 fork 成功，子进程中fork的返回值是 0，父进程中 fork 的返回值是子进程的进程号，如果 fork 不成功，父进程会返回错误。


**子进程从父进程继承的有：**
1. 进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))；
2. 环境(environment)；
3. 堆栈；
4. 内存；
5. 进程组号；

**独有：**  
1.进程号；  
2.不同的父进程号(即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)；  
3.资源使用(resource utilizations)设定为 0 ；  


**进程组**：进程组就是多个进程的集合，其中肯定有一个组长，其进程 PID等于进程组的 PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关。

**作业**：shell 分前后台来控制的不是进程而是作业(job)或者进程组(Process Group)。一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，shell 可以运行一个前台作业和任意多个后台作业，这称为**作业控制**；

**会话**：会话(Session)是一个或多个进程组的集合。一个会话可以有一个控制终端。在 xshell 或者 WinSCP 中打开一个窗口就是新建一个会话。


## 29.为什么只能运行一个前台作业?
当我们在前台新起了一个作业，shell 就被提到了后台，因此 shell 就没有办法再继续接受我们的指令并且解析运行了。   
但是如果前台进程退出了，shell 就会又被提到前台来，就可以继续接受我们的命令并且解析运行。
  
作业与进程组的区别：如果作业中的某个进程有创建了子进程，则该子进程是不属于该作业的。一旦作业运行结束，shell 就把自己提到前台（子进程还存在，但是子进程不属于作业），如果原来的前台进程还存在（这个子进程还没有终止)，他将自动变为后台进程组）。

## 30.进程终止的几种方式？
1、main函数的自然返回，# return #；   
2、调用 `exit` 函数，属于c的函数库；  
3、调用 `_exit` 函数，属于系统调用；  
4、调用 `abort` 函数，异常程序终止，同时发送 `SIGABRT` 信号给调用进程；   
5、接受能导致进程终止的信号：`ctrl+c`(^C)、SIGINT(SIGINT中断进程)


## 31.Linux中异常和中断的区别？
- **异常**又叫同步中断，是当指令执行时由cpu控制单元产生的，之所以称之为异常，是因为只有在一条指令结束之后才发出中断（程序执行异常或者系统调用）。
- **中断**又叫异步中断，是由其他硬件设备依照 cpu 时钟信号随机产生的。

相同点：

- 最后都是由CPU发送给内核，由内核去处理；
- 处理程序的流程设计上是相似的；

不同点：

- 产生源不相同，异常是由 CPU 产生的，而中断主要是由硬件设备产生的；
- 内核需要根据是异常还是中断调用不同的处理程序；
- 中断不是时钟同步的，这意味着中断可能随时到来，异常由于是CPU产生的，所以它是时钟同步的；
- 当处理中断时，处于中断上下文中，处理异常时，处于进程上下文中。



[https://www.cnblogs.com/charlesblc/p/6261741.html](https://www.cnblogs.com/charlesblc/p/6261741.html)

## 32.内存分布情况
操作系统下：
<img src="http://inews.gtimg.com/newsapp_bt/0/14071993259/640">

C++ 下：
<img src="https://i-blog.csdnimg.cn/blog_migrate/b5bf86b2742e773db67fd03d0c16d5e2.png">

- Windows系统中，栈的大小被记录在可执行文件中，**由编译器设置决定**，VS2013中栈大小理默认为1M。
- linux系统中，栈大小不是由编译器决定，而是**由操作系统决定**，栈大小默认为8M。`ulimit -s`


## 33.程序从堆中动态分配内存时，虚拟内存上怎么操作的？
**页表**：是一个存放在物理内存中的数据结构，它记录了虚拟页与物理页的映射关系；

在进行动态内存分配时，例如`malloc()`函数或者其他高级语言中的 `new` 关键字，操作系统会在硬盘中创建或申请一段虚拟内存空间，并更新到页表（分配一个页表条目（PTE），使该PTE指向硬盘上这个新创建的虚拟页），通过 PTE建立虚拟页和物理页的映射关系。


## 34.常见的几种磁盘调度算法
读写一个磁盘块的时间的影响因素有：

- 旋转时间(主轴转动盘面，使得磁头移动到适当的扇区上)；
- 寻道时间(制动手臂移动，使得磁头移动到适当的磁道上)；
- 实际的数据传输时间；


其中，寻道时间最长，因此**磁盘调度的主要目标是使磁盘的平均寻道时间最短**。



**1、先来先服务（FCFS）**  
先来先服务（First-Come, First-Served） 磁盘调度算法按照请求的顺序依次处理。它简单易实现，但可能导致磁头在磁盘上移动的距离较大，效率不高。

**2、最短寻道时间优先（SSTF）**  
最短寻道时间优先（Shortest Seek Time First） 算法选择离磁头当前位置最近的请求进行处理。这可以最大程度地减少寻道时间，但可能导致某些请求长时间等待。

**3、电梯算法**  
电梯算法 包括 SCAN 和 C-SCAN 两种变种。  
SCAN 算法从当前位置向某个方向移动，直到最远的请求为止，然后改变方向。  
C-SCAN 算法类似，但在到达磁盘末端后立即返回到磁盘的起始位置。这些算法能够平衡请求的等待时间，但可能会导致某些请求长时间等待。

**4、LOOK和C-LOOK**  
LOOK 和 C-LOOK 是电梯算法的改进版本，它们不会在到达磁盘末端时立即返回，而是根据需要调整方向。这可以减少一些请求的等待时间，提高了效率。

头部从一个方向的第一个请求开始，向另一端的最后一个请求移动，为中间的所有请求服务。在到达一端的最后一个请求后，头部跳到另一个方向，并向剩余的请求移动，然后像以前一样满足它们。**与C-SCAN不同，磁头指针将移动到磁盘的最后一个请求**。

# 35.交换空间与虚拟内存的关系？
Linux 中的 **交换空间** （Swap space）在物理内存（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。

交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。

**交换空间的总大小应该相当于你的计算机内存的两倍**和 32 MB这两个值中较大的一个，但是它不能超过 2048 MB（2 GB）。



**虚拟内存** 是文件数据交叉链接的活动文件。是 WINDOWS目录下的一个"WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。

就速度方面而言，CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是虚拟内存使用的是硬盘的空间，为什么我们要使用速度最慢的硬盘来做为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。

**交换空间与虚拟内存区别**

一、主体不同

1、交换空间：存在于数据服务器上的一个共享文件夹。  
2、虚拟内存：是计算机系统内存管理的一种技术。

二、作用不同

1、交换空间：作用是为前台与后台数据交换提供一个场所。  
2、虚拟内存：使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

三、特点不同

1、交换空间：挂载交换区空间的情形有两种系统内存不足，特殊应用程序的需求，如 oracle、lotus notes 等。  
2、虚拟内存：将逻辑和物理地址空间都分成固定大小的页。主存按页顺序编号，而每个独立编址的程序空间有自己的页号顺序，通过调度辅存中程序的各页可以离散装入主存中不同的页面位置。

<font color = red>对于'虚拟内存'有两种理解：

1. Linux中的内存管理机制；
2. Windows上的虚拟内存，类似Linux下的内存交换分区；

</font>


## 36.抖动你知道是什么吗？它也叫颠簸现象
颠簸（thrashing）又称“抖动”，是指页面在内存与外存储器之间频繁地调度，以致系统用于调度页面的时间比进程实际运行所占用的时间还要长。

颠簸是由于页故障率过高而产生的结果（**主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)**），它将严重地影响系统的效率，甚至可能使系统全面崩溃。
通俗来讲就是一个进程的页面放入内存中，被淘汰出去后，进程又需要使用这个页面然后重新把他放入内存的过程。即你把我赶走之后，又叫我回来。

## 37.从堆和栈上建立对象哪个快？(考察堆和栈的分配效率比较)
**栈对象**

- 在适当的时候自动生成，又在适当的时候自动销毁，不需要程序员操心；
- 栈对象的创建速度一般较堆对象快，因为分配堆对象时，会调用operator new操作，operator new 会采用某种内存空间搜索算法，而该搜索过程可能是很费时间的，产生栈对象则没有这么麻烦，它仅仅需要移动栈顶指针就可以了。但是要注意的是，通常栈空间容量比较小，一般是1MB～2MB，所以体积比较大的对象不适合在栈中分配。
- 特别要注意递归函数中最好不要使用栈对象，因为随着递归调用深度的增加，所需的栈空间也会线性增加，当所需栈空间不够时，便会导致栈溢出，这样就会产生运行时错误。

**堆对象**

- 其产生时刻和销毁时刻都要程序员精确定义，也就是说，程序员对堆对象的生命具有完全的控制权。我们常常需要这样的对象，比如，我们需要创建一个对象，能够被多个函数所访问，但是又不想使其成为全局的，那么这个时候创建一个堆对象无疑是良好的选择，然后在各个函数之间传递这个堆对象的指针，便可以实现对该对象的共享。
- 相比于栈空间，堆的容量要大得多。实际上，当物理内存不够时，如果这时还需要生成新的堆对象，通常不会产生运行时错误，而是系统会使用虚拟内存来扩展实际的物理内存。



**分配和释放**，堆在分配和释放时都要调用函数(malloc,free)，比如分配时会到堆空间去**寻找足够大小的空间**（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。


**访问时间**，**访问堆的一个具体单元，需要两次访问内存**，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

## 38.常见内存分配方式有哪些？
**静态内存分配**：

- 静态内存分配是在程序**编译阶段**完成的，使得内存分配在程序运行期间保持不变；
- 静态内存分配使用**全局变量或静态变量**来分配内存空间；
- 内存分配在程序的数据段或全局内存中，会一直**保持**分配的内存空间直至程序退出；
- 内存大小是在编译时**确定的**，无法在运行时动态改变。


**栈内存分配**：

- 栈内存分配是由编译器**自动**进行的，用于存储函数的局部变量和函数调用信息；
- 使用栈来管理内存分配，分配和释放内存的速度非常快；
- 内存大小是在**编译时确定**的，不能在运行时动态改变；
- 栈内存分配的**生命周期与其所在的函数相对应**，在函数执行完毕后，内存会自动释放。


堆内存分配：

- 堆内存**分配是在运行时动态进行**的，用于存储动态分配的内存块。
- 使用堆来管理内存分配，通过函数如 malloc 和 free 或 new 和 delete 进行操作。
- 内存大小**可以在运行时动态改变**，可以根据需要分配和释放内存。
- 堆内存分配**需要手动管理**内存的分配和释放，避免出现内存泄漏或悬挂指针等问题。
- 堆内存分配的生命周期由程序员控制，需要显式地释放已分配的内存。


## 39.常见内存分配内存错误
（1）**内存分配未成功，却使用了它**。

常用解决办法是，在使用内存之前检查指针是否为 `NULL`。如果指针p是函数的参数，那么在函数的入口处用 `assert(p!=NULL) `进行检查。如果是用 `malloc` 或 `new` 来申请内存，应该用`if(p==NULL)` 或 `if(p!=NULL)` 进行防错处理。

（2）**内存分配虽然成功，但是尚未初始化就引用它**。

（3）**内存分配成功并且已经初始化，但操作越过了内存的边界**。

（4）**忘记了程放内存，造成内存泄露**。

含有这种错误的函数每被调用一次就丢失一块内存了。动态内存的申请与释放必须配对，程序中 `malloc` 与 `free` 的使用次数一定要相同，否则肯定有错误( `new/delete` 同理）。

（5）释放了内存却继续使用它。

## 40.ASCIl、Unicode和UTF-8编码的区别？

**ASCII编码**

ASCII 码使用指定的 7 位或 8 位二进制数组合来表示 128 或 256 种可能的字符。标准 ASCII 码也叫基础 ASCII 码，使用 7 位二进制数（剩下的1位二进制为0）来表示所有的大写和小写字母，数字 0  到 9、标点符号， 以及在美式英语中使用的特殊控制字符。其中最后一位用于奇偶校验。

问题：ASCII 是单字节编码，无法用来表示中文（**中文编码至少需要2个字节**），所以，中国制定了GB2312编码，用来把中文编进去。但世界上有许多不同的语言，所以需要一种统一的编码。

**Unicode**

Unicode 把所有语言都统一到一套编码里，这样就不会再有乱码问题了。
Unicode 最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要 4 个字节）。现代操作系统和大多数编程语言都直接支持 Unicode。


**UTF8**

所以，本着节约的精神，又出现了把 Unicode 编码转化为“可变长编码”的 UTF-8 编码。  

UTF-8 编码把一个 Unicode 字符根据不同的数字大小编码成 1-6 个字节，常用的英文字母被编码成 1 个字节，汉字通常是 3 个字节，只有很生僻的字符才会被编码成 4-6 个字节。如果你要传输的文本包含大量英文字符，用 UTF-8 编码就能节省空间。  

UTF-8 编码有一个额外的好处，就是 ASCII 编码实际上可以被看成是 UTF-8 编码的一部分，所以，大量只支持 ASCII 编码的历史遗留软件可以在 UTF-8 编码下继续工作。


<font color=blue>

- 在计算机内存中，统一使用 Unicode 编码，当需要保存到硬盘或者需要传输的时候，就转换为 UTF-8 编码。
-  用记事本编辑的时候，从文件读取的 UTF-8 字符被转换为 Unicode 字符到内存里，编辑完成后，保存的时候再把 Unicode 转换为 UTF-8 保存到文件。
- 浏览网页的时候，服务器会把动态生成的 Unicode 内容转换为 UTF-8 再传输到浏览器。

</font>

<img src="https://ask.qcloudimg.com/http-save/1692602/zs2m48pymr.png">
<img src = "https://ask.qcloudimg.com/http-save/1692602/zxks1cbo4v.png">

[https://cloud.tencent.com/developer/article/1441294](https://cloud.tencent.com/developer/article/1441294)

## 41.原子操作的是如何实现的
原子操作（atomic operation）指的是由多步操作组成的一个操作。如果该操作不能原子地执行，则**要么执行完所有步骤，要么一步也不执行**，不可能只执行所有步骤的一个子集。

在单核环境中，一般的意义下原子操作中线程不会被切换，线程切换要么在原子操作之前，要么在原子操作完成之后。更广泛的意义下原子操作是指一系列必须整体完成的操作步骤，如果任何一步操作没有完成，那么所有完成的步骤都必须回滚，这样就可以保证要么所有操作步骤都未完成，要么所有操作步骤都被完成。

- 在单核系统里，**单个的机器指令可以看成是原子操作**（如果有编译器优化、乱序执行等情况除外）；
- 在多核系统中，单个的机器指令就不是原子操作，因为多核系统里是多指令流并行运行的，一个核在执行一个指令时，其他核同时执行的指令有可能操作同一块内存区域，从而出现数据竞争现象。多核系统中的原子操作通常使用 **内存栅障（memory barrier）** 来实现，即**一个CPU核在执行原子操作时，其他 CPU 核必须停止对内存操作或者不对指定的内存进行操作**，这样才能避免数据竞争问题。

**原子操作的底层实现**

**1. 总线加锁**
所谓总线锁就是使用处理器提供的一个 `lock#` 信号，**当一个处理器在总线上输出此信号时，其他处理器的请求会被阻塞住**，那么该处理器可以独占共享内存。  
但总线锁定把 cpu 和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以开销比较大。

**2.缓存加锁**
通过缓存锁定来保证原子性。在同一时刻，我们只需**保证对某个内存地址的操作是原子性即可**，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。  
所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在 `Lock` 操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言`LOCK#`信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为 **缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据** ，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。


有两种情况下处理器不会使用缓存锁定。

1. 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。
1. 第二种情况是：有些处理器不支持缓存锁定。对于 Intel 486 和 Pentium 处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。


**编程使用**  
（1）GCC编译器提供的原子操作 API： ` type __sync_fetch_and_add (type *ptr, type value); `还有很多；  
（2）C++11提供的原子操作：C++11中在<atomic>中定义了 `atomic` 模板类，`atomic` 的模板参数类型可以为`int、long、bool`等等，C++ 中称为 trivially copyable type。atomic_int、atomic_long 为 atomic 模板实例化后的宏定义；  

[http://t.csdnimg.cn/vs2Gz](http://t.csdnimg.cn/vs2Gz)


## 42.页面置换算法？
访问的页面不在内存中时，会发生一个缺页异常，操作系统必须将该页换入内存，如果此时内存已满，则操作系统必须将其中一个页面换出，放到 swap 交换区中，**为当前访问的页面腾出空间**，这个过程称为页面置换。操作系统提供了多种页面置换算法：

**1.最优页面置换算法**

选择一个将来最长时间不会被访问的页面换出。这样可以保证将来最低的缺页率。这是一种理论上的算法，因为无法知道哪个页面是将来最长时间都不会被访问的。

**2.最近未使用页面置换算法 (NRU)**

为每个页面设两个状态位：被访问时设置为 R=1 位，页面被修改时，设置为 M=1 位。当启动一个进程时，所有页面都被初始化为 R=0，M=0。其中 R 位会被定时的清 0，以此区分最近被访问的页面和没有被访问的页面。

于是所有页面可以分为以下 4 类：

- 0 类：R=0，M=0；
- 1 类：R=0，M=1；
- 2 类：R=1，M=0；
- 3 类：R=1，M=1；

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出（挑选优先级：1 类 > 2 类 > 3 类）。

**3.最近最少未使用（LRU）页面置换算法**

在内存中维护一个所有页面的单链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**4.先进先出（FIFO）页面置换算法**

维护一个链表，最先进入的页面放在表头，最后进入的页面放在表尾，当缺页中断发生时，直接淘汰表头的页面，并把新的页面放在表尾。

这种算法有可能置换掉经常访问的页面，导致缺页率升高。

**5.第二次机会页面置换算法**

对 FIFO 算法做一个修改：取出表头的页面时，检查该页面的 R 位，如果是 1 表示是最近有访问的，将其清 0，然后放入表尾，然后继续检查下一个表头的页面，直到遇到一个 R 位为 0 的页面，将其换出。

**6.时钟页面置换算法**

单链表改成了环形链表，形成一个时钟，移动的也不是页面，而是中间的表针。检查页面逻辑类似，如果该页面 R 为 0，则直接置换该页面，否则将该 R 位清 0，然后表针向前移动。


[https://www.cnblogs.com/Leophen/p/11397699.html](https://www.cnblogs.com/Leophen/p/11397699.html)

[https://xiaolincoding.com/os/5_schedule/schedule.html#%E6%9C%80%E4%BD%B3%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95](https://xiaolincoding.com/os/5_schedule/schedule.html#%E6%9C%80%E4%BD%B3%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95)


## 43.内存碎片之外部碎片与内部碎片
“内存碎片”描述了一个**系统中所有不可用的空闲内存**。这些资源之所以仍然未被使用，是因为负责分配内存的分配器使这些内存无法使用**，原因在于空闲内存以小而不连续方式出现在不同的位置，内存分配器无法将这些内存利用起来分配给新的进程**。由于分配方法决定内存碎片是否是一个问题，因此内存分配器在保证空闲资源可用性方面扮演着重要的角色。


**内部碎片** 是由于 **系统分配给进程的空间大于其所申请的大小** ，处于（操作系统分配的用于装载某一进程的内存）区域内部或页面内部的存储块， **占有这些区域或页面的进程并不使用这个存储块**。而在进程占有这块存储块时，系统无法利用它。**直到进程释放它**，或进程结束时，系统才有可能利用这个存储块。

**外部碎片** 指的是**还没有被分配出去**（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域，即 **处于任何两个已分配区域或页面之间的空闲存储块**。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。


分段式分配是按需分配，而固定式分配是固定分配的方式。
[https://jacktang816.github.io/post/memoryfragmentation/](https://jacktang816.github.io/post/memoryfragmentation/)

## 44.服务器高并发的解决方案你知道多少？
- **应用数据与静态资源分离** 将静态资源(图片，视频,js，css等)单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。
- **客户端缓存** 因为效率最高，消耗资源最小的就是纯静态的 html 页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用 ajax 异步请求获取动态数据。
- **集群和分布式**（集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用）（分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度)  
可以使用服务器集群和分布式架构，使得原本属于一个服务器的计算压力分散到多个服务器上。同时加快请求处理的速度。
- **反向代理** 在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端。


# 计算机网络

## 1.说一下一次完整的HTTP请求过程包括哪些内容？
- 使用 DNS 域名解析；
- 发起 TCP 的 3 次握手
- 建立TCP连接后发起http请求；
- 服务器响应 http 请求，浏览器得到返回 response；
- 浏览器解析 response，并请求其它的资源（如js、css、图片等）；
- 浏览器对页面进行渲染。

## 2.DNS是什么？工作原理？
官方解释：DNS（Domain Name System，域名系统），因特网上作为**域名和 IP 地址相互映射的一个分布式数据库**能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。
通过主机名，最终得到该主机名对应的 IP 地址的过程叫做域名解析(或主机名解析)。
通俗的讲，我们更习惯于记住一个网站的名字，比如www.baidu.com，而不是记住它的 ip 地址，比如:167.23.10.2；(**方便记忆：IP地址是面向主机的，而域名则是面向用户的**)

将主机域名转换为 ip 地址，属于**应用层协议，使用UDP传输**。


过程：

（1）当用户在浏览器中输入 www.qq.com 域名访问该网站时，操作系统 **会先检查自己本地的 hosts 文件是否有这个网址映射关系** ，如果有，就先调用这个IP地址映射，完成域名解析。   
（2）如果 hosts 里没有这个域名的映射，则**查找本地 DNS 解析器缓存**，是否有这个网址映射关系，如果有，直接返回，完成域名解析。   
（3）如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找 TCP/ip 参数中设置的首选 DNS 服务器，在此我们叫它 **本地 DNS 服务器** ，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。   
（4）如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已**缓存了此网址映射关系**，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。     
（5）如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（**是否设置转发器**）进行查询，如果未用转发模式，本地DNS就把请求发至 13 台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责 .com 域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理 .com 域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到www.qq.com 主机。   
（6）如果用的是转发模式， **此DNS服务器就会把请求转发至上一级DNS服务器** ，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

提示：从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间的交互查询就是迭代查询。

**域名解析总体可分为以下下过程：**  
(1) 输入域名后，先查找自己主机对应的域名服务器，域名服务器先查找自己的数据库中的数据；  
(2) 如果没有，就向上级域名服务器进行查找， 依次类推；  
(3) 最多回溯到根域名服务器，肯定能找到这个域名的 IP 地址；  
(4) 域名服务器自身也会进行一些缓存， 把曾经访问过的域名和对应的IP地址缓存起来，可以加速查找过程。  

**具体可描述如下：**

1. 主机先向本地域名服务器进行递归查询；
2. 本地域名服务器采用迭代查询，向一个根域名服务器进行查询；
3. 根域名服务器告诉本地域名服务器，下一次应该查询的顶级域名服务器的 IP 地址；
4. 本地域名服务器向顶级域名服务器进行查询；
5. 顶级域名服务器告诉本地域名服务器，下一步查询权限服务器的 IP 地址；
6. 本地域名服务器向权限服务器进行查询；
7. 权限服务器告诉本地域名服务器所查询的主机的IP地址；
8. 本地域名服务器最后把查询结果告诉主机。

<img src="https://i-blog.csdnimg.cn/blog_migrate/a73040d92f51a8c741b1b6f6a6d841c6.png">


[https://blog.csdn.net/mocas_wang/article/details/109167660](https://blog.csdn.net/mocas_wang/article/details/109167660)


## 3.DNS为什么既使用TCP又使用UDP？为什么域名解析用UDP协议？为什么区域传送用TCP协议?
DNS的规范规定了2种类型的DNS服务器，一个叫 **主DNS服务器**，一个叫 **辅助DNS服务器**。在一个区中主 DNS 服务器从自己本机的数据文件中读取该区的 DNS 数据信息，而辅助 DNS 服务器则从区的主DNS服务器中读取该区的 DNS 数据信息。当一个辅助 DNS 服务器启动时，它需要与主 DNS 服务器通信，并加载数据信息，这就叫做 **区传送（zone transfer）** 。

**域名解析时使用UDP协议：**

客户端向DNS服务器查询域名，一般返回的内容都**不超过512字节**，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器**负载更低**，响应更快。虽然从理论上说，客户端也可以指定向 DNS 服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持 UDP 查询包。

**区域传送时使用TCP**，主要有一下两点考虑：

- 辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。
- TCP是一种可靠的连接，保证了数据的准确性。

[为什么DNS既使用TCP又使用UDP？](https://scoolor.github.io/2018/11/10/dns-udp-tcp/#%E4%B8%BA%E4%BB%80%E4%B9%88DNS%E6%97%A2%E4%BD%BF%E7%94%A8TCP%E5%8F%88%E4%BD%BF%E7%94%A8UDP%EF%BC%9F)

## 4. HTTP 长连接和短连接的区别？
**长连接**：长连接，指在一个连接上可以连续发送多个数据包，在连接保持期间，如果没有数据包发送，需要双方发链路检测包（TCP 保活机制）。

**短连接**：短连接（short connnection）是相对于长连接而言的概念，指的是在数据传送过程中，只在需要发送数据时，才去建立一个连接，数据发送完成后，则断开此连接，即每次连接只完成一项业务的发送。

在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器**每进行一次 HTTP 操作，就建立一次连接**，任务结束就中断连接。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

## 5.什么是 TCP 粘包/拆包？发生的原因？
**粘包**：指TCP协议中，发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

> 为什么UDP没有粘包？  
> 粘包拆包问题在数**据链路层、网络层以及传输层都有可能发生**。日常的网络应用开发大都在传输层进行，由于UDP有消息保护边界，不会发生粘包拆包问题，因此粘包拆包问题只发生在TCP协议中。


因为 TCP 是面向流，没有边界，而操作系统在发送TCP数据时，会通过缓冲区来进行优化，例如缓冲区为1024个字节大小。

- 如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP则会**将多个请求合并为同一个请求**进行发送，这就形成了粘包问题。
- 如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP就会将其**拆分为多次发送**，这就是拆包。

原因  
1、应用程序写入数据的字节大小**大于**套接字发送缓冲区的大小；  
2、进行 MSS 大小的 TCP 分段。( `MSS = TCP报文段长度 - TCP首部长度`）；  
3、以太网的 payload 大于 MTU 进行 IP 分片。(MTU指：一种通信协议的某一层上面所能通过的最大数据包大小）

出现粘包的一些可能：

- 由TCP连接复用造成的粘包问题；
- 因为TCP默认会使用Nagle算法，此算法会导致粘包问题只有上一个分组得到确认，才会发送下一个分组；收集多个小分组，在一个确认到来时一起发送。
- 数据包过大造成的粘包问题；
- 流量控制，拥塞控制也可能导致粘包；
- **接收方不及时接收缓冲区的包，造成多个包接收**

**解决方案**  

1. 发送端将每个包都封装成固定的长度，比如100字节大小。如果不足100字节可通过补0或空等进行填充到指定长度；
1. 发送端在每个包的末尾使用固定的分隔符，例如\r\n。如果发生拆包需等待多个包发送过来之后再找到其中的\r\n进行合并；例如，FTP协议；
1. 将消息分为头部和消息体，头部中保存整个消息的长度，只有读取到足够长度的消息之后才算是读到了一个完整的消息；
1. 通过自定义协议进行粘包和拆包的处理。使用其它复杂的协议，如 RTMP 协议等。

[https://cloud.tencent.com/developer/article/1804413](https://cloud.tencent.com/developer/article/1804413)

## 6.为什么服务器会缓存这一项功能？如何实现的？
原因

- 缓解服务器压力；
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

实现方法  

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存。


**正向代理**：如果把局域网的Internet想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。在客户端（浏览器）配置代理服务，通过代理服务器进行**互联网访问**。
<img src = "https://i-blog.csdnimg.cn/blog_migrate/547de65ebbe20f037da0d232a227ecfe.png">

**反向代理**：其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。
<img src = "https://i-blog.csdnimg.cn/blog_migrate/0e85cb8d88d0caa7e21ff42695799b76.png">

- 正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端；
- 反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端；

> **反向代理服务器**架设在服务器端，通过**缓存经常被请求的页面**来缓解服务器（如Web服务器）的工作量。安装反向代理服务器有几个原因：

>1. 负载平衡
1. 缓存静态内容
1. 压缩数据
1. 外网发布


[缓存问题](http://t.csdnimg.cn/2S3VF)  
[Nigix](http://t.csdnimg.cn/RytbI)

## 7.GET 和 POST 的区别，你知道哪些？
<font color = blue> **GET 和 POST 本质上就是 TCP 链接，并无差别**。但是由于 HTTP 的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。</font>

**最直观的区别**就是 GET 把参数包含在 URL 中，POST 通过 request body 传递参数（相对安全）。

- get是 获取数据，post 是修改数据；
- get 提交的数据最大是2k（限制实际上取决于浏览器），post理论上没有限制；
- GET 请求会被浏览器主动缓存，而 POS T不会，除非手动设置；
- 本质区别：GET 是幂等的（只读），而 POST 不是幂等的（新增或提交数据）；
> 幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。

GET和POST还有一个重大区别：**GET产生一个TCP数据包；POST产生两个TCP数据包**。

- 对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；
- 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应 200 ok（返回数据）。


## 8.一个TCP连接可以发送多少个HTTP请求？
默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接【长连接】。

如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

- 在 HTTP/1.1 存在 管道（ pipeline） 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。【因为服务器必须按照接收请求的顺序发送对这些管道化请求的响应，如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「**队头堵塞**」】；
- 在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。【多个 Stream 复用在一条 TCP 连接，针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，**当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据（队头阻塞）。一个包丢失，所有的请求都必须等这个包重传**】


那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

- 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求；
- 和服务器建立多个 TCP 连接；

## 9.DNS负载均衡是什么策略？
当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，**DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果**，**将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器**，从而达到负载均衡的目的，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

## 10.传输过中如何保证 数据既能不被篡改，又能不被窃取？
公加私解，私加公解

- 公钥加密私钥解密，只能保证数据不会篡改，但是可以被窃取；
- 私钥加密公钥解密，只能保证数据不会窃取，但是可能被整个替换；

签名和信封

- 数据取摘要，然后私钥加密这种做法可以加快速度，保证数据不被篡改，这种方式叫做签名；
- 数据对称加密，然后公钥加密对称加密密钥，密钥保证数据安全，公钥加密保证密钥不会窃取，公钥加密密钥比直接加密数据快，这种方式叫做信封；

> 一个数字证书通常包含了：
> 
- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份文件的数字签名及使用的算法；
- 证书有效期；
- 还有一些其他额外信息；
- <font color = blue>数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充（**服务端是否是合法的**）。</font>

[https://www.cnblogs.com/cxygg/p/17725826.html](https://www.cnblogs.com/cxygg/p/17725826.html)


## 11.HTTP请求和响应报文有哪些主要字段？

**1. 请求报文**

客户端发送一个请求报文给服务器，**服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端**。

请求报文结构：

- 第一行是包含了请求方法、URL、协议版本（请求行）；
- 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值（请求头）；
- 一个空行用来分隔首部和内容主体 Body；
- 最后是请求的内容主体。


**2.响应报文**

响应报文结构：

- 第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了（相应行）；
- 接下来多行也是首部内容（响应头）；
- 一个空行分隔首部和内容主体；
- 最后是响应的内容主体。

[https://blog.csdn.net/weixin_43901865/article/details/112908748](https://blog.csdn.net/weixin_43901865/article/details/112908748)

## 12.Cookie是什么？
HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1引入 Cookie 来保存状态信息。

**Cookie 是服务器发送到用户浏览器并保存在本地**的一小块数据，它会在浏览器之后向同一服务器再次发起清求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销(尤其是在移动环境下)。

cookie 的作用就好比服务器给你贴个标签，然后每次向服务器再发请求时，服务器就能够 cookie 认出你。


**Cookie的生命周期：**
cookie 有 2 种存储方式，一种是会话性，一种是持久性。

- **会话性**：如果 cookie 为会话性，那么 cookie 仅会保存在客户端的内存中，当我们关闭客服端时 cookie 也就失效了
- **持久性**：如果 cookie 为持久性，那么 cookie 会保存在用户的硬盘中，直至生存期结束或者用户主动将其销毁。

**用途：**

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）；
- 个性化设置（如用户自定义设置、主题等）；
- 浏览器行为跟踪（如跟踪分析用户行为等）。


## 13.什么是 session？
在Web中，Session是**指一个用户与网站服务器进行一系列交互的持续时间**，通常指从注册进入系统到注销退出系统之间所经过的时间，以及在这段时间内进行的操作，还有，服务器端为保存用户状态开辟的存储空间。

- Session 就一个接口（HttpSession）。
- Session 就是会话。它是用来维护一个客户端和服务器之间关联的一种技术。
- 每个客户端都有自己的一个 Session 会话。
- Session 会话中，我们经常用来保存用户登录之后的信息。

**工作原理**：session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 session 的 id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid 之后，在内存找到与之对应的 session 这样就可以正常工作了。

http 协议只完成请求和响应的工作，不能记录用户状态，服务器为了记录用户状态，跟踪用户行为，从而提供个性化服务而引入 session，用户的一系列交互行为都包含在 session 内，用户状态信息也存储在服务器端为 session 开辟的一个存储空间内；当用户通过浏览器发送一系列 http 请求时，为了识别这些请求属于哪个 session，服务端需要给每个 session 一个 sessionID，cookie 就是浏览器端用来存储和发送这个 sessionID 的。

[https://github.com/frmachao/frmachao.github.io/issues/2](https://github.com/frmachao/frmachao.github.io/issues/2)  
[http://t.csdnimg.cn/Te9Pi](http://t.csdnimg.cn/Te9Pi)


## 14.什么是 token？
**Token** 是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个 Token 便将此 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次带上用户名和密码。

**用途**：使用token机制的身份验证方法，在服务器端不需要存储用户的登录记录。

大概的流程：

1. 客户端使用用户名和密码请求登录。
1. 服务端收到请求，验证用户名和密码。
1. 验证成功后，服务端会生成一个token，然后把这个token发送给客户端。
1. 客户端收到token后把它存储起来，可以放在 cookie 或者 Local Storage （本地存储）里。
1. 客户端每次向服务端发送请求的时候都需要带上服务端发给的 token。
1. 服务端收到请求，然后去验证客户端请求里面带着 token，如果验证成功，就向客户端返回请求的数据。

[http://t.csdnimg.cn/36YEI](http://t.csdnimg.cn/36YEI)

## 15.Session 、Cookie和Token三者的关系和区别
- Cookie 是浏览器用来保存用户信息的文件，可以保存比如用户是谁，购物车有哪些商品等，是**客户端保持状态**的方法。；
- Session 是一次会话，会话是指我们访问网站的一个周期，是**服务器保持状态**的方法。；
- token 是服务器返回的一个临时签名数据，可以使用这个签名数据表面用户身份。

 都是一个目的，服务器需要知道和自己通话的人是谁，就是 <font color = blue>**服务器需要用某种机制来识别具体的用户**。</font>

这要从HTTP协议开始说起，HTTP协议是**无状态的协议**。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话，自然无法识别用户，所以诞生了Cookie，session 和 token。

> Cookie 简单的理解就是存储**由服务器发至客户端并由客户端保存的一段字符串**。为了保持会话，服务器可以在响应客户端请求时将 Cookie 字符串放在 Set-Cookie 下，客户机收到 Cookie 之后保存这段字符串，之后再请求时候带上Cookie 就可以被识别。
> 
> **Session 保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的 Session 用户在客户端上记录用户的操作**。可以理解为每个用户有一个独一无二的 SessionID 作为 Session 文件的 Hash 键，通过这个值可以锁定具体的 Session 结构的数据，这个 Session 结构中存储了用户操作行为。

<img src="https://upload-images.jianshu.io/upload_images/1500839-a5a19abfc7488c8d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/700">




## 16.什么是 SQL 注入 (SQi)？
结构化查询语言 (SQL*) 注入是一种代码注入技术，用于修改或从 SQL 数据库检索数据。 **通过在输入字段中插入专用的 SQL 语句，攻击者可以执行命令，以允许从数据库中检索数据、破坏敏感数据或执行其他操纵行为** 。

通过正确执行 SQL 命令，未经授权的用户可以伪造特权更高的用户的身份，使自己或其他人成为数据库管理员，篡改现有数据、修改事务和余额以及检索和/或销毁所有服务器数据。

本质上：本应为特定类型的数据（例如数字）保留的 SQL 查询字段传递了意外的信息（例如命令）。该命令在运行时越过预期的范围，从而允许可能有害的行为。查询字段通常由在网页上输入表单的数据填充。

[https://www.cloudflare.com/zh-cn/learning/security/threats/sql-injection/](https://www.cloudflare.com/zh-cn/learning/security/threats/sql-injection/)

## 17.什么是RARP？工作原理？

1、定义：  
概括： 反向地址转换协议，网络层协议，RARP 与 ARP 工作方式相反。 RARP使**只知道自己硬件地址的主机能够知道其IP地址**。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。

2、原理：  
（1）网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的 MAC 地址。主机从网卡上读取 MAC 地址，然后**在网络上发送一个 RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址**。  
（2）RARP 服务器收到了 RARP 请求数据包，**为其分配 IP 地址，并将RARP回应发送给主机**。  
（3）PC1 收到 RARP 回应后，就使用得到的 IP 地址进行通讯。

## 18.端口有效范围是多少到多少？
`0-1023` 为知名端口号，比如其中 HTTP 是80（HTTPS:443），FTP是20(数据端口)、21(控制端口)

UDP 和 TCP 报头使用两个字节存放端口号，所以端口号的有效范围是从 0 到 65535。动态端口的范围是从 1024 到 65535。

## 19.为何需要把 TCP/IP 协议栈分成5 层（或7层）？开放式回答。
分层的好处：  
①各层之间是独立的；  
②灵活性好；  
③结构上可以分隔开；  
④易于实现和维护；  
⑤能促进标准化工作。

<img src="http://oss.interviewguide.cn/img/202205072300887.png">

## 20.DNS查询方式有哪些？
**当局部 DNS 服务器自己不能回答客户机的 DNS 查询时，它就需要向其他 DNS 服务器进行查询**。

**1.递归解析**   

**局部 DNS 服务器自己负责向其他 DNS 服务器进行查询**，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询。最后得到的查询结果返回给局部 DNS 服务器，再由局部 DNS 服务器返回给客户端。

（1）查看浏览器缓存；  
（2）查看系统缓存【host 文件】；  
（3）查看路由器缓存；  
（4）查看ISP DNS 缓存（比如电信的 DNS 缓存服务器）；  
（5）询问根域名服务器（全球仅有 13 台根域名服务器，1 个主根域名服务器，其余 12 为辅根域名服务器）；    
（6）询问顶级域名服务器；  
（7）询问权威域名（主域名）服务器；  
（8）保存结果至缓存。


**2.迭代解析**

局部 DNS 服务器不是自己向其他 DNS 服务器进行查询，而是**把能解析该域名的其他 DNS 服务器的 IP 地址返回给客户端 DNS 程序**，客户端 DNS 程序再继续向这些 DNS 服务器进行查询，直到得到查询结果为止，也就是说，**代解析只是帮你找到相关的服务器而已**，而不会帮你去査。比如说：baidu.com 的服务器ip地址在 192.168.4.5 这里，你自己去查吧，本人比较忙只能帮你到这里了。【如：若 dns2 不能响应 dns1 的请求，则它会将 dns3 的ip给 dns2，以便其再向dns3发出请求】；

[https://www.guokeyun.com/news/technology/detail/222.html?navId=22](https://www.guokeyun.com/news/technology/detail/222.html?navId=22)

[https://info.support.huawei.com/info-finder/encyclopedia/zh/DNS.html](https://info.support.huawei.com/info-finder/encyclopedia/zh/DNS.html)


## 21.HTTP中缓存的私有和共有字段？知道吗？
1.`private` 指令规定了将资源作为私有缓存，只能被单独用户使用，**一般存储在用户浏览器中**。    `Cache-Control: private`

2.`public` 指令规定了将资源作为公共缓存，可以被多个用户使用，**一般存储在代理服务器中**。`Cache-Control: public`

## 23.使用 session 的过程是怎样的？
- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值；
- 存入浏览器中;客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

## 24.DDos 攻击了解吗？
客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认 没有彻底根治的办法，除非不使用 TCP DDos 预防:   
1)限制同时打开SYN半链接的数目；  
2)缩短SYN半链接的 Time out 时间；  
 3)关闭不必要的服务。


## 25.MTU 和 MSS 分别是什么？
MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。

MS5：maximum segment size，最大分节大小，为 TCP 数据包每次传输的最大数据分段大小，一般由发送端向对端 TCP 通知对端在每个分节中能发送的最大TCP数据。MSS 值为 MTU 值减去I Pv4 Header(20 Byte) 和 TCP header(20Byte) 得到。

## 26.TCP头部中有哪些信息？
TCP头部由源端口、目的端口、序号、确认号、标识位、校验和以及可选信息等部分组成，最少20个字节，最多60个字节。

- **源端口和目标端口**，各占2个字节，结合IP协议包头部的源IP地址和目标IP地址可以确定连接的两台主机和端口。
- **序列号码**，占4个字节，用于标识当前数据包的位置，有两种特殊情况，当SYN标志或FIN标志为1的时候。
	- 如果SYN标志为1，其值是初始序列号ISN。
	- 如果SYN标志为0，握手后的第一个数据包的值为ISN+1，后续的数据包的值为上一个数据包的序列号码+上一个数据包的数据段长度。 
- **确认号码**，占4个字节，只有ACK标志为1时，确认号码才有效，其值是本端期望下次收到的序列号码。 
- **数据偏移**，占4bit，表示数据部分的起始位置，也可以认为是tcp头部的长度，范围是5～15，单位是4个字节，比如取值是5(二进制是1001)，说明头部长度是5 * 4字节 = 20字节。
- **保留字段**，占3bit，值是000，目前未使用，没有意义。
- **标识位(experimental)**，占 6 bit；
- **窗口大小**，占2个字节，表示从确认号码开始，发送方可以接收的字节数，即TCP缓冲区的可用大小，用于流量控制，窗口最大65535个字节。
- **校验和**，占2个字节，通过对整个TCP数据包，包括TCP头部和数据部分进行计算得到，用于校验收到的TCP数据包的正确性和完整性。
- **紧急指针**，占2个字节，只有当URG标识为1时紧急指针才有效，紧急指针指出在数据包中紧急数据共有多少个字节，紧急数据放在本报文段数据的最前面。
- **选项部分和填充**，最多40个字节，必须为4的整数倍，不够4字节的填充0。


[https://zhixing.co/lesson/detail/1435146487706779649](https://zhixing.co/lesson/detail/1435146487706779649)


## 27.网络的七层/五层模型主要的协议有哪些？
<img src = "http://oss.interviewguide.cn/img/202205072300758.png">


## 28.什么是半连接队列？
**半连接队列** 是指服务器在收到客户端的 SYN 请求，但还没有完整建立连接时所处的状态。 当服务器收到客户端的 SYN 请求后，将客户端的请求放入半连接队列，等待服务器完成第二次握手并建立连接。 在半连接队列中，服务器可以接受新的 SYN 请求，但是尚未完成三次握手的连接不会被传递给应用程序处理。

半连接队列：

- **提供临时存储空间**：半连接队列为尚未完成三次握手的连接提供了临时存储空间，保留了连接的基本信息。
- **防止连接丢失**：当服务器的并发连接请求超过其处理能力时，半连接队列可以暂存未完成握手的连接，避免连接请求被丢失。


**服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的**，所以服务器容易受到SYN洪泛攻击。

**SYN 攻击** 就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server 则回复确认包，并等待 Client 确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

常见的防御 SYN 攻击的方法有如下几种：

- 缩短超时(SYN Timeout)时间；
- 增加最大半连接数；
- 过滤网关防护；
- SYN cookies技术；


## 29.四次挥手
<img src="https://cdn.xiaolincoding.com//mysql/other/18635e15653a4affbdab2c9bf72d599e.png">

- 服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 `CLOSE_WAIT` 状态。
- 在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以**必须要得继续 read 接收缓冲区已接收的数据**。
- 接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 `LAST_ACK` 状态；

> close 函数，同时 socket 关闭发送方向和读取方向。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，也不会发送 FIN 报文，0 时才释放；
> 
> shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用。


任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。


四次挥手释放连接时，等待2MSL的意义?

- 保证客户端发送的最后一个ACK报文段能够到达服务端（超时重传）。
- 防止“已失效的连接请求报文段”出现在本连接中。 客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以**使本连接持续的时间内所产生的所有报文段都从网络中消失**，使下一个新的连接中不会出现这种旧的连接请求报文段。

<img src="http://oss.interviewguide.cn/img/202205220036408.png">


## 30.对称加密和非对称加密的区别都有那些？
密钥

- 对称加密：使用同一个密钥进行加密和解密。这意味着加密方和解密方必须事先共享同一个密钥，并且保证这个密钥的安全。
- 非对称加密：使用一对密钥，一个公开密钥（公钥）用于加密，一个私有密钥（私钥）用于解密。公钥可以公开分享，而私钥必须保持私密。

**加密速度**

- 对称加密：通常更快，因为它使用较简单的算法来处理大量数据。
- 非对称加密：由于其复杂的数学运算，尤其是在处理大量数据时，比对称加密慢得多。

**安全性**

- 对称加密：虽然对称加密算法通常很难破解，但密钥的管理和分发过程可能导致安全漏洞。
- 非对称加密：提供了更高的安全性，因为即使公钥被公开，没有私钥也无法解密信息。不过，实现上更为复杂，需要更小心地保护私钥。

**使用场景**

- 对称加密：适用于需要快速处理大量数据的场景，如文件加密、数据库加密、网络数据传输加密等。
- 非对称加密：常用于安全敏感的通信中，如数字签名、SSL/TLS证书验证、安全电子邮件等。由于其速度较慢，通常用于加密少量数据或用于加密对称加密中使用的密钥。

**典型算法**

- 对称加密算法：AES（高级加密标准）、DES（数据加密标准）、3DES（三重数据加密算法）、RC4等。
- 非对称加密算法：RSA、ECC（椭圆曲线密码学）、Diffie-Hellman密钥交换协议、ElGamal等。

## 31.从输入 URL 到页面展现发生了什么？
1. **解析 URL**：分析 URL 所需要使用的传输协议和请求的资源路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，则对非法字符进行转义后在进行下一过程。
1. **缓存判断**：判断所请求的资源是否在缓存里，如果请求的资源在缓存里且没有失效，那么就直接使用，否则向服务器发起新的请求。。
1. **域名解析** （DNS 解析）：把域名映射为 IP 的系统，访问的时候可以直接访问域名，更方便一些。
1. **获取 MAC 地址**：本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相结合，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC 地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。
1. TCP 三次握手。
1. HTTPS 的 TLS 四次握手
1. 发送 HTTP 请求（请求报文由请求行【包含请求方法、URL 和版本协议】、请求头、空行和请求体四个部分组成）。
1. 服务器处理请求并返回 HTTP 报文（响应报文由响应行、响应头部、空行和响应主体三部分组成）。
1. 断开连接（TCP 四次挥手）。
1. 浏览器解析渲染页面。

[https://github.com/yd160513/blog/issues/17](https://github.com/yd160513/blog/issues/17)

## 32.如何实现扫码登录功能？

二维码登录本质上也是一种登录认证方式。既然是登录认证，要做的也就两件：

- 告诉系统我是谁；
- 向系统证明我是谁；

**三个过程：待扫描、已扫描待确认、确认**

1. 访问PC端二维码生成页面，PC 端请求服务端获取二维码ID
1. 服务端生成相应的二维码 ID，设置二维码的过期时间，状态等【二维码ID与PC端设备信息进行绑定】。
1. PC获取二维码 ID，生成相应的二维码【为了及时知道二维码的状态，客户端在展现二维码后，PC端不断的轮询服务端，比如每隔一秒就轮询一次，请求服务端告诉当前二维码的状态及相关信息】。
1. 手机端扫描二维码，获取二维码 ID。
1. 手机端将手机端 token 和二维码 ID 发送给服务端【服务端接收到后，它可以将身份信息与二维码ID进行绑定，生成临时token，然后返回给手机端（这时**PC 端显示已扫描待确认**），手机端在接收到临时 token 后会弹出确认登录界面】，确认登录【用户点击确认时，手机端携带临时token用来调用服务端的接口，告诉服务端，我已经确认】。
1. 服务端校验手机端 token，根据手机端 token 和二维码 ID 生成 PC 端登录的 token；
1. PC 端通过轮询方式请求服务端，通过二维码ID获取二维码状态，如果已成功，返回 PC token，登录成功。

> **账号密码登录时，客户端会将设备信息一起传递给服务端**；
  
>如果账号密码校验通过，服务端会把账号与设备进行一个绑定，存在一个数据结构中，这个数据结构中包含了账号 ID，设备 ID，设备类型等等

>然后服务端会生成一个token，用它来映射数据结构，这个token其实就是一串有着特殊意义的字符串，它的意义就在于，通过它可以找到对应的账号与设备信息，

> 客户端得到这个token后，需要进行一个本地保存，每次访问系统 API 都携带上 token 与设备信息。

> 服务端就可以通过 token 找到与它绑定的账号与设备信息，然后把绑定的设备信息与客户端每次传来的设备信息进行比较， 如果相同，那么校验通过，返回AP接口响应数据， 如果不同，那就是校验不通过拒绝访问


[https://juejin.cn/post/6940976355097985032](https://juejin.cn/post/6940976355097985032)

## 33.HTTPS 的 TLS 四次握手
如果使用的是 HTTPS 协议，在通信前还存在 TLS 的四次握手。

1. 首先由客户端向服务器端发送 TLS 协议的版本号、一个随机字符串和支持使用的加密算法。
1. 服务器端收到后，确认加密的算法，也向客户端发送一个随机字符串、确定的加密算法和自己的数字证书（包含公钥）。
1. 客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机字符串，并使用证书中的公钥对随机字符串加密，再生成一个前面所有内容的 hash 值供服务器端检验，然后发送给服务器端。
1. 服务器端接收后，使用自己的私钥对数据解密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。
1. 这个时候双方都有了三个随机字符串，按照之前所约定的加密方法，使用这三个随机字符串生成一把共享秘钥。以后双方通信前，就使用这个秘钥对数据进行加密后再传输。

<img src="https://user-images.githubusercontent.com/34637837/218344479-0a111630-fbbc-44c8-9418-494b5b8bca2b.png">

> **数字证书认证机构(CA，Certificate Authority)是客户端与服务器双方都可信赖的第三方机构**。  
> 服务器的运营人员**向  CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起**。进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证如果验证通过，就可以开始通信了。

## 34.