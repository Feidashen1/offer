# C++

----------

## 1.C++ 在 main() 函数执行前，后执行了哪些操作?
main 函数执行之前，主要就是初始化系统相关资源：

1. 设置栈指针：栈分配相关的位置，用来放一些局部变量和其他数据；
1.  static 静态和 global 全局变量，即 data 段的内容：**把全局和静态变量初始化**；
3. 将未初始化部分的全局变量赋初值：数值型 short，int，long 等为0，bool 为FALSE，指针为NULL，等等，即 .bss 段的内容：**将未设置初值的全局变量赋初值**；
4. 全局对象初始化，在main之前调用构造函数；
5. 将main函数的参数，argc，argv等传递给main函数，然后才真正运行main函数。

在执行完 main 函数后：执行全局的析构函数，要销毁堆内存，关闭标准输入，输出，错误流。

## 2. 结构体内存对齐问题
- 结构体内成员按照声明顺序存储，第一个成员地址和整个结构体地址相同。
- 未特殊说明时，按结构体中size最大的成员对齐(若有double成员，按8字节对齐)

**内存对齐：** 一种提高内存访问速度的策略，CPU 在访问未对齐的内存可能需要经过两次的内存访问，而经过内存对齐一次就可以了。

**内存对齐的原则：**

- 对于结构体的各个成员，<font color="#F100">除了第一个成员的偏移量为 0 外，其余成员的偏移量是 **其实际长度** 的整数倍，如果不是，则在前一个成员后面补充字节。</font>
- 结构体内所有数据成员各自内存对齐后，结构体本身还要进行一次内存对齐，<font color="#F100">**保证整个结构体占用内存大小是结构体内最大数据成员的最小整数倍**。</font>
- 如程序中有  `#pragma pack(n)` 预编译指令，则所有成员对齐以 n 字节 为准（即偏移量是n的整数倍），不再考虑当前类型以及最大结构体内类型。

[https://www.cnblogs.com/hyacinthLJP/p/16041690.html](https://www.cnblogs.com/hyacinthLJP/p/16041690.html)

- C++ `alignas` 用来**指定**对象的对齐字节数。效果和__attribute__((aligned(n)))一样，对齐值必须是 2 的幂，`alignas` 指定的对齐要求不能低于类型的自然对齐要求。；
- C++ `alignof` 用来**查看**对象的对齐字节数。用法类似于sizeof。

使用<stddef.h>头文件中的，**offsetof 宏**，可以获得结构成员相对于结构开头的字节偏移量 `offserof(S,t)`，其中 `S` 是结构体，`t` 是结构体变量。

[http://t.csdnimg.cn/P5cZl](http://t.csdnimg.cn/P5cZl)

## 3. 指针和引用的区别
C++ 指针和引用的区别在于：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元； 而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。

- 指针是存储变量地址的变量；引用是变量的别名；
- 指针变量定义时不必初始化；引用定义时必须初始化，不然会报错；
- 指针变量定义时可以初始化为 NULL；引用不能初始化为 NULL，不然报错；
- const 修饰指针变量，const 放在之前，指针变量所指向变量的值不可改变，指针值可以改变；const 放在之后，指针变量所指向变量的值可以改变，指针值不可以改变；const 修饰引用，const 放在&之前，不能修改引用所表示的变量的值；const 放在 & 之后，const 的作用被忽略，可以修改引用所表示的变量的值。
- 非常指针在指针赋值后可以改变指针值；引用在初始化后不能再作为别的变量的别名。
- sizeof 运算符作用于指针变量得到指针变量自身大小；作用于引用，得到引用所指向的变量的大小。
- 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。
- 指针可以有多级，引用只有一级。
- 指针的自增、自减表示指向下一个同类型变量的地址，一般用于指向数组的指针；引用的自增、自减表示指向变量值的增、减。


> 指针的大小并不是固定的，它取决于运行程序的计算机架构。 在 32 位系统中，一个指针通常占用 4 个字节（32 bits / 8 bits per byte = 4 bytes）。 而在 64 位系统中，一个指针则占用 8 个字节（64 bits / 8 bits per byte = 8 bytes）。

## 4.在传递函数参数时，什么时候使用引用，什么时候使用指针，什么时候按值传递呢？
对于使用传递的值而不做修改的函数：

- 如果数据量很小，如内置数据类型或小型结构，则按值传递；
- 如果数据对象是数组，则使用指针，并将指针申明为指向 `const` 的指针(如`void fun(const int * arr, int length)`)；
- 如果数据对象是较大的结构，则使用 `const` 指针或 `const` 引用；
- 如果数据对象是类对象，则使用 `const` 引用。传递类对象参数的标准方式是按引用传递。

对于修改调用函数中数据的函数：

- 如果数据对象是内置数据类型，则使用引用，如`int* randomArr(int& length)`，别人看到这个声明就知道此函数内部会修改 `length` 的值；
- 如果数据对象是数组，则只能使用指针；
- 如果数据对象是结构体，则使用引用或指针；
- 如果数据对象是类对象，则使用引用；

总结：

- <font color="#A100">需要**返回函数内局部变量的内存的时候用指针**。使用指针传递参数需要先开辟内存，用完要释放指针，不然会内存泄漏。而返回局部变量的引用是没有意义的。
- 对栈空间大小比较敏感的场景（比如使用递归）要使用引用。**使用引用传递的时候不需要创建临时变量**，开销会更小。
- 类对象作为参数传递的时候使用引用，这是cpp类对象传递的标准方式。</font>


## 5. 堆和栈的区别
1. **申请方式不同**：
栈由系统自动分配；
堆是自己申请和释放的。
2. **申请大小限制不同**：
栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定（可以通过 `ulimit -a` 查看，由 `ulimit -s` 修改）；堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。【栈空间默认是4M，堆区一般是 1G - 4G】
3. **申请效率不同**：
栈由系统分配，速度快，不会有碎片；
堆由程序员分配，速度慢，且会有碎片。
4. **使用方法不同**：堆一般是底层用` malloc `通过` brk() `系统调用从堆分配内存；栈一般就是直接定义，就是分配，简单的 `esp, ebp` 指针的移动。
5. **存放内容不同**：堆一般是在堆的头部用一个字节存放堆的大小，具体内容由程序员安排；栈在函数调用时第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址然后是函数的各个参数，在大多数的 C 编译器中，**参数是由右往左入栈（占位符确定参数个数）**，然后是函数中的局部变量。
【[C语言函数参数压栈顺序为何是从右到左？（从左向右的话，碰到printf的会陷入死循环）](https://blog.csdn.net/yhc166188/article/details/91949428?spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-91949428-blog-51559788.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-91949428-blog-51559788.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=16)】
6. 栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了**栈的效率比较高**。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。
7. 堆地址向上生长（低到高），栈地址向下生长（高到低），因为计算机总是先从低地址开始读，所以，栈先进后出，堆先进先出。


[http://t.csdnimg.cn/sV3N5](http://t.csdnimg.cn/sV3N5)

## 6.区别指针类型
	int *p[10]
	int (*p)[10]
	int *p(int)
	int (*p)(int)

1. `int *p[10]`表示指针数组，强调数组概念，是一数组变量，数组大小为 10，数组内每个元素都是指向 `int` 类型的指针变量（一个有十个指针的数组）。
1. `int (*p)[10]`表示数组指针，强调是指针，只有一个变量，是指针类型，不过指向的是一个 `int` 类型的数组，这个数组大小是10（一个指向有十个整型数据数组的指针）。
1. `int *p(int)`是函数声明，函数名是 `p`，参数是 `int` 类型的，返回值是`int *`类型的。
1. `int (*p)(int)`是函数指针，强调是指针，该指针指向的函数具有 `int` 类型参数，并且返回值是 `int` 类型的。

**指针函数与函数指针：**

- **指针函数**：本质是一个函数，不过它的返回值是一个指针。【`ret *func(args, ...);`--`func` 是一个函数，`args` 是形参列表，`ret *` 作为一个整体，是 `func` 函数的返回值，是一个指针的形式。】
- **函数指针**：本质是一个指针，该指针的地址指向了一个函数，所以它是指向函数的指针。函数的定义是存在于代码段，因此，每个函数在代码段中，也有着自己的入口地址，函数指针就是指向代码段中函数入口地址的指针。【`ret (*p)(args, ...);` —`ret` 为返回值，`*p`作为一个整体，代表的是指向该函数的指针，`args` 为形参列表。其中`p`被称为函数指针变量 】


[http://t.csdnimg.cn/ItQSC](http://t.csdnimg.cn/ItQSC)


## 7.new/delete 与 malloc/free 的异同
- 相同点：都可用于内存的动态申请和释放；
- 不同点：
	- 前者是 C++ 运算符，后者是 C/C++ 语言标准库函数；
	- new 自动计算要分配的空间大小，malloc 需要手动计算；
	- new 是类型安全的，malloc不是。
	- new 调用名为 `operator new` 的标准库函数分配足够空间并调用相关对象的构造函数，delete 对指针所指对象运行适当的析构函数；然后通过调用名为`operator delete` 的标准库函数释放该对象所用内存。后者均没有相关调用；
	- 后者需要库文件支持，前者不用；
	- new 是封装了 malloc，直接 free 不会报错，但是这只是释放内存，而不会析构对象。
	- malloc 和 free 返回的是 void 类型指针(必须进行类型转换)，new 和 delete 返回的是具体类型指针。

**new 的实现过程**：首先调用名为 `operator new` 的标准库函数，分配足够大的原始为类型化的内存，以保存指定类型的一个对象；接下来运行该类型的一个构造函数，用指定初始化构造对象；最后返回指向新分配并构造后的的对象的指针。

**delete 的实现过程**：对指针指向的对象运行适当的析构函数，然后通过调用名为 `operator delete` 的标准库函数释放该对象所用内存。

## 8.malloc/free和new/delete释放后的内存系统会马上回收吗？
用户 `free` 掉的内存并不是都会马上归还给系统，`ptmalloc` 会统一管理 `heap` 和 `mmap` 映射区域中的空闲的 `chunk`，当用户进行下一次分配请求时，`ptmalloc` 会首先试图在空闲的 `chunk` 中挑选一块给用户，这样就避免了频繁的系统调用，降低了内存分配的开销。

`ptmalloc` 将相似大小的 `chunk` 用双向链表链接起来，这样的一个链表被称为一个 bin。`ptmalloc` 一共维护了 128 个 bin，并使用一个数组来存储这些 bin。

内存管理一般会有一个`free block list`，`free` 掉的东西就放在这里来，这里会尝试合并这些散乱的 `block`，而 `malloc` 首先找的也是` free block list`，而非从OS申请新的内存。【碎片问题：页大小固定，避免小内存一直分配，占据不同的页】

[https://blog.csdn.net/YMY_mine/article/details/81180168](https://blog.csdn.net/YMY_mine/article/details/81180168)


## 9.宏定义和函数有何区别？
- 宏在预处理阶段完成替换，之后被替换的文本参与编译，相当于**直接插入**了代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数；
- 宏定义属于在结构中插入代码，**没有返回值**；函数调用具有返回值；
- 宏定义**参数没有类型**，不进行类型检查；函数参数具有类型，需要检查类型；
- 宏定义不要在最后加分号。

## 10.宏定义 和 typedef 区别?
- 宏主要用于定义常量及书写复杂的内容；`typedef` 主要用于定义类型别名；
- 宏替换发生在编译阶段之前，属于文本插入替换；`typedef` 是编译的一部分；
- 宏不检查类型；typedef会检查数据类型；
- 宏不是语句，不在在最后加分号；typedef是语句，要加分号标识结束；

注意对指针的操作，`typedef char*p_char`和`#define p_char char *`区别巨大：

	typedef (int*)  pINT;
	#define pINT2 int*

效果相同？实则不同！实践中见差别：`pINT a,b;`的效果同`int *a; int *b;`表示定义了两个整型指针变量；而`pINT2 a,b;`的效果同`int *a, b;`表示定义了一个整型指针变量 a 和整型变量 b。


## 11.变量声明和定义区别?
- 声明仅仅是把变量的声明的位置及类型提供给编译器，并不分配内存空间；定义要在定义的地方为其**分配存储空间**。
- 相同变量可以在**多处声明**(外部变量 `extern`)，但只能在**一处定义**。


## 12.strlen 和 sizeof 区别?
- `sizeof` 是运算符，并不是函数，结果在编译时得到而非运行中获得；`strlen` 是字符处理的库函数；
- `sizeof` 参数可以是任何数据的类型或者数据(`sizeof` 参数不退化)；`strlen` 的参数只能是字符指针且结尾是`\0'`的字符串；
- 因为 `sizeof` 值在编译时确定，所以不能用来得到动态分配(运行时分配)存储空间的大小。

## 13.常量指针和指针常量区别?
- **指针常量**：是一个指针，读成常量的指针，指向一个只读变量，也就是后面所指明的`int const `和 `const int`，都是一个常量，可以写作 `int const *p` 或 `const int *p`；【**不能够通过指针修改内存数据**。只能防止通过指针引用修改内存中的数据，并不保护指针所指向的对象】
- **常量指针**：是一个不能改变指向的指针。指针是个常量，必须初始化，一旦初始化完成，它的值(也就是存放在指针中的地址)就不能在改变了，即不能中途改变指向，如`int *const p`。【**指针所指向的位置不能改变**，即指针本身是一个常量，但是指针所指向的内容可以改变。】

<font color="#F100">【以*为中间划一条线，看const修饰谁就谁就是常量。】</font>

[http://t.csdnimg.cn/q3F0U](http://t.csdnimg.cn/q3F0U)


## 14.C 语言和 C++ 的区别

1. **过程**：*C 编程语言不支持面向对象编程。因此，它不允许多态性、继承等。作为一种面向对象的语言，C++ 支持多态性和继承。*
2. **安全性**：*由于 C 语言不允许封装，数据变得可访问，其他实体可以破坏它。然而，C++ 支持封装，可以保护数据结构并根据需要使用它。*
3. **方法**：*C 编程语言鼓励自顶向下的方法，首先定义一个通用问题，然后将其分解为较小的任务。另一方面，C++ 鼓励自底向上的方法。这涉及首先识别和定义类，然后使用它们执行最初的任务。*
4. **输入/输出函数**：在 C 中，I/O 操作主要通过 C 标准库的标准 I/O 函数进行处理，如 printf() 和 scanf()。这些函数提供基本的格式化和读取功能，但缺少 C++ 中的一些高级功能；另一方面，C++ 通过使用 iostream 库中的对象扩展了 I/O 功能，这些对象称为**标准 I/O 流**。cout 流允许进行简单而灵活的输出操作，而 cin 流提供了增强的输入功能。C++ 流支持运算符重载，可方便地输出复杂数据类型并启用自定义格式选项。
5. **重载和覆盖**：方法覆盖允许子类重新定义从其祖先继承的函数。重载允许同一个函数有多个版本，每个版本具有唯一的参数。C 不支持这两者，但 C++ 支持。
6. **内存分配**： C 编程依赖于两个关键函数——`calloc()`和`malloc()`——用于内存分配。相应的 free() 函数用于内存释放。C++使用 new 运算符进行动态内存分配，使用delete运算符进行释放。
7. **编译**：C 和 C++ 的软件开发始于编写源代码。C文件的源代码具有`.c`扩展名，而 C++ 使用扩展名如`.cpp`或`.cxx`。这些源代码文件包含程序的指令和逻辑。
8. **变量**：通常，C编程语言使用两种类型的值：字面值和变量。C使用四种基本的变量类型：int、float、char 和 double。C++ 的主要变量类型包括 bool、void 和 wchar_t。
9. **特点**：C 编程语言是一种过程式、快速和高效的语言，具有模块化和丰富的内置运算符。与C不同，C++是一种过程式语言，具有面向对象程序设计（英语：Object-oriented programming，缩写：OOP）。此外，它是机器无关的、简单的和区分大小写的。
10. 在C++中，除了值和指针之外，**新增了引用**。引用型变量是其他变量的一个别名，我们可以认为他们只是名字不相同，其他都是相同的。

11. C++中的`try/catch/throw`异常处理机制取代了标准C中的`setjmp()`和`longjmp()`函数。

C编程语言是一种中级语言，而C++是一种高级语言。



[http://t.csdnimg.cn/X7tM2](http://t.csdnimg.cn/X7tM2)


## 15.C++中 struct 和 class 的区别？
相同点：

1. 两者都拥有成员函数、公有和私有部分；
1. 任何可以使用class完成的工作，同样可以使用struct完成。

不同点：

1. 两者中如果不对成员不指定公私有，struct默认是公有的，class则默认是私有的；
2. class默认是private继承，而struct默认是public继承；
3. class 可以使用模板，而 struct 不能；


**引申：C++和C的struct区别**

- C 语言中：struct 是用户自定义数据类型(UDT)；C++中 struct 是抽象数据类型(ADT)，支持成员函数的定义，(**C++中的 struct 能继承，能实现多态**)
- C 中 struct 是没有权限的设置的，且 struct 中只能是一些变量的集合体，可以封装数据却不可以隐藏数据，而且**成员不可以是函数**；C++中，struct 增加了访问权限，且可以和类一样有成员函数，成员默认访问说明符为public(为了与C兼容)；
- struct 作为类的一种特例是用来自定义数据结构的。一个结构标记声明后，在C中**必须在结构标记前加上struct**，才能做结构类型名(除:typedef struct class0;)；C++中结构体标记(结构体名)可以**直接作为结构体类型名使用**，此外结构体 struct 在C++ 中被当作类的一种特例；

    	Student xiaoming, jim; //C++允许省略struct，在Student前面可以不加struct。定义结构体Student类型的变量xiaoming,jim。
    	struct Student xiaoming, jim; //C风格的变量定义，在C++里面也没有问题，兼容。

[https://www.cnblogs.com/banluxinshou/p/11823158.html](https://www.cnblogs.com/banluxinshou/p/11823158.html)


## 16.define宏定义和const的区别？
角度1： 就定义常量说的话， const 定义的常数是**变量 也带类型**， #define 定义的只是个**常数 不带类型**。

角度2： 就起作用的阶段而言，#define 是在编译的**预处理阶段**起作用，而 const 是在 **编译、运行**的时候起作用。

角度3： 就起作用的方式而言，#define 只是简单的字符串替换，没有类型检查。而 const 有对应的数据类型，是要进行判断的，可以避免一些低级的错误。 正因为 define 只是简单的字符串替换会导致边界效应，具体举例可以参考下面代码：

	#define N 2+3     // 我们预想的 N 值是 5，我们这样使用 
	Ndouble a = N/2;  // 我们预想的  a 的值是 2.5，可实际上 a 的值是 3.5
角度4： 就空间占用而言， 例如：

	#define PI 3.14     //预处理后 占用代码段空间
	const float PI=3.14;    // 本质上还是一个 float，占用数据段空间

角度5： 从代码**调试**的方便程度而言, const 常量可以进行调试的，#define 是不能进行调试的，因为在预编译阶段就已经替换掉了

角度6： 从是否可以再定义的角度而言，const 不足的地方，是与生俱来的，**const 不能重定义**，而 #define 可以通过 #undef 取消某个符号的定义，再重新定义；【[const定义的对象属性可以改变](https://blog.csdn.net/Ain_z/article/details/109634087)】

[https://www.runoob.com/note/12963](https://www.runoob.com/note/12963)


## 17.C++ 中 const 和 static 的作用？
static

不考虑类的情况：

- 隐藏。所有不加 static 的全局变量和函数具有全局可见性，可以在其他文件中使用，**加了之后只能在该文件所在的编译模块中使用**；
- 默认**初始化为0**，包括未初始化的全局静态变量与局部静态变量，都存在**全局未初始化区**；
- 静态变量在函数内定义，**始终存在，且只进行一次初始化**，具有记忆性，其作用范围0与局部变量相同，函数退出后仍然存在，但不能使用

考虑类的情况：

- static 成员变量：**只与类关联**，不与类的对象关联。**定义时要分配空间，不能在类声明中初始化**，必须在类定义体外部初始化，**初始化时不需要标示为static**；可以被非static成员函数任意访问。
- static 成员函数：不具有this指针，无法访问类对象的非static成员变量和非static成员函数；不能被声明为const、虚函数和volatile；可以被非static成员函数任意访问；


const

不考虑类的情况：

- const 常量在定义时必须初始化，之后无法更改；
- const 形参可以接收 const 和非 const 类型的实参，例如//i可以是int 型或者 const int型void fun(const int& i){ //...}

考虑类的情况：

- const成员变量：不能在类定义外部初始化，只能通过构造函数初始化列表进行初始化，并且必须有构造函数；不同类对其const数据成员的值可以不同，所以不能在类中声明时初始化；
- const成员函数：const 对象不可以调用非 const 成员函数；非const对象都可以调用；不可以改变非 `mutable`(用该关键字声明的变量**可以在const成员函数中被修改)数据的值**）。


<font color="#A100">

const 定义的常量在超出其作用域之后其空间会被释放，而static 定义的静态常量在函数执行后不会释放其存储空间。</font>


类里的static cosnt 和 const static成员初始化：它们的初始化没有区别，虽然一个是静态常量一个是常量静态。静态都将存储在全局变量区域，其实最后结果都一样。可能在不同编译器内，不同处理，但最后结果都一样。  

[https://www.cnblogs.com/phpzhou/p/6390869.html](https://www.cnblogs.com/phpzhou/p/6390869.html)


## 18.C++的顶层 const 和底层 const?
**顶层const**：指的是 `const` 修饰的变量本身是一个常量，无法修改，指的是指针，就是`*`号的右边；

**底层const**：指的是 `const` 修饰的变量所指向的对象是一个常量，指的是所指变量，就是号的左边；

	int a = 10;int* const b1 = &a;        //顶层const，b1本身是一个常量
	const int* b2 = &a;       //底层const，b2本身可变，所指的对象是常量
	const int b3 = 20; 		   //顶层const，b3是常量不可变
	const int* const b4 = &a;  //前一个const为底层，后一个为顶层，b4不可变
	const int& b5 = a;		   //用于声明引用变量，都是底层const

- 如果 const 右结合修饰的为 `类型` 或者 `*`，那这个 const 就是一个底层 const；
- 如果 const 右结合修饰的为 `标识符`，那这个 const 就是一个顶层 const。

主要区别：

- 被修饰的变量本身无法改变的 const 是顶层 const；
- 通过指针或引用等间接途径来限制目标内容不可变的 const 是底层 const。

顶层 const 表示指针本身（对象值）是个常量；
底层 const 表示指针所指的对象（地址）是一个常量。

## 19.数组名和指针(这里为指向数组首元素的指针)区别?
- 二者均可通过**增减偏移量来访问**数组中的元素；
- 数组名不是真正意义上的指针，可以理解为常量指针，所以数组名没有自增、自减等操作；指针是变量指针；
- **当数组名当做形参传递给调用函数后，就失去了原有特性，退化成一般指针，多了自增、自减操作，但 sizeof 运算符不能再得到原数组的大小了**。

## 20.final 和 override 关键字
`final` 和 `override` 是C++11标准引入的两个关键字，它们为类的继承和多态机制提供了更多的控制权和明确性。

- `final` 关键字用于指示一个类或成员函数是最终的，**不能被继承或覆盖**，可以保护基类不被修改，防止滥用继承；
- `override` 关键字用于**明确指出**派生类中的成员函数旨在覆盖基类中的同名虚拟函数，并进行编译时类型检查。


## 21.拷贝初始化和直接初始化
- 如果**使用等号（=）**初始化一个变量，实际上执行的是“**拷贝初始化**”，编译器把等号右侧的初始值拷贝到新创建的对象中去。
- 与之相反，如果**不使用等号**，则执行的是“**直接初始化**”；

直接初始化实际上是要求编译器使用普通的函数匹配来选择与我们提供的参数最匹配的构造函数；

拷贝初始化实际上是要求编译器将右侧运算对象拷贝到正在创建的对象中，通常用拷贝构造函数来完成；

**拷贝构造函数的形参必须是引用类型**的原因：如果不是引用类型，为了调用拷贝构造函数，我们必须拷贝它的实参，但为了拷贝实参，我们又需要调用拷贝构造函数，如此无限循环，造成错误。

使用 `explicit` 修饰构造函数时：如果构造函数存在隐式转换，编译时会报错

[https://blog.csdn.net/capecape/article/details/78276677](https://blog.csdn.net/capecape/article/details/78276677)


## 22.C++初始化与赋值的区别
初始化不是赋值，初始化的含义是在创建对象时赋予一个初值，而赋值是将对象的当前值擦除掉，以一个新值代替。

[http://t.csdnimg.cn/sBvrQ](http://t.csdnimg.cn/sBvrQ)

## 23.extern"C" 的用法
`extern "c" ` 的主要作用就是为了**能够正确实现 C++ 代码调用其他 C 语言代码**。加上 `extern “c”` 后，会指示**编译器这部分的代码按C语言，而不是C++的方式进行编译**。


由于C++支持函数重载，因**此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名**；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。


**extern "C"使用要点**：

- 可以是单一语句：`extern “C” double sqrt(double);`
- 可以是复合语句，相当于复合语句中的声明都加了 `extern “C”`：`extern “C”{ double sqrt(double); int min(int, int);}`
- 可以包含头文件，相当于头文件中的声明都加了extern “C” ：`extern “C”{＃include <cmath> }`
- 不可以将 extern “C” 添加在函数内部;
- 如果函数有多个声明，可以都加 extern “C”, 也可以只出现在第一次声明中，后面的声明会接受第一个链接指示符的规则。


## 24.野指针和悬空指针
- **野指针**：指针变量未及时初始化 => 定义指针变量及时初始化，要么置空；
- **悬空指针**：指针 free 或 delete 之后没有及时置空  => 释放操作后立即置空；

C++智能指针的本质就是避免悬空指针的产生。

## 25.C 和 C++ 的类型安全？
类型安全很大程度上可以等价于内存安全，**类型安全的代码不会试图访问自己没被授权的内存区域**。

<font color="#F100">**类型安全**是指同一段内存在不同的地方，会被强制要求使用相同的办法来解释(内存中的数据是用类型来解释的)。</font>

C 只在局部上下文中表现出类型安全；因为同一段内存可以用不同的数据类型来解释，比如1用int来解释就是1，用boolean来解释就是true。

如果C++使用得当，它将远比C更有类型安全性。相比于C，C++提供了一些新的机制保障类型安全：

- 操作符new返回的指针类型严格与对象匹配，而不是void*；
- C中很多以void*为参数的函数可以改写为C++模板函数，而模板是支持类型检查的；
- 引入const关键字代替#define constants，它是有类型、有作用域的，而#define constants只是简单的文本替换；
- 一些#define宏可被改写为inline函数，结合函数的重载，可在类型安全的前提下支持多种类型，当然改写为模板也能保证类型安全；
- C++提供了dynamic_cast关键字，使得转换过程更加安全，因为dynamic_cast比static_cast涉及更多具体的类型检查。


Java语言是类型安全的，除非强制类型转换。

[http://t.csdnimg.cn/AlWSs](http://t.csdnimg.cn/AlWSs)


## 26.C++中的重载、重写(覆盖)和隐藏的区别？
**重载**：是指同一可访问区内被声明的几个具有不同参数列（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，**重载不关心函数返回类型**。

**隐藏**：是指派生类的函数屏蔽了与其同名的基类函数，注意**只要同名函数，不管参数列表是否相同，基类函数都会被隐藏**。

**重写(覆盖)**：是指派生类中存在重新定义的函数。其**函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致**。**只有函数体不同**（花括号内），派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有 `virtual` 修饰，派生类可以没有。


## 27.C++有哪几种的构造函数
通常 C++中的构造函数可以分为5类：默认构造函数、普通构造函数、拷贝构造函数、转换构造函数、移动构造函数。

- **默认构造函数**：未提供显式初始值时，用来创建对象的构造函数`Student();//没有参数`；
- **普通构造函数**：C++用于构建类的新对象时需要调用的函数`Student(int num，int age）;//有参数`；
- **拷贝构造函数**：何时生成默认的拷贝构造函数；
- **转换构造函数**：一个构造函数接收一个不同于其类类型的形参，可以视为将其形参转换成类的一个对象【string 类中可以找到使用转换构造函数的实用示例】；
- **移动构造函数**：以移动而非深拷贝的方式初始化含有指针成员的类对象。简单的理解，移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”。


委托构造函数是C++11引入的一个特性，它**允许一个构造函数调用同一类的另一个构造函数**，从而避免在类内部出现相似的初始化代码，提高代码的可维护性。在构造函数的初始化列表中使用` : `符号，可以调用同一类中的其他构造函数。

委托构造函数的调用必须出现在构造函数的初始化列表中。在构造函数主体中调用其他构造函数是不允许的。

## 28.浅拷贝和深拷贝的区别
**浅拷贝**：浅拷贝只是拷贝一个指针，并没有新开辟一个地址，拷贝的指针和原来的指针指向同一块地址，**如果原来的指针所指向的资源释放了，我那么再释放浅拷贝的指针的资源就会出现错误**。

**深拷贝**：**深拷贝不仅拷贝值，还开辟出一块新的空间用来存放新的值**，即使原先的对象被析构掉，释放内存了也不会影响到深拷贝得到的值。在自己实现拷贝赋值的时候，如果有指针变量的话是需要自己实现深拷贝的。

深拷贝和浅拷贝是指在赋值一个对象时，拷贝的深度不同。 在进行深拷贝时，会拷贝所有的属性，并且如果这些属性是对象，也会对这些对象进行深拷贝，直到最底层的基本数据类型为止。

## 29.内联函数和宏定义的区别
**宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的**。

而且**内联函数是真正的函数**，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销。

**内联函数有类型检测、语法判断等功能，而宏没有。**


## 30.public, protected 和 private 访问和继承权限 /public/protected/private 的区别?
**访问权限：**

- public:可以被任意实体访问；
- protected:只允许子类及本类的成员函数访问；
- private:只允许本类的成员函数访问；

**继承：**

1. public 继承不改变基类成员的访问权限；
2. private 继承使得基类所有成员在子类中的访问权限变为 private；
3. protected 继承将基类中public成员变为子类的protected成员，其它成员的访问 权限不变；
4. 基类中的 private 成员不受继承方式的影响，子类永远无权访问。


友元是一种**定义在类外部的普通函数，但它需要在类体内进行声明**，为了与该类的成员函数加以区别，在声明时前面加以关键字 `friend`。友元不是成员函数，但是它可以访问类中的私有成员。友元的作用在于提高程序的运行效率，但是，它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的私有成员。

[【C++】友元函数和友元类（作用及优缺点）](http://t.csdnimg.cn/ThyG8)

## 31.如何用代码判断大小端存储？
- **大端存储**：是指数据的低位保存在内存的高地址中，而数据的高位保存在内存的低地址中；
- **小端存储**：是指数据的低位保存在内存的低地址中，而数据的高位保存在内存的高地址中。

<font color="#F100">想办法取出一个字节的内容，就可以知道是哪种存储方式。</font>

初始化一个 `16 进制` 的int型的数据，然后把它放在一个 `char` 类型的数组中，由于**十六进制的数据一位代表四个bit位**；`char` 型是8个bit位，那么十六进制的两位占一个 `char` 位，那么就可以把数据位分离。

**方法一：直接法**

	int main()
	{
		int a = 0x12345678;
		char i = a;
		printf("%x", i);
	}
定义一个十六进制的数据，数据类型为int型，之后定义一个char类型的数据，**int数据类型的大小为四个字节，而char类型的数据为一个字节，所以将int类型的数据赋值给char时会丢失三个字节的数据，char类型中存储的是int类型中低地址的数据**，这时候char类型获取的数据输出之后，如果输出的是12那就说明你低地址位置的数据是12，那就说明你的数据是大端存储，如果输出的结果是78那当前条件下就是小端存储。

**方法二：指针法**

	int main()
	{
	    int i = 0x1122;
		char* p = (char*)& i;
		if (p[0] == 0x22 && p[1] == 0x11) {
			cout << "little endian" << endl;
		}
		else if (p[0] == 0x11 && p[1] == 0x22) {
			cout << "big endian" << endl;
		}
	}

`*p`就是`p[0]`，把变量的地址强制类型转换为`char*`，这样就可以每次取出一个字节的内容，因为 `char` 的大小就是1个字节，`p[0]`和`p[1]`都表示一个 `char` 类型。

将`int*`类型的` &i`强制转换为了`char*`类型，但值没有改变（地址）；地址存储的值也未改变，`p` 就是表示的这个地址，但 `p` 是 `char*` 类型的变量，因此可以用`p[0]p[1]`去取，每一个`p[]`就是两个十六进制的数（也就是一个字节）。`p[0]`就是`0x22`, `p[1]`就是`0x11`。

**方法三：联合体法**

	int main(){
		union
		{
			int value;
			char union_bytes[ sizeof(int) ];
		} test;
		test.value = 0x0102;
		if (  ( test.union_bytes[ 0 ] == 1 ) && ( test.union_bytes[ 1 ] == 2 ) )
		{
			printf( "big endian\n" );
		}
		else if ( ( test.union_bytes[ 0 ] == 2 ) && ( test.union_bytes[ 1 ] == 1 ) )
		{
			printf( "little endian\n" );
		}
		else
		{
			printf( "unknown...\n" );
		}
	}
在联合体中定义一个 char 类型的变量和 int 类型的变量，利用二者所占同一段存储空间，可以通过引用联合体变量中的成员访问 `char`  类型的数据，取出一个字节的内容。

**在 `union` 中所有的数据成员共用一个空间**，而且是**从低位开始占用**，同一时间只能储存其中一个数据成员，所有的数据成员具有相同的起始地址，**共用体变量的内存空间大小是该变量中某个占用空间最大的那个成员所占的空间**。。

即上述的union虽然定义了两个成员，但其实这个union只占用了4个字节(32位机器中 int 所占的空间大小)，往 value 成员赋值（value完整是0x00000102），然后读取 union_bytes ，union_bytes[0]就是value的第一个字节，union_bytes[1]就是value的第二个字节。

[http://t.csdnimg.cn/lm2iI](http://t.csdnimg.cn/lm2iI)


## 32.volatile、mutable 和 explicit 关键字的用法？
volatile 关键字是一种类型修饰符，用它声明的类型变量**表示可以被某些编译器未知的因素更改**。

<font color="#F100">当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。</font>


volatile 定义变量的值是易变的，每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份。

多线程中被几个任务共享的变量需要定义为 volatile 类型。


volatile 限定符的用法和 const 很相似，它起到对类型额外修饰的作用；const 和volatile 限定符互相没什么影响，**某种类型可能既是 const 的也是 volatile 的**，此时它同时具有二者的属性。

只有 `volatile` 的成员函数才能被 `volatile` 的对象调用。

可以把一个非 volatile in t赋给 volatile int，但是不能把非 volatile 对象赋给一个volatile对象。

**mutable**

- 用 const 修饰的成员函数时，**const修饰this指针指向的内存区域，成员函数体内不可以修改本类中的任何普通成员变量**，当成员变量类型符前用 `mutable` 修饰时例外。

-  常对象可访问 const 或非 const 数据成员，不能修改，除非成员用mutable修饰；


> 常函数不能对普通成员变量（除mutable修饰外）进行写操作 ；
> 常函数可以被普通对象或者常对象调用；
> 
> 常对象不能调用所有普通函数，只能调用常函数；
> 常对象可以读成员变量；
> 
> [http://t.csdnimg.cn/pOfDm](http://t.csdnimg.cn/pOfDm)


**explicit**

c++ 提供了关键字 `explicit`，禁止通过构造函数进行的隐式转换。声明为 `explicit` 的构造函数不能在隐式转换中使用。

- 是针对**单参数**的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造)而言，需要多个实参的构造函数不能用于执行隐式转换，所以无需将这些构造函数指定为explicit。
-  explicit用于修饰构造函数，防止隐式转化。




[https://www.cnblogs.com/codemagiciant/p/17524184.html](https://www.cnblogs.com/codemagiciant/p/17524184.html)


## 33.什么情况下会调用拷贝构造函数？
拷贝构造函数是一种特殊的构造函数，它在创建对象时，是**使用同一类中之前创建的对象来初始化新创建的对象**。拷贝构造函数通常用于：

- 通过使用另一个同类型的对象来初始化新创建的对象；
- 复制对象把它作为参数传递给函数；
- 复制对象，并从函数返回这个对象；

如果在类中没有定义拷贝构造函数，编译器会自行定义一个。如果类带有指针变量，并有动态内存分配，则它必须有一个拷贝构造函数。

## 34.C++中有几种类型的new（plain new\nothrow new\placement new)

**1. plain new**

言下之意就是普通的 `new`，就是我们常用的 `new`；

在C++中定义如下：

	void* operator new(std::size_t) throw(std::bad_alloc);
	void operator delete(void *) throw();
	Copy to clipboardErrorCopied
因此 plain new 在空间分配失败的情况下，抛出异常`std::bad_alloc`而不是返回 `NULL`，因此通过判断返回值是否为 `NULL` 是徒劳的。

**2.nothrow new**

	char *p = new(nothrow) char[10e11];
`nothrow new `在空间分配失败的情况下是不抛出异常，而是返回 `NULL`；


**3.placement new**

    ADT *q = new(p) ADT;
这种 new **允许在一块已经分配成功的内存上重新构造对象或对象数组。** `placement new`不用担心内存分配失败，因为它根本不分配内存，它做的唯一一件事情就是调用对象的构造函数。

	void* operator new(size_t,void*);
	void operator delete(void*,void*);
	Copy to clipboardErrorCopied

`palcement new` 的主要用途就是反复使用一块较大的动态分配的内存来构造不同类型的对象或者他们的数组；

`placement new`构造起来的对象数组，要显式的调用他们的析构函数来销毁（析构函数并不释放对象的内存），千万不要使用delete，这是因为`placement new`构造起来的对象或数组大小并不一定等于原来分配的内存大小，使用delete会造成内存泄漏或者之后释放内存时出现运行时错误。


## 35.C++的异常处理的方法
- try、throw 和 catch 关键字`try...(throw)...catch...`；
- 函数的异常声明列表：在定义函数的时候知道函数可能发生的异常，可以在函数声明和定义时，指出所能抛出异常的列表`int fun() throw(int,double,A,B,C) {...};`
这种写法表名函数可能会抛出 `int,double` 型或者A、B、C三种类型的异常，如果 `throw` 中为空表明不会抛出任何异常，如果没有 `throw` 则可能抛出任何异常【在C++11这种做法已经被摒弃，而后者则被C++11的 noexcept （noexcept 的一个作用是**阻止异常的传播，提高安全性**）异常声明所代替：`void func() noexcept {...}//等价于void func() throw(){...}`】；
- C++标准异常类 `exception`：C++标准提供了一组标准异常类，这些类以基类 Exception 开始，标准程序库抛出的所有异常，都派生于该基类，该基类提供一个成员函数 what()，用于返回错误信息（返回类型为 const char*）。

【析构函数默认也是noexcept的】

[https://www.cnblogs.com/QG-whz/p/5136883.html](https://www.cnblogs.com/QG-whz/p/5136883.html)
[https://www.cnblogs.com/suozhiyuan/p/12528891.html#_label0](https://www.cnblogs.com/suozhiyuan/p/12528891.html#_label0)

## 36.值传递、指针传递、引用传递的区别和效率

**传值**： 函数参数压栈的是参数的副本。  
任何的修改是在副本上作用，没有作用在原来的变量上。  

**传指针**：压栈的是指针变量的副本。    
当你对指针解指针操作时，其值是指向原来的那个变量，所以**对原来变量操作**。  

**传引用**：压栈的是引用的副本。由于引用是指向某个变量的，对引用的操作其实就是**对他指向的变量的操作**。

**传递效率上**： 调用被调函数的代码将实参传递到被调函数体内的过程。 
指针传递和引用传递比值传递效率高。一般主张使用引用传递，代码逻辑上更加紧凑、清晰。 

**执行效率上**：在被调用的函数体内执行时的效率。    
因为传值调用时，当值被传到函数体内，临时对象生成以后，所有的执行任务都是通过**直接寻址**的方式执行的，而指针和大多数情况下的引用则是以**间接寻址**的方式执行的，所以实际的执行效率会比传值调用要低；如果函数体内对参数传过来的变量进行操作比较频繁，执行总次数又多的情况下，传址调用和大多数情况下的引用参数传递会造成比较明显的执行效率损失。

[https://www.cnblogs.com/ywliao/articles/8127531.html](https://www.cnblogs.com/ywliao/articles/8127531.html)

## 37.C++ 全局变量和 static 变量初始化问题
- 全局变量、文件域中的静态变量、类中的成员静态变量在 main 函数执行前初始化；局部变量中的静态变量在第一次调用时初始化。


**在 C 语言中是编译期初始化并分配内存**，故不能用变量给静态局部变量赋值，只能用常量。

**在C++中是第一次执行时初始化**，因为 C++ 引入了对象的概念，对象一般需要构造函数，无法简单的分配内存，故可以用变量赋值，并且在**第一次使用时初始化**。


- 初始化顺序：对于编译单元（同一个文件）的全局变量来讲，初始化顺序跟声明的顺序一致。销毁顺序则相反。
对于不同编译单元的全局变量，初始化顺序不确定。对于不同编译单元的全局变量互相引用的情况应避免。

解决不同文件相互引用全局变量初始化顺序不确定问题：可以通过函数调用，引用的时候不直接引用全局变量，而是放在一个函数中。**函数中的全局变量在调用时初始化**。


**类的静态成员变量声明和定义**   
静态成员变量不属于任何一个对象，对象的数据中不应该包含静态成员的数据。所以在**定义类的时候不会给静态变量分配内存只是声明**，因此就要在其他地方分配即定义。

> 定义与声明的区别  
**声明**：只是向程序表面变明的类型和名字。    
**定义**：为变量分配内存，也可以顺便初始化。程序中变量有且只有一个定义（更能说明为什么要在类外再定义下类的静态成员变量了）





## 38.new 和 malloc 的区别
1、 new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持；
2、使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算；而malloc则需要显式地指出所需内存的尺寸。  
3、 new 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 new 是符合类型安全性的操作符。而malloc内存分配成功则是返回`void*`需要**通过强制类型转换将`void*`指针转换成我们需要的类型**。  
4、new 内存分配失败时，会抛出 `bac_alloc` 异常。malloc分配内存失败时返回NULL。  
5、 new 会先调用`operator new`函数，申请足够的内存(通常底层使用malloc实现)。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete 先调用析构函数，然后调用operator delete函数释放内存(通常底层使用free实现)。malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做**自定义类型对象构造和析构工作**。


## 39.delete p、delete [] p、allocator都有什么作用?
- delete p是用于释放由 new 运算符分配的单个对象的内存。
- 如果使用 new[] 运算符创建了一个对象数组，那么应该使用delete [] p 来释放内存，而不是 delete p。【delete[] p是用于释放由`new[]`运算符分配的对象数组的内存。在释放内存时，delete[] p会**调用每个对象的析构函数**，然后释放整个数组的内存（delete[时，数组中的元素按**逆序**的顺序进行销毁）】。

- new在内存分配上面有一些局限性，new 的机制是将内存分配和对象构造组合在一起同样的，delete 也是将对象析构和内存释放组合在一起的。allocator 将这两部分分开进行， **allocator 申请一部分内存，不进行初始化对象**，只有当需要的时候才进行初始化操作。

[https://www.cnblogs.com/codemagiciant/p/17524217.html](https://www.cnblogs.com/codemagiciant/p/17524217.html)


allocator的主要作用如下：

1.**内存分配**：allocator负责为容器中的元素分配内存。它使用动态内存分配机制（如new和malloc）从堆上分配内存，并返回指向分配内存的指针。

2.**内存释放**：当元素被从容器中移除或容器被销毁时，allocator负责释放先前分配的内存。它使用delete和free等函数释放先前分配的内存。

3.**对象构造和析构**：allocator还负责在分配的内存空间中构造和析构对象。当新元素被添加到容器中时，allocator使用元素的构造函数来创建对象，并在元素被移除时调用析构函数来销毁对象。

4.**内存对齐**：allocator还负责按照特定的内存对齐方式来分配内存，以确保对象的起始地址满足对齐要求。这对于某些类型的对象（如带有对齐要求的结构体）非常重要。


## 40.new和delete的实现原理，delete是如何知道释放内存的大小的？
new 和 delete是用户进行动态内存申请和释放的操作符，operator new 和operator delete是系统提供的全局函数，new在底层调用operator new全局函数来申请空间，delete在底层通过operator delete全局函数来释放空间。

C++ 的做法是在分配数组空间时多分**配了4个字节的大小，专门保存数组的大小**，在 delete 时就可以取出这个保存的数，就知道了需要调用析构函数多少次了。



[http://t.csdnimg.cn/NX0dG](http://t.csdnimg.cn/NX0dG)


## 41.malloc、realloc、calloc的区别
malloc 申请的空间的值是随机初始化的；  
calloc 申请的空间的值是初始值为0；  
realloc 给动态分配的空间分配额外的空间，用于扩充容量。


## 42.malloc与free的实现原理?
`malloc` 小于`128k`的内存，使用 `brk` 分配内存，将「堆顶」指针往高地址推；`malloc` 大于 `128k` 的内存，使用 `mmap` 分配内存，在堆和之间找一块空闲内存分配；

**brk分配的内存需要等到高地址内存释放以后才能释放，而mmap分配的内存可以单独释放。** 

**malloc分配内存之后，只是分配了虚拟内存，还没有映射到物理内存，只有当访问申请的内存的时候，才会发生缺页中断，分配对应的物理内存**

当最高地址空间的空闲内存超过128K(可由M TRIM THRESHOLD选项调节)时，执行内存紧缩操作(trim)。【调用`sbrk(-size)`将内存归还操作系统】


[https://jacktang816.github.io/post/mallocandfree/](https://jacktang816.github.io/post/mallocandfree/)


## 43.类成员初始化方式？构造函数的执行顺序？为什么用成员初始化列表会快一些？
**赋值初始化**，通过在函数体内进行赋值初始化；  
**列表初始化**，在冒号后使用初始化列表进行初始化。

主要区别在于：  
<font color = blue>对于在函数体中初始化，是在所有的数据成员被分配内存空间后才进行的；  </font>
列表初始化是给数据成员分配内存空间时就进行初始化，就是说分配一个数据成员只要冒号后有此数据成员的赋值表达式(此表达式必须是括号赋值表达式)，那么分配了内存空间后在进入函数体之前给数据成员赋值，就是说**初始化这个数据成员此时函数体还未执行**。


一个派生类构造函数的执行顺序如下：  
① 虚拟基类的构造函数（多个虚拟基类则按照继承的顺序执行构造函数）；  
② 基类的构造函数（多个普通基类也按照继承的顺序执行构造函数）；  
③ 类类型的成员对象的构造函数（按照成员对象在类中的定义顺序）；  
④ 派生类自己的构造函数。


方法一是在构造函数当中做赋值的操作，而方法二是做纯粹的初始化操作。我们都知道，**C++的赋值操作是会产生临时对象的**。临时对象的出现会降低程序的效率。


## 44.有哪些情况必须用到成员列表初始化？作用是什么？
1.**必须使用成员初始化**的四种情况：  
① 当初始化一个引用成员时；  
② 当初始化一个常量成员时；  
③ 当调用一个基类的构造函数，而它拥有一组参数时；  
④ 当调用一个成员类的构造函数，而它拥有一组参数时；  

**成员初始化列表做了什么**：  
① 编译器会一一操作初始化列表，以适当的顺序在构造函数之内安插初始化操作，并且在任何显示用户代码之前；  
② list 中的项目顺序是**由类中的成员声明顺序决定**的，不是由初始化列表的顺序决定的。

## 45.C++中新增了string，它与C语言中的 char * 有什么区别吗？它是如何实现的？
string 继承自 `basic_string`，其实是对 `char* `进行了封装，封装的 string 包含了 `char*` 数组，容量长度等等属性。

`string` 可以进行动态扩展，在每次扩展的时候另外申请一块原空间大小两倍的空间 (`2*n`) 然后将原字符串拷贝过去，并加上新增的内容。


## 46.什么是内存泄露，如何检测与避免？
**内存泄露**  
一般我们常说的内存泄漏是指**堆内存的泄漏**。  
堆内存是指程序从堆中分配的，大小任意的（内存块的大小可以在程序运行期决定）内存块，使用完后必须显式释放的内存。应用程序般使用 malloc、realloc、new 等函数从堆中分配到块内存，
**使用完后，程序必须负责相应的调用 free 或 delete 释放该内存块，否则，这块内存就不能被再次使用，我们就说这块内存泄漏**。

避免内存泄露的几种方式  
计数法：使用 new 或者 malloc 时，让该数+1，delete 或 free 时，该数 -1，程序执行完打印这个计数，如果不为 0 则表示存在内存泄露；  
一定要将基类的析构函数声明为虚函数【否则不会调用派生类的析构函数，要能够保证继承关系中最高的基类的析构函数是虚的（具有传递性）】；  
对象数组的释放一定要用delete []；  
有 new 就有delete，有 malloc 就有 free，保证它们一定成对出现；

检测工具  
Linux下可以使用Valgrind工具；  
Windows下可以使用CRT库。

## 47.对象复用的了解，零拷贝的了解
**对象复用是指将已经创建的对象进行重复使用，而不是创建新的对象。**  

在面向对象编程中，对象复用可以通过以下几种方式实现：  
1.**对象池** ：对象池是一种常见的对象复用方式，它可以将已经创建的对象保存起来，并在需要时将其重新使用。  
2.**模板类和模板对象** ：模板类和模板对象可以将一些公共的行为封装在类和对象中，从而实现对象的复用。  
3.**类的成员变量** ：类的成员变量可以是类的实例对象，这样可以将对象的状态和行为保存在类的成员变量中，从而实现对象的复用。  
4.**对象的静态变量** ：对象的静态变量可以是类的实例对象，这样可以将对象的状态和行为保存在类的静态变量中，从而实现对象的复用。

**零拷贝是指在程序运行过程中，对对象的复制和初始化过程中，只复制对象的引用而不复制对象本身**。  
这样可以避免对象的内存分配和释放过程，从而提高程序的性能。零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。零拷贝技术可以减少数据拷贝和共享总线操作的次数。  
实现零拷贝的方法有多种，其中最常见的是使用**C++中的智能指针和垃圾回收器**。


## 48.介绍面向对象的三大特性，并且举例说明
**1.封装**  
C++中的封装是指将属性和方法包装在一个类中，并通过访问控制符来限制外部对类的访问。封装可以提高代码的可维护性和安全性，同时也可以实现多态性。


**2.继承**  
C++最重要的特征是代码重用，通过继承机制可以利用已有的数据类型来定义新的数据类型，新的类不仅拥有旧类的成员，还拥有新定义的成员。


**3.多态**
同一事物表现出不同事物的能力，即向不同对象发送同一消息，不同的对象在接收时会产生不同的行为（重载实现编译时多态，虚函数实现运行时多态）【允许将子类类型的指针赋值给父类类型的指针（向上转换）】。

实现多态有二种方式：覆盖（override），重载（overload）。

## 48.C++的四种强制转换 reinterpret_cast/const_cast/static_cast/dynamic_cast

**为什么C++需要四种类型转换？**  
**1.隐式转换缺点**：  

- 可能会导致数据精度丢失：当将一个数据类型转换为另一个数据类型时，可能会发生精度丢失，例如将一个浮点数转换为整数时，小数部分会被截断。
- 可能导致未定义行为：隐式转换可能会导致未定义行为，例如将一个指针类型转换为整数类型可能会导致未定义行为。
- 代码不够清晰：隐式转换可能会使代码不够清晰，因为它不需要在代码中明确地指定转换的类型。

【C++中提供了 `explicit` 关键字，在构造函数声明的时候加上 `explicit` 关键字，能够**禁止隐式转换**】


**2.显式转换缺点：**

- 可能会导致数据失真：当使用显式转换将一个数据类型转换为另一个数据类型时，可能会导致数据失真，例如将一个整数转换为浮点数时，小数部分可能会出现不准确的情况。
- 可能会导致代码不够清晰：显式转换需要程序员在代码中明确地指定转换的类型，这可能会使代码不够清晰，同时也增加了代码的复杂性。


C++中的类型转换包括**自动类型转换**、**强制类型转换**、**类型解析转换**和**类型推断转换**。

- **static_cast**（编译时类型检查）：`static_cast < type-id > ( expression )`，将 `expression` 转换为 `type-id` 类型。  
<font color = red>static_cast 是静态类型转换，发生在编译期。这种转换不会进行运行时的动态检查（RTTI），因而这种转换可能是不安全的。 </font>
- **const_cast**：`const_cast` 只能改变运算对象的**底层 const**，用来移除变量的 `const` 或 `volatile` 限定符。  
注意：`const_cast` 是不能用来执行任何类型的转换的，比如只能将 `const char* p` 转换成` char* p`，而不能转成 `int* p`。
- **reinterpret_cast**：`reinterpret_cast` 可以将指针类型任意转换，甚至是不相关的类之间（既不检查指针所指向的内容，也不检查指针类型本身）【旧式强制类型转换执行与reinterpret_cast类似的功能】；
- **dynamic_cast**：`dynamic_cast` 只能用于指向类的指针和引用(或void*)。它的目的是确保类型转换的结果指向目标指针类型的有效完整对象。  
`dynamic_cast` 主要用于类层次结构中父类和子类之间指针和引用的转换，由于具有运行时类型检查，因此可以保证下行转换的安全性（）

> 何为安全性？  
> 即转换成功就返回转换后的正确类型指针，如果转换失败，则返回NULL，之所以说static_cast在下行转换时不安全，是因为即使转换失败，它也不返回NULL。


C++中层次类型转换中无非两种：上行转换和下行转换

- 对于上行转换，`static_cast` 和 `dynamic_cast` 效果一样，都安全；
- 对于下行转换：你必须确定要转换的数据确实是目标类型的数据，即需要注意要转换的父类类型指针是否真的指向子类对象，如果是，`static_cast` 和 `dynamic_cast` 都能成功；如果不是 `static_cast` 能返回，但是不安全，可能会出现访问越界错误，而 `dynamic_cast` 在运行时类型检查过程中，判定该过程不能转换，返回NULL。



[https://www.cnblogs.com/codemagiciant/p/17544722.html](https://www.cnblogs.com/codemagiciant/p/17544722.html)

## 49.C++函数调用的压栈过程
1. 当函数从入口函数 `main` 函数开始执行时，编译器会将我们操作系统的运行状态，`main` 函数的返回地址、`main` 的参数、`mian` 函数中的变量、进行依次压栈；
2. 当 `main` 函数开始调用 `func()` 函数时，编译器此时会将 `main` 函数的运行状态进行压栈，再将 `func()` 函数的返回地址、`func()` 函数的参数从右到左、`func()`  定义变量依次压栈；
3. 当 `func()` 调用 `f()` 的时候，编译器此时会将 `func()` 函数的运行状态进行压栈，再将的返回地址 `f()` 函数的参数从右到左、`f()`定义变量依次压栈。

**函数的调用过程**  
1)从栈空间分配存储空间；  
2)从实参的存储空间复制值到形参栈空间；  
3)进行运算


## 50. 写 C++ 代码时有一类错误是 coredump，很常见，你遇到过吗？怎么调试这个错误？
coredump 是程序由于异常或者 bug 在运行时异常退出或者终止，在一定的条件下生成的一个叫做 core 的文件，这个 **core 文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等**。对这个文件进行分析**可以定位到程序异常的时候对应的堆栈调用信息**。

【使用gdb命令对core文件进行调试】：`gdb [可执行文件名] [core文件名]`


## 51.说说移动构造函数
移动构造是C++11标准中提供的一种新的构造方法。  

移动构造函数首先将传递参数的内存地址空间接管，然后将内部所有指针设置为 `nullptr`，并且在原地址上进行新对象的构造，最后调用原对象的的析构函数，这样做既不会产生额外的拷贝开销，也不会给新对象分配内存空间。即提高程序的执行效率，节省内存消耗。

移动构造函数的参数和拷贝构造函数不同，拷贝构造函数的参数是一个左值引用，但是**移动构造函数的初值是一个右值引用**。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只用用一个右值，或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个 **move 语句，就是将一个左值变成一个将亡值**。

> 何为左值？能用取址符号 & 取出地址的皆为左值，剩下的都是右值。
> std::move() 能把左值强制转换为右值。
> 【匿名变量一律属于右值】

[C++中的左值、纯右值、将亡值](https://www.cnblogs.com/zpcdbky/p/5275959.html)

[http://t.csdnimg.cn/zleoS](http://t.csdnimg.cn/zleoS)

## 52.C++中将临时变量作为返回值时的处理过程
首先需要明白一件事情，临时变量，在函数调用过程中是被压到程序进程的栈中的，**当函数退出时，临时变量出栈，即临时变量已经被销毁**，临时变量占用的**内存空间没有被清空，但是可以被分配给其他变量**，所以有可能在函数退出时，该内存已经被修改了，对于临时变量来说已经是没有意义的值了。  
函数调用结束后，**返回值被临时存储到寄存器中**，并没有放到堆或栈中，也就是说与内存没有关系了。当退出函数的时候，临时变量可能被销毁，但是返回值却被放到寄存器中与临时变量的生命周期没有关系。
如果我们需要返回值，一般使用赋值语句就可以了。

## 53.静态类型和动态类型，静态绑定和动态绑定的介绍
- **静态类型**：对象在声明时采用的类型，在编译期既已确定；
- **动态类型**：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的；
- **静态绑定**：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期；
- **动态绑定**：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期；

从上面的定义也可以看出，**非虚函数一般都是静态绑定，而虚函数都是动态绑定**（如此才可实现多态性）。

<font color="#F100">绝对不要重新定义一个继承而来的 `virtual` 函数的缺省参数值，因为缺省参数值都是静态绑定（为了执行效率），而 `virtual` 函数却是动态绑定。</font>

[https://www.cnblogs.com/lizhenghn/p/3657717.html](https://www.cnblogs.com/lizhenghn/p/3657717.html)


## 54.指针加减计算要注意什么?
	int *a, *b, c;
	a = (int*)0x500;
	b = (int*)0x520;
	c = b - a;
	printf("%d\n", c); // 8
	a += 0x020;
	c = b - a;
	printf("%d\n", c); // -24

首先变量 `a` 和 `b` 都是以 `16` 进制的形式初始化，将它们转成 `10` 进制分别是`1280(5*16^2=1280)`和`1312(5*16^2+2*16=1312)`，那么它们的差值为`32`，也就是说a和b所指向的地址之间间隔`32`个位，但是考虑到是 `int` 类型占 `4` 位，所以 `c` 的值为`32/4=8`

`a `自增`16`进制 `0x20` 之后，其实际地址变为`1280+2*16*4=1408`，(`因为一个int占4位，所以要乘4`)，这样它们的差值就变成了`1312-1280=-96`，所以`c`的值就变成了`-96/4=-24`。

<font color=blue> 需要明确的是指针每移动一位，它实际跨越的内存间隔是指针类型的长度，建议都转成 10 进制计算，计算结果除以类型长度取得结果 </font>

## 55.怎样判断两个浮点数是否相等？
浮点数在内存中的存储有舍入误差，在计算机中用近似表示某个实数；
所以不能用`==`来判断两个浮点数是否相等，而是

	const double eps = 1e-8;
	
	if(abs(a-b) <= eps)  相等
	else 不相等

**对于两个浮点数比较只能通过相减并与预先设定的精度比较**，记得要取绝对值。浮点数与 0 的比较也应该注意。与浮点数的表示方式有关。


**结构体变量比较是否相等**  
1.重载了“==”操作符；  

	struct foo {
	
	  int a;
	  int b;
	
	  bool operator==(const foo& rhs) *//* *操作运算符重载*
	
	  {
	    return( a == rhs.a) && (b == rhs.b);
	  }
	};
2.元素的话，一个个比；  
3.指针直接比较，如果保存的是同一个实例地址，则(p1==p2)为真;





## 56.C++中的指针参数传递和引用参数传递有什么区别?底层原理你知道吗?
**1) 指针参数传递本质上是值传递，它所传递的是一个地址值。**

值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的一个副本（替身）。  
值传递的特点是，被调函数对形式参数的任何操作都是作为**局部变量**进行的，不会影响主调函数的实参变量的值（形参指针变了，实参指针不会变）。

 
**2) 引用参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。**

被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量（根据别名找到主调函数中的本体）。  
因此，被调函数对形参的任何操作都会影响主调函数中的实参变量。

**3) 引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。**

而对于指针传递的参数，如果改变被调函数中的指针地址，它将应用不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就得使用指向指针的指针或者指针引用。

 

**4) 从编译的角度来讲，程序在编译时分别将指针和引用添加到符号表上，符号表中记录的是变量名及变量所对应地址。**

指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值（与实参名字不同，地址相同）。  
符号表生成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。


[https://www.cnblogs.com/crbhf/p/15004480.html](https://www.cnblogs.com/crbhf/p/15004480.html)

## 57.类如何实现只能静态分配和只能动态分配？
1.前者是把 `new`、`delete` 运算符重载为 `private` 属性。后者是把构造、析构函数设为 `protected` 属性，再用子类来动态创建；

2.建立类的对象有两种方式：

① 静态建立，例如 A a;

静态建立一个类对象，就是由编译器为对象在栈空间中分配内存。使用这种方法，是直接调用类的构造函数。

② 动态建立，例如 A *p = new A();

动态建立一个类对象，就是使用 `new` 运算符为对象在堆空间中分配内存。这个过程分为两步，第一步执行`operator new()`函数，在堆中搜索一块内存并进行分配；第二步调用类构造函数构造对象；

<font color=red>**只有使用new运算符，对象才会被建立在堆上**</font>，因此只要限制 `new` 运算符就可以实现类对象只能建立在栈上，可以将 `new` 运算符设为私有。

## 58.继承机制中对象之间如何转换？指针和引用之间如何转换?
**1. 向上类型转换**  
将派生类指针或引用转换为基类的指针或引用被称为向上类型转换，向上类型转换会自动进行，而且向上类型转换是安全的。

**2. 向下类型转换**  
将基类指针或引用转换为派生类指针或引用被称为向下类型转换，向下类型转换不会自动进行，因为一个基类对应几个派生类，所以向下类型转换时不知道对应哪个派生类，所以在向下类型转换时必须加动态类型识别技术。RTTI（运行时类型识别（Run-Time Type Identification，RTTI））技术，用 `dynamic_cast` 进行向下类型转换。

**指针和引用之间怎么转换：**  

- 指针转引用：把指针用`*`就可以转换成对象，可以用在引用参数当中。
- 引用转指针：把引用类型的对象用`&`取地址就获得指针了。

[https://www.cnblogs.com/swk0918/p/14444983.html](https://www.cnblogs.com/swk0918/p/14444983.html)

## 59.知道C++中的组合吗？它与继承相比有什么优缺点吗？
**继承：**  
优点：是子类可以重写父类的方法来方便地实现对父类的扩展。  
缺点：

- 父类的内部细节对子类是可见的；
- 子类从父类继承的方法在编译时就确定下来了，无法在运行期间改变从父类继承的方法的行为；
- 如果对父类的方法做了修改的话（比如增加了一个参数），则子类的方法必须做出相应的修改。
- 子类与父类是一种高耦合，违背了面向对象思想。

**组合**   
设计类的时候把要组合的类的对象加入到该类中作为自己的成员变量。  
优点：

- 当前对象只能通过所包含的那个对象去调用其方法，所以所包含的对象的内部细节对当前对象时不可见的。
- 当前对象与包含的对象是一个低耦合关系，如果修改包含对象的类中代码不需要修改当前对象类的代码。
- 当前对象可以在运行时动态的绑定所包含的对象。可以通过set方法给所包含对象赋值


缺点：

- 容易产生过多的对象；
- 为了能组合多个对象，必须仔细对接口进行定义。

[http://t.csdnimg.cn/sU2LO](http://t.csdnimg.cn/sU2LO)

## 60.函数指针？
函数指针**指向的是函数而非对象**。和其他指针一样，函数指针指向某种特定类型。函数的类型由它的返回类型和形参类型共同决定，与函数名无关。

要想声明一个可以指向该函数的指针，只需要**用指针替换函数名即可**。

**为什么有函数指针**：函数与数据项相似，函数也有地址。我们希望在同一个函数中通过使用相同的形参在不同的时间使用产生不同的效果。

**一个函数名就是一个指针，它指向函数的代码**。  
一个函数地址是该函数的进入点，也就是调用函数的地址。函数的调用可以通过函数名，也可以通过指向函数的指针来调用。函数指针还允许将函数作为变元传递给其他函数；

两种赋值方法：`指针名 =函数名`；`指针名=&函数名`

> `decltype` 与 `auto` 关键字一样，用于**进行编译时类型推导**，不过它与 auto 还是有一些区别的。decltype 的类型推导并不是像 auto 一样是从变量声明的初始化表达式获得变量的类型，而是总是**以一个普通表达式作为参数**，返回该表达式的类型，而且 **decltype 并不会对表达式进行求值**。  
> [https://www.cnblogs.com/QG-whz/p/4952980.html](https://www.cnblogs.com/QG-whz/p/4952980.html)


## 61.说一说你理解的内存对齐以及原因？
内存对齐是指在结构体中，**成员变量按照特定规则排列**以满足硬件平台要求和提高性能的过程。

1.平台原因：  
不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。

2.性能原因 ：  
数据结构( 尤其是栈 ) 应该尽可能地在自然边界上对齐。 原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。这里归根结底的来说就**是以空间换时间** 。


[https://blog.csdn.net/weixin_45897952/article/details/123727425](https://blog.csdn.net/weixin_45897952/article/details/123727425)


**对齐规则**  
1.每个特定平台上的编译器都有自己的默认“对齐系数”#pragma pack(show)可以查看；  
2.有效对齐值：是给定值#pragma pack(n)和结构体中最长数据类型长度中较小的那个。有效对齐值也叫对齐单位。  
3.结构体第一个成员变量的偏移量(offset)为0，以后每个数据成员的起始位置要从自身大小的整数倍开始存储；  
4.结构体的总大小为：若没有设定对齐字节数，则最大成员为对齐字节数。若有设定对齐字节数，则对齐字节数为：min(最大成员，设定的对齐字节数)的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。

<font color=blue>对齐规则是按照成员的声明顺序，依次安排内存，其偏移量为成员大小的整数倍，0看做任何成员的整数倍，最后结构体的大小为最大成员的整数倍</font>

## 62.函数调用过程栈的变化，返回值和参数变量哪个先入栈？
1. 将函数的参数压入栈中。参数的压入顺序与调用约定有关，在大多数C/C++编译器中，在函数调用的过程中，函数的参数是 ***由右向左*** 入栈的；
2. 将**当前函数的返回地址**压入栈中。返回地址是指函数调用结束后回到调用点的地址。
3. 将当**前函数的栈帧**（Stack Frame）压入栈中。栈帧包括本地变量、临时变量、函数的返回值等信息。栈帧的大小取决于函数中定义的变量和数据类型。
4. 跳转到**函数的入口点**开始执行函数代码。
5. 函数执行完毕后，将**返回值存放在寄存器中**（或者放在栈内存中），然后将栈帧弹出，恢复返回地址，跳转回调用点。

在返回之前，可以进行一些清理工作，例如释放内存、关闭文件等。函数调用过程中，栈的变化是动态的，每次函数调用都会增加栈的深度，而函数返回时栈的深度又会减少。如果递归调用函数，栈的深度会不断增加，直到达到一定限制，例如栈溢出。

## 63.你知道 printf 函数的实现原理是什么吗？
printf 是格式化输出可以自己定义输出的格式；`printf(“%d\n”,a),`其中" "之间的是格式说明串。% 后的一个或两个字符是格式说明符，用它来控制输出变量值的形式,
printf可以输入以上两种格式:

- 字符说明符 `%c` 同于 `putchar`；
- 字符串说明符 `%s` 同于 `puts`；


压栈时从右往左压栈，因此，printf  的第一个被找到的参数就是那个**字符指针**，就是被双引号括起来的那一部分，函数通过判断字符串里控制参数的个数来判断参数个数及数据类型，通过这些就可算出数据需要的堆栈指针的偏移量了。

## 64.为什么模板类一般都是放在一个 h 文件中？
1. 模板定义很特殊。由`template<…>`处理的任何东西都意味着编译器**在当时不为它分配存储空间**，它一直处于**等待状态直到被一个模板实例告知**。在编译器和连接器的某一处，有一机制能去掉指定模板的多重定义。所以为了容易使用，几乎总是在头文件中放置全部的模板声明和定义。
2. 在分离式编译的环境下，编译器编译某一个`.cpp`文件时并不知道另一个`.cpp`文件的存在，也不会去查找（当遇到未决符号时它会寄希望于连接器）。这种模式在没有模板的情况下运行良好，但遇到模板时就傻眼了，因为**模板仅在需要的时候才会实例化出来**。    
所以，当编译器只看到模板的声明时，它不能实例化该模板，只能创建一个具有外部连接的符号并期待连接器能够将符号的地址决议出来。  
然而**当实现该模板的`.cpp`文件中没有用到模板的实例**时，编译器懒得去实例化，所以，整个工程的.obj中就找不到一行模板实例的二进制代码，于是连接器也黔驴技穷了。

<font color=red>编译器会对函数模板进行两次编译，在声明函数模板地方编译一次，在调用的地方再编译一次。</font>

C++ 是独立编译的，a.cpp发现一个函数调用，在当前文件找不到函数定义，则在函数位置生成符号，在链接时，再寻找这个函数。

[https://www.cnblogs.com/JCpeng/p/15072692.html](https://www.cnblogs.com/JCpeng/p/15072692.html)

## 65.cout 和 printf 有什么区别？
C中的printf是一个标准的**输出函数**。  
C++中的cout是在iostrem文件中定义的**全局对象**。


**1.原理不同**  
    std::cout<<“输出内容"std::endl;  
其中`<<`操作符提取"输出内容”，然后进行重载，同时重载函数，根据"输出内容"的类型来重载不同类型的函数。

同时在定义每一个流对象时，系统会在内存中**开辟一段缓冲区（全缓冲）**，用来暂存数据（系统内有多个缓冲区）。此时当收到endl时，cout行会进行换行，同时刷新缓冲区。  
当缓冲区满或者收到结束符时，会将缓冲区数据一并清空并在显示设备输出。  
**flush 立即强迫缓冲输出**。

printf 是**行缓冲输出**，不是无缓冲输出。

> **全缓冲**： 全缓冲就是等待标准IO缓冲区填满或者flush操作，才进行IO操作输入输出  ；  
**行缓冲**：当遇到 \n 回车换行符时，进行IO操作输入输出；  
**无缓冲**：没有缓冲，直接进行IO操作；

**2.cout与printf格式不同**：  
**cout**：` std::cout<<"任意类型函数"std::endl;`  
**printf**：` printf(“其他+%转换+其他”，参数)`；


**3.输出效率不同(C++中 cin,cout 是不是效率不如scanf,printf)**：    
因为 printf 是在编译期确定操作数类型和调用的输出函数，**不用在运行期解析格式**控制字符串带来额外开销。不过标准流对象 cin/cout 为了普适性，继承体系很复杂，所以在对象的构造等方面会影响效率，因此总体效率比较低。。

## 66.你知道重载运算符吗？
重载的运算符是带有特殊名称的函数，函数名是由**关键字 operator** 和其后**要重载的运算符符号**构成的。

1. **只能重载已有的运算符**，而无权发明新的运算符；对于一个重载的运算符，其优先级和结合律与内置类型一致才可以；不能改变运算符操作数个数；
2. 两种重载方式：**成员运算符和非成员运算符**，成员运算符比非成员运算符少一个参数；下标运算符、箭头运算符必须是成员运算符；
3. 引入运算符重载，是为了实现类的**多态性**；
4. 当重载的运算符是成员函数时，**this 绑定到左侧运算符对象**。成员运算符函数的参数数量比运算符对象的数量少一个；至少含有一个类类型的参数；
5. 从参数的个数推断到底定义的是哪种运算符，当运算符既是一元运算符又是二元运算符（`+，-，*，&`）；
6. **下标运算符必须是成员函数**，下标运算符通常以所访问元素的引用作为返回值，同时最好定义下标运算符的常量版本和非常量版本；
7. **箭头运算符必须是类的成员**，解引用通常也是类的成员；重载的箭头运算符必须返回类的指针；


当程序中有函数重载时，函数的匹配原则和顺序：
1.名字查找（选定候选函数）；
2.确定候选函数（选定可行函数）；
3.寻找最佳匹配；

<font color=blue>**重载可以根据静态子类型分派不同表现，所以它是一种静态多态。**</font>


## 67.动态多态和静态多态的比较
**静态多态**  

优点：

- 由于**静多态是在编译期完成的**，因此效率较高，编译器也可以进行优化；
- 有很强的适配性和松耦合性，比如可以通过偏特化、全特化来处理特殊类型；
- 最重要一点是静态多态通过模板编程为C++带来了泛型设计的概念，比如强大的STL库。

缺点：

- 由于是模板来实现静态多态，因此模板的不足也就是静多态的劣势，比如调试困难、编译耗时、代码膨胀、编译器支持的兼容性
- 不能够处理异质对象集合；


**动态多态**

优点：

- OO设计，对是客观世界的直觉认识；
- 实现与接口分离，可复用；
- 处理同一继承体系下异质对象集合的强大威力；


缺点：

- 运行期绑定，导致一定程度的运行时开销；
- 编译器无法对虚函数进行优化
- 笨重的类继承体系，对接口的修改影响整个类层次；


**不同点：**

- 本质不同，静态多态在编译期决定，由模板具现完成，而动态多态在运行期决定，由继承、虚函数实现；
- 动态多态中接口是显式的，以函数签名为中心，多态**通过虚函数在运行期实现**；静态多台中接口是隐式的，以有效表达式为中心，多态通过模板具现在编译期完成


**相同点：**

- 都能够实现多态性，静态多态/编译期多态、动态多态/运行期多态；
- 都能够使接口和实现相分离，一个是模板定义接口，类型参数定义实现，一个是基类虚函数定义接口，继承类负责实现；



[https://www.cnblogs.com/lizhenghn/p/3667681.html](https://www.cnblogs.com/lizhenghn/p/3667681.html)

## 68.定义和声明的区别
**如果是指变量的声明和定义**：  
从编译原理上来说，声明是仅仅告诉编译器，有个某类型的变量会被使用，但是编译器并不会为它分配任何内存。而定义就是分配了内存。

**如果是指函数的声明和定义**：  
**声明**：一般在头文件里，对编译器说{这里我有一个函数叫function()}，让编译器知道这个函数的存在；  
**定义**：一般在源文件里，具体就是函数的实现过程写明函数体。


[https://linhongbo.com/posts/difference-between-definition-and-declaration/](https://linhongbo.com/posts/difference-between-definition-and-declaration/)

## 69.说一下你理解的 ifdef endif 代表着什么？
1.  一般情况下，源程序中所有的行都参加编译。但是有时希**望对其中一部分内容只在满足一定条件才进行编译**，也就是对一部分内容指定编译的条件，这就是“**条件编译**”。有时，希望当满足某条件时对一 组语句进行编译，而当条件不满足时则编译另一组语句。

2) 条件编译命令最常见的形式为：

	\#ifdef 标识符
		程序段1
	\#else
		程序段2
	\#endif

它的作用是：**当标识符已经被定义过(一般是用#define命令定义)，则对程序段1进行编译，否则编译程 序段2**。

3) 在一个大的软件工程里面，**可能会有多个文件同时包含一个头文件**，当这些文件编译链接成一个可执行文件上时，就会出现大量“重定义”错误。

在头文件中使用#define、#ifndef、#ifdef、#endif** 能避免头文件重定义**。

## 70.C++如何处理多个异常的？
- **C++ 中的异常情况**：   
**语法错误**（编译错误）：比如变量未定义、括号不匹配、关键字拼写错误等等编译器在编译时能发现的错误，这类错误可以及时被编译器发现，而且可以及时知道出错的位置及原因，方便改正；  
**运行时错误**：比如数组下标越界、系统内存不足等等。这类错误不易被程序员发现，它能通过编译且能进入运行，但运行时会出错，导致程序崩溃。为了有效处理程序运行时错误，C++中引入异常处理机制来解决此问题。
- **C++异常处理机制**：    
**异常处理基本思想**：执行一个函数的过程中发现异常，**可以不用在本函数内立即进行处理， 而是抛出该异常，让函数的调用者直接或间接处理这个问题**。    
C++异常处理机制由3个模块组成：try(检查)、throw(抛出)、catch(捕获) 抛出异常的语句格式为：throw 表达式；如果 try 块中程序段发现了异常则抛出异常。

## 71.如何在不使用额外空间的情况下交换两个数？你有几种方法？
1)  算术

	x = x + y;
	y = x - y;
	
	x = x - y; 

2)  异或

	x = x^y;// 只能对int,char..
	y = x^y;
	x = x^y;
	x ^= y ^= x;

## 72.你知道 strcpy 和 memcpy 的区别是什么吗？
1. **复制的内容不同**。strcpy 只能复制字符串，而 memcpy 可以复制任意内容，例如字符数组、整型、结构体、类等。
2. **复制的方法不同**。strcpy 不需要指定长度，它遇到被复制字符的串结束符"`\0`"才结束，所以容易溢出。memcpy 则是根据其第3个参数决定复制的长度。
3. **用途不同**。通常在复制字符串时用 strcpy，而需要复制其他类型数据时则一般用 memcpy。

[https://www.cnblogs.com/codemagiciant/p/17544881.html](https://www.cnblogs.com/codemagiciant/p/17544881.html)

> strlen函数返回的是在字符串中’\0’前面出现的字符的个数；  
> strcat追加拷贝，追加到目标空间后面，目标空间必须足够大，能容纳下源字符串的内容；  
> strcmp比较两个字符串的大小，一个字符一个字符比较，按ASCLL码比较；

## 73.程序在执行int main(int argc, char *argv[])时的内存结构，你了解吗？
参数的含义是程序在命令行下运行的时候，需要输入 argc 个参数，每个参数是以char 类型输入的，依次存在数组里面，数组是 argv[]，**所有的参数在指针`char *` 指向的内存中，数组的中元素的个数为 argc个，第一个参数为程序的名称**。

## 74.如果有一个空类，它会默认添加哪些函数？
	1)  Empty(); // 缺省构造函数//
	2)  Empty( const Empty& ); // 拷贝构造函数//
	3)  ~Empty(); // 析构函数//
	4)  Empty& operator=( const Empty& ); // 赋值运算符//

## 75.C++中标准库是什么？
1.C++ 标准库可以分为两部分： 
 
- **标准函数库**：这个库是由通用的、独立的、不属于任何类的函数组成的。函数库继承自C语言；  

- **面向对象类库**：这个库是类及其相关函数的集合；

	- 输入/输出 I/O、字符串和字符处理、数学、时间、日期和本地化、动态分配、其他、宽字符函数;  
	- 标准的 C++  I/O 类、String 类、数值类、STL 容器类、STL 算法、STL 函数对象、STL 迭代器、STL 分配器、本地化库、异常处理类、杂项支持库


## 76.你知道 const char* 与 string 之间的关系是什么吗？
- string 是 C++ 标准库里面其中一个，封装了对字符串的操作，实际操作过程我们可以用`const char*`给string类初始化；
- `c_str()` 函数可以将 `const string*` 类型 转化为 `const char*` 类型；

> c_str() 这个函数转换后返回的是一个临时指针，不能对其进行操作；
> 
所以因为这个数据是临时的，所以当有一个改变这些数据的成员函数被调用后，该数据就会改变失效；


## 77.如何设计一个计算仅单个子类的对象个数？
1. 为类设计一个 static 静态变量 count 作为计数器；
2. 类定义结束后初始化 count;
3. 在构造函数中对 count 进行+1;
4. 设计拷贝构造函数，在进行拷贝构造函数中进行 count +1，操作；
5. 设计赋值构造函数，在进行赋值函数中对 count+1 操作；
6. 在析构函数中对 count 进行-1；


## 78.成员初始化列表会在什么时候用到？它的调用过程是什么？
1.当初始化一个引用成员变量时；  
2.当初始化一个非静态的常量成员时；  
3.当调用一个基类的构造函数，而构造函数拥有一组参数时；  
4.当调用一个成员类的构造函数，而他拥有一组参数；  
5.成员类型是没有默认构造函数的类。

编译器会一一操作初始化列表，以适当顺序在构造函数之内安插初始化操作，并且在任何显示用户代码前。<font color = blue>初始化列表中的项目顺序是由类中的成员声明顺序决定的，不是初始化列表中的排列顺序决定的。</font>

## 79.在进行函数参数以及返回值传递时，可以使用引用或者值传递，其中使用引用的好处有哪些？
对比值传递，引用传参的好处：

1. 在函数内部可以对此参数进行修改；
2. 提高函数调用和运行的效率（因为没有了传值和生成副本的时间和空间消耗）

**用引用作为返回值最大的好处就是在内存中不产生被返回值的副本**。

但是有以下的限制：

1. 不能返回局部变量的引用。因为函数返回以后局部变量就会被销毁；
2. 不能返回函数内部 new 分配的内存的引用。虽然不存在局部变量的被动销毁问题，可对于这种情况（返回函数内部new分配内存的引用），又面临其它尴尬局面。例如，被函数返回的引用只是作为一 个临时变量出现，而没有被赋予一个实际的变量，那么这个引用所指向的空间（由new分配）就无法释放，造成内存泄露；
3. 可以返回类成员的引用，但是最好是 const。因为如果其他对象可以获得该属性的非常量的引用，那么对该属性的单纯赋值就会破坏业务规则的完整性。

## 80.说一说 strcpy、sprintf 与 memcpy 这三个函数的不同之处？
1.操作对象不同

① strcpy 的两个操作对象均为字符串；  
② sprintf 的操作源对象可以是多种数据类型，目的操作对象是字符串；  
③ memcpy 的两个对象就是两个任意可操作的内存地址，并不限于何种数据类型。

2.复制的方法不同

①strcpy 不需要指定长度，它遇到被复制字符的串结束符"`\0`"才结束，所以容易溢出。  
②sprintf 如果失败，则返回一个负数。对于写入buffer（它可以指代缓存、缓冲区等）的字符数是没有限制的，这就存在了 buffer 溢出的可能性。  
③ memcpy 则是根据其第3个参数决定复制的长度。

3.执行效率不同  

memcpy最高，strcpy次之，sprintf的效率最低； 

4.实现功能不同

① strcpy 主要实现字符串变量间的拷贝；  
② sprintf 主要实现其他数据类型格式到字符串的转化；  
③ memcpy主要是内存块间的拷贝。

## 81.你知道数组和指针的区别吗？
1.数组在内存中是连续存放的，开辟一块连续的内存空间；数组所占存储空间：sizeof（数组名）；**数组大小：sizeof(数组名)/sizeof(数组元素数据类型)**；

2.用运算符 sizeof 可以计算出数组的容量（字节数）。**sizeof(p), p 为指针得到的是一个指针变量的字节数，而不是 p 所指的内存容量**。

3.编译器为了简化对数组的支持，实际上是利用指针实现了对数组的支持。具体来说，就是将**表达式中的数组元素引用转换为指针加偏移量的引用**。

4.在向函数传递参数的时候，如果实参是一个数组，那用于接受的形参为对应的指针。也就是**传递过去是数组的首地址而不是整个数组**，能够提高效率；

5.在使用下标的时候，两者的用法相同，都是原地址加上下标值，不过**数组的原地址就是数组首元素的地址是固定的，指针的原地址就不是固定的**。

## 82.如何禁止程序自动生成拷贝构造函数？
1. 为了阻止编译器默认生成拷贝构造函数和拷贝赋值函数，我们需要手动去重写这两个函数，某些情况﻿下，为了避免调用拷贝构造函数和﻿拷贝赋值函数，我们需要将他们设置成 `private`，防止被调用。
2. 类的成员函数和 `friend` 函数还是可以调用 private 函数，如果这个 private 函数只声明不定义，则会产生一个连接错误；
3. 针对上述两种情况，我们可以定一个 base 类，**在 base 类中将拷贝构造函数和拷贝赋值函数设置成 private**，那么派生类中编译器将不会自动生成这两个函数，且由于 base 类中该函数是私有的，因此，派生类将阻止编译器执行相关的操作。【muduo 就是这样实现的】

## 83.你知道 Debug 和 Release 的区别是什么吗？
**Debug**：调试版本，包含调试信息，所以容量比 Release 大很多，并且不进行任何优化（优化会使调试复杂化，因为源代码和生成的指令间关系会更复杂），便于程序员调试。Debug 模式下生成两个文件，除了`.exe`或`.dll`文件外，还有一个`.pdb`文件，该文件记录了代码中断点等调试信息 

**Release**：发布版本，不对源代码进行调试，编译时对应用程序的速度进行优化，使得程序在代码大小和运行速度上都是最优的。（调试信息可在单独的PDB文件中生成）。Release 模式下生成一个文件`.exe`或`.dll`文件

实际上，Debug 和 Release 并**没有本质的界限**，**他们只是一组编译选项的集合，编译器只是按照预定的选项行动**。事实上，我们甚至可以修改这些选项，从而得到优化过的调试版本或是带跟踪语句的发布版本。

[https://www.cnblogs.com/taiyonghai/p/6126074.html](https://www.cnblogs.com/taiyonghai/p/6126074.html)

## 84. main 函数的返回值有什么值得考究之处吗? 
**main 函数的返回值用于说明程序的退出状态**。如果返回 0，则代表程序正常退出。返回其它数字的含义则由系统决定。通常，返回非零代表程序异常退出。

既然 main 函数只有一种返回值类型，那么是不是可以不写？规定：不明确标明返回值的，默认返回值为 int，也就是说 main()等同于int main()，而不是等同于void main()。

main 也是个函数，它运行了自然也是有结果的，这个结果通常是告诉操作系统，自身是正常运行结束了（值为0），还是发生了异常（这个值就有很多了）。告诉操作系统值是多少，目的是后台或者SHELL可以从操作系统中取得这个程序的运行结果，从而可以进行进一步操作。

其实 **main 函数本身是可以调用这个返回值**的，这个的作用就在于多线程的编程中，另外一个线程等待这个程序执行完毕，等待的就是这个MAIN函数的执行结果。


[http://t.csdnimg.cn/pwJvm](http://t.csdnimg.cn/pwJvm)

## 85.成员函数里 memset(this,0,sizeof(*this)) 会发生什么？
- 类里面定义了很多int,char,struct等c语言里的那些类型的变量，我习惯在构造函数中将它们初始化为0，但是一句句的写太麻烦，所以直接就memset(this, 0, sizeof *this);将整个对象的内存全部置为0。

以下场景不可以使用：

- 类含有虚函数表：这么做**会破坏虚函数表**，后续对虚函数的调用都将出现异常【this指向的是一个对象，该对象中有一个指向虚表的指针，那么此操作会将虚表指针的值置为0，则无法索引到虚函数表】；
- 如果成员的类对象变量中如果有用到new的方法，例如 std::string内部 指针全部置空 ，这时确实会导致找不到开辟的内存的位置，会导致内存泄露，访问异常。因为**指针清零，但是指针指向的内存空间还没有释放**。

## 86.你知道回调函数吗？它的作用？
函数指针的调用，即是一个通过函数指针调用的函数；  
如果**把函数的指针（地址）作为参数传递给另一个函数**，当这个指针被用来调用其所指向的函数时，就说这是回调函数。

<font color=red>回到函数作用：“解耦”【因为可以把调用者与被调用者分开。调用者不关心谁是被调用者，所有它需知道的，只是存在一个具有某种特定原型、某些限制条件(如返回值为int)的被调用函数】，普通函数代替不了回调函数的这个特点。</font>

**使用回调函数，和普通函数调用区别：**  
1）在主入口程序中，把回调函数像参数一样传入库函数。这样一来，只要**改变传进库函数的参数，就可以实现不同的功能**，且不需要修改库函数的实现，变的很灵活，这就是解耦。  
2）主函数和回调函数是在同一层的，而库函数在另外一层。如果库函数对我们不可见，我们修改不了库函数的实现，也就是说不能通过修改库函数让库函数调用普通函数那样实现，那我们就只能通过传入不同的回调函数了。

**回调函数其实就是函数指针的一种用法**【使用回调函数会有间接调用，因此，会有一些额外的传参与访存开销，对于MCU代码中对时间要求较高的代码要慎用】

**回调函数的缺点：**    
1）回调函数固然能解决一部分系统架构问题但是绝不能再系统内到处都是，如果你发现你的系统内到处都是回调函数，那么你一定要重构你的系统。  
2）回调函数本身是**一种破坏系统结构的设计思路**，回调函数会绝对的变化系统的运行轨迹，执行顺序，调用顺序。回调函数的出现会让读到你的代码的人非常的懵头转向。



[https://blog.csdn.net/llzhang_fly/article/details/104933969](https://blog.csdn.net/llzhang_fly/article/details/104933969)


## 87.什么是一致性哈希？
分布式存储（每个节点数据不同）使用哈希算法有一个很致命的问题，如果节点数量发生了变化了映射关系的数据，否则会出现查询不到数据的问题。也就是在对系统做扩容或者缩容时，必须迁移改变。

一致性哈希是一种哈希算法，就是在**移除或者增加一个结点时，能够尽可能小的改变**已存在 key 的映射关系。  
一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。（也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值）     
映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。

<img src="https://cdn.xiaolincoding.com//mysql/other/83d7f363643353c92d252e34f1d4f687.png" alt="哈希环" width="300" height="300">

但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，会有大量的请求集中在一个节点上。

<img src ="https://cdn.xiaolincoding.com//mysql/other/d528bae6fcec2357ba2eb8f324ad9fd5.png"  width="300" height="300">

一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。

[https://www.xiaolincoding.com/os/8_network_system/hash.html#%E6%80%BB%E7%BB%93](https://www.xiaolincoding.com/os/8_network_system/hash.html#%E6%80%BB%E7%BB%93)

不再将真实节点映射到哈希环上，而是**将虚拟节点映射到哈希环上**，并**将虚拟节点映射到实际节点**，所以这里有「两层」映射关系。

## 88.C++从代码到可执行程序经历了什么?
<img src = "http://oss.interviewguide.cn/img/202205212343505.png" >

1、**预编译**  
主要处理源代码文件中的以“#”开头的预编译指令；  
2、**编译**  
把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。  
3、**汇编**  
将汇编代码转变成机器可以执行的指令(机器码文件)。  经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows 下)、xxx.obj(Linux下)。  
4、**链接**  
将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。

链接分为静态链接和动态链接：

- 静态链接：
函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，**链接器从库中复制**这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件；【在内存存在多个副本；需要重新进行编译链接；执行的时候运行速度快】
	- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
	- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

- 动态链接：
动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，**在程序运行时才将它们链接在一起**形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件，在 Linux 系统中通常用 .so 后缀来表示，windows 为 DLL。【共享库；更新时只需要替换原来的目标文件；链接推迟到了程序运行】

[http://t.csdnimg.cn/ZouMD](http://t.csdnimg.cn/ZouMD)

## 89.友元函数在类内部声明还是内外？
友元函数不一定要在类内声明，普通的友元函数可以在类外声明，也可以在类内声明。  
只有友元工厂才必须用到类内声明友元函数。

**如果友元函数是在类的内部声明的**，那么它可以直接访问类的私有成员和保护成员，即使这些成员在类的外部是不可见的。然而，如果友元函数在类的内部声明，它的**可见性只限于该类及其派生类，无法在其他地方直接使用**。

**如果友元函数是在类的外部声明的**，那么它仍然可以访问类的私有成员和保护成员，但是**需要使用类名来限定友元函数的可见性**。因为友元函数的声明和定义可以单独放在一个头文件中，而不需要与类的定义混合在一起。


[https://www.cnblogs.com/codemagiciant/p/17601831.html](https://www.cnblogs.com/codemagiciant/p/17601831.html)

## 90.友元函数和友元类的基本情况
友元是一种定义在类外部的普通函数，但它需要在类体内进行声明，为了与该类的成员函数加以区别，在声明时前面加以关键字friend。

友元不是成员函数，但是它**可以访问类中的私有成员**。  
友元的作用在于提高程序的运行效率，但是，它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的私有成员。


- 友元函数可访问类的私有成员，但不是类的成员函数
- 友元函数不能用const修饰
- 友元函数可以在类定义的任何地方声明，不受类访问限定符限制
- 一个函数可以是多个类的友元函数
- 友元函数的调用与普通函数的调用和原理相同


友元除了友元函数以外，友元还可以是类——**友元类**，即一个类可以作另一个类的友元。当一个类作为另一个类的友元时，这就意味着这个类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的非公有成员。

- **友元关系是单向的，不具有交换性。**  
- **友元关系不能被继承，但对已有的方法来说访问权限不改变**。


## 91.介绍一下几种典型的锁
**读写锁**

- 多个读者可以同时进行读；
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）；
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）；

**互斥锁**：一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以**互斥锁在加锁操作时涉及上下文的切换**。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁；

**条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而**条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件**。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。

**自旋锁**

**如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止**。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

## 92.为什么C++没有垃圾回收机制?
- 首先，实现一个**垃圾回收器会带来额外的空间和时间开销**。你需要开辟一定的空间保存指针的引用计数和对他们进行标记 `mark`。然后需要单独开辟一个线程在空闲的时候进行 free 操作。

- 垃圾回收会使得C++不适合进行很多底层的操作。


## 93.类的对象存储空间?
类所占内存的大小主要是由**成员变量（静态变量除外）决定的**，成员函数（虚函数除外）是不计算在内的。

类内部的成员变量：

- 普通的变量：是要占用内存的，但是要注意<font color = red>**对齐原则**</font>（这点和struct类型很相似）。
- static修饰的静态变量：不占用内容，原因是编译器将其放在全局变量区。

类内部的成员函数：

- 普通函数：不占用内存。这是因为所有的函数都是存放在代码区的，不管是全局函数，还是成员函数。
- 虚函数：要占用4个以上字节(在32位系统分配指针大小为4字节)，用来指定虚函数的虚拟函数表的入口地址。所以一个类的虚函数所占用的地址是不变的，和虚函数的个数是没有关系的。类继承自多个基类的时候可能有多个虚函数表指针，可能会占据多个内存空间。

<font color = red>空的类是会占用内存空间的，而且大小是1，原因是C++要求每个实例在内存中都有独一无二的地址。</font>空类也会被实例化，所以编译器会给空类隐含的添加一个字节。

> 带有虚函数的 C++ 类大小不为1，因为**每一个对象会有一个 vptr 指向虚函数表，具体大小根据指针大小确定**。

`可见子类的大小 = 本身成员变量的大小 + （父类成员变量的的大小 + 虚函数表指针）* n` , n 表示继承的类的个数。



[https://blog.csdn.net/leigelaile1/article/details/81982103](https://blog.csdn.net/leigelaile1/article/details/81982103)


## 94.简要说明C++的内存分区

- **栈**： 存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放。
- **堆**： 动态申请的内存空间，就是由 malloc 分配的内存块，由程序员控制它的分配和释放，如果程序执行结束还没有释放，操作系统会自动回收。
- **全局区/静态存储区**（.bss 段和 .data 段）： 存放全局变量和静态变量，程序运行结束操作系统自动释放，在 C 语言中，未初始化的放在 .bss 段中，初始化的放在 .data 段中，C++ 中不再区分了。
- **常量存储区**（.data 段）： 存放的是常量，不允许修改，程序运行结束自动释放。
- **代码区**（.text 段）： 存放代码，不允许修改，但可以执行。编译后的二进制文件存放在这里。

## 95.什么是内存池，如何实现？
内存池（Memory Pool） 是一种内存分配方式。通常我们习惯直接使用 new、malloc 等申请内存，这样做的缺点在于：**由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能**。

内存池则是**在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用**。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

**内存池的工作原理**

1. 在初始化时，从操作系统申请一块连续的物理内存，称为内存池。
1. 将内存池按照固定大小分成多个内存块。
1. 将这些内存块用链表、栈或其他数据结构连接起来，形成一个内存块池。
1. 当需要分配内存时，从内存块池中获取一个内存块，并将其标记为已分配。
1. 当不需要使用内存块时，将其标记为未分配，放回到内存块池中。
1. 当内存块池中无可用内存块时，可以选择动态扩展内存池。

## 96.关于this指针你知道什么？全说出来？
1. 每个对象都有一个隐藏的 this 指针，但**不属于对象，是编译器添加的**；
2. `this` 只能在成员函数中使用【实际上，成员函数默认第一个参数为T *const this】。全局函数、静态函数都不能使用 `this`；
3. 由此可见，**this 在成员函数的开始前构造，在成员函数的结束后清除**。这个生命周期同任何一个函数的参数是一样的，没有任何区别。当调用一个类的成员函数时，编译器将类的指针作为函数的 `this` 参数传递进去。

## 97.this指针存放在何处？堆、栈、全局变量，还是其他？
this 指针会因编译器不同而有不同的放置位置。可能是栈，也可能是寄存器，甚至全局变量。

## 98.this指针是如何传递类中的函数的？绑定？还是在函数参数的首参数就是this指针？那么，this指针又是如何找到“类实例后函数的”？
大多数编译器通过ecx（寄数寄存器）寄存器传递this指针。事实上，这也是一个潜规则。一般来说，不同编译器都会遵从一致的传参规则，否则不同编译器产生的obj就无法匹配了。

在call之前，编译器会把对应的对象地址放到eax中。this是通过函数参数的首参来传递的。this指针在调用之前生成，至于“类实例后函数”，没有这个说法。类在实例化时，只分配类中的变量空间，并没有为函数分配空间。自从类的函数定义完成后，它就在那儿，不会跑的。

## 99.我们只有获得一个对象后，才能通过对象使用this指针。如果我们知道一个对象this指针的位置，可以直接使用吗？
**this 指针只有在成员函数中才有定义**。因此，你获得一个对象后，也不能通过对象使用 this 指针。所以，我们无法知道一个对象的this指针的位置（只有在成员函数里才有this指针的位置）。当然，在成员函数里，你是可以知道this指针的位置的（可以通过&this获得），也可以直接使用它。


[http://blog.chinaunix.net/uid-21411227-id-1826942.html](http://blog.chinaunix.net/uid-21411227-id-1826942.html)

## 100.每个类编译后，是否创建一个类中函数表保存函数指针，以便用来调用函数？

普通的类函数（不论是成员函数，还是静态函数）都不会创建一个函数表来保存函数指针。只有虚函数才会被放到函数表中。但是，即使是虚函数，**如果编译器能明确知道调用的是哪个函数，编译器就不会通过函数表中的指针来间接调用，而是会直接调用该函数**。

## 101.在成员函数中调用delete this会出现什么问题？对象还可以使用吗？
在类对象的内存空间中，**只有数据成员和虚函数表指针**，并不包含代码内容，类的成员函数单独放在代码段中。  
在调用成员函数时，隐含传递一个 this 指针，让成员函数知道当前是哪个对象在调用它。    
**当调用 delete this 时，类对象的内存空间被释放**。在 delete this 之后进行的其他任何函数调用，只要不涉及到 this 指针的内容，都能够正常运行。一旦涉及到this 指针，如操作数据成员，调用虚函数等，就会出现不可预期的问题。


## 102. C++11 有哪些新特性

[https://cloud.tencent.com/developer/article/1745592](https://cloud.tencent.com/developer/article/1745592)


## 103.auto、decltype和decltype(auto)的用法
编程时常常需要把表达式的值赋给变量，这就要求声明变量时清楚的知道表达式的类型。然而有些情况是**声明的变量的类型我们并不知道**，比如在模板编程时。  
为了解决这个问题，C++11引入了**auto类型说明符，用它来让编译器替我们去分析表达式所属的类型**。

decltype是C++11新增的关键字，主要用于提取变量和表达式的类型。  
decltype的语法形式为：`decltype(e)`，这里e是一个表达式，而`decltype(e)`是一个类型指示符。decltype的结果不是值，而是一个类型。**编译器只是分析表达式并得到它的类型，却不进行实际的计算表达式的值。  
**

`decltype(auto)`是C++14新增的类型指示符，可以**用来声明变量以及指示函数返回类型**。  
使用时，会将”=”号右边的表达式替换掉auto，再根据decltype的语法规则来确定类型

	int e = 4;
	const int* f = &e; // f是底层const
	decltype(auto) j = f;//j的类型是const int* 并且指向的是e

## 104. C++中NULL和nullptr区别
- NULL是一个宏定义，C++中通常将其定义为0，编译器一般优先把它当作一个整型常量(C标准下定义为(void*）0)；
- nullptr是一个编译期常量，其类型为nullptr_t。它**既不是整型类型，也不是指针类型**；
- 在模板推导中，nullptr被推导为nullptr_t类型，仍可隐式转为指针。但0或NULL则会被推导为整型类型；
- 要避免在整型和指针间进行函数重载。因为NULL会被匹配到整型形参版本的函数，而不是预期的指针版本。

[https://blog.csdn.net/qq_38410730/article/details/105183769](https://blog.csdn.net/qq_38410730/article/details/105183769)

## 105. 智能指针理解
[http://t.csdnimg.cn/et0ON](http://t.csdnimg.cn/et0ON)

动态内存管理经常会出现两种问题：
（1）一种是忘记释放内存，会造成内存泄漏；
（2）一种是尚有指针引用内存的情况下就释放了它，就会产生引用非法内存的指针。

为了更加容易（更加安全）的使用动态内存，**引入了智能指针**的概念。智能指针的行为类似常规指针，重要的区别是它负责自动释放所指向的对象。

`auto_ptr` 是c++11以前的最原始的智能指针，可以将 new 获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用 delete 来释放内存。但是在c++11中已经被弃用（使用的话会被警告）了。

原因：

1. 复制或者赋值都会改变资源的所有权；
2. 在STL容器中使用auto_ptr存在着重大风险，因为容器内的元素必须支持可复制和可赋值；
3. 不支持对象数组的内存管理；

`unique_ptr`：`unique_ptr` 和 `auto_ptr` 用法几乎一样，除了一些特殊

特性：

1. 基于排他所有权模式：**两个指针不能指向同一个资源**
1. 无法进行左值 `unique_ptr` 复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值；
1. 保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象；
1. 在容器中保存指针是安全的；


`shared_ptr`：:它所指向的资源具有共享性，即多个shared_ptr可以指向同一份资源，并在内部使用引用计数机制来实现这一点。可以记录引用特定内存对象的智能指针数量，当复制或拷贝时，引用计数加 1，当智能指针析构时，引用计数减 1，如果计数为零，代表已经没有指针指向这块内存，那么就释放它。

<font color = "#FA1000">`shared_ptr` 的构造函数和拷贝构造函数做的事情，导致虽然都是指向同一个资源，但是**对于引用计数对象的管理方式**，这两个函数是不一样的，构造函数是**新分配引用计数对象**，拷贝构造函数只做引用**计数增减**。</font>

> 当新的 `shared_ptr` 对象与指针关联时，则在其构造函数中，将与此指针关联的引用计数增加1。

> 当任何 `shared_ptr` 对象超出作用域时，则在其析构函数中，它将关联指针的引用计数减1。如果引用计数变为0，则表示没有其他 `shared_ptr` 对象与此内存关联，在这种情况下，它使用delete函数删除该内存。


最安全的分配和使用动态内存的方法就是调用一个名为 `make_shared` 的标准库函数，此函数在动态内存中分配一个对象并初始化它，返回指向此对象的 `shared_ptr`。


<font color = "#F100">可以说，当生命控制权没有彼此互相掌握时，才能正确解决循环引用问题，而弱引用的使用可以使生命控制权互相掌握的情况消失。</font>

我们在 `enable_shared_from_this<A>` 基类中继承一个成员变量 `_Wptr`，当定义第一个智能指针对象的时候： `shared_ptr< A > ptr1(new A())`，调用 `shared_ptr` 的普通构造函数，就会初始化 `A` 对象的成员变量 `_Wptr`，作为观察 `A` 对象资源的一个弱智能指针观察者。

`weak_ptr` :设计的目的是为配合 `shared_ptr` 而引入的一种智能指针来协助 `shared_ptr` 工作, 它只提供了对管理对象的一个访问手段，同时也可以实时动态地知道指向的对象是否存活。它只可以从一个 `shared_ptr` 或另一个 `weak_ptr` 对象构造, 它的**构造和析构不会引起引用记数的增加或减少**。 同时 `weak_ptr` 没有重载`*`和`->`，，所以并不能直接使用资源，但可以使用 lock 获得一个可用的 `shared_ptr` 对象。

`shared_from_this()` 函数，是直接返回了一个 `shared_ptr<_Ty>(_Wptr)`，该语法在 shared_ptr 中也有相应的构造函数，其主要作用就是**把一个弱智能指针提升为一个强智能指针**，可以在多线程环境中判断对象是否存活或者已经析构释放.

[C/C++｜智能指针的 shared\_ from \_ this 和enable\_ shared\_ from\_ this](http://t.csdnimg.cn/sNhIH)

## 106.智能指针出现循环引用怎么解决?
一般来讲，解除这种循环引用有下面有三种可行的方法(参考)：

1. 当只剩下最后一个引用的时候需要手动打破循环引用释放对象。
2. 当A的生存期超过B的生存期的时候，B改为使用一个普通指针指向A。
3. 使用弱引用的智能指针打破这种循环引用。
虽然这三种方法都可行，但方法1和方法2都需要程序员手动控制，麻烦且容易出错。我们一般使用第三种方法：弱引用的智能指针weak_ptr。

weak_ptr除了对所管理对象的基本访问功能（通过get()函数）外，还有两个常用的功能函数：   
`expired()` 用于检测所管理的对象是否已经释放；  
`lock()` 用于获取所管理的对象的强引用指针。不能直接通过 weak_ptr 来访问资源。那么**如何通过weak_ptr来间接访问资源呢？答案是：在需要访问资源的时候weak_ptr为你生成一个shared_ptr，shared_ptr能够保证在shared_ptr没有被释放之前，其所管理的资源是不会被释放的**。`创建shared_ptr的方法就是lock()方法。`

                        
[https://blog.csdn.net/daniel_ustc/article/details/23096229](https://blog.csdn.net/daniel_ustc/article/details/23096229)  
[http://t.csdnimg.cn/G5HAZ](http://t.csdnimg.cn/G5HAZ)

## 107.Lambda 表达式
类似匿名函数（需要函数体，不需要函数名），可以理解为简易版函数。  
**基本格式**： `[捕获方式] (参数) -> 返回值类型 {函数体}`（可以忽略返回类型，lambda自动推断出返回类型）。

`[ ]`：闭包形式(closure type)，即定义一个lambda表达式后，编译器会自动生成一个重载()运算符的匿名类。优势在于可以通过传值或引用的方式捕获其封装作用域内的变量（即捕获方式中存在的变量）

lambda 的性能优势：

1. 内联函数：
编译器自动将 lambda 表达式内联，这意味着代码直接插入到调用函数中。
可以减少函数调用的开销，并提高性能。

2. 避免命名函数的开销：
lambda 表达式没有名称，因此不必被声明和存储在符号表中，
可以减少开销，并提高性能。

3. 改善高速缓存局部性：
lambda 表达式可以在同一个函数中定义和使用，这意味着 lambda 使用的代码和数据
存储在与调用代码相同的高速缓存行中。
可以改善高速缓存局部性并降低高速缓存失效的成本。

4. 减小代码大小：
lambda 表达式通常比命名函数小，并不需要外部函数调用，
这可以减小编译代码的大小并提高性能。

5. 增加灵活性：
lambda 表达式可以用来将函数作为参数传递给其他函数，


## 108.什么是STL?
C++ STL从广义来讲包括了三类：算法，容器和迭代器。

- 算法包括排序，复制等常用算法，以及不同容器特定的算法。
- 容器就是数据的存放形式，包括序列式容器和关联式容器，序列式容器就是 list，vector 等，关联式容器就是set，map等
- 迭代器就是在不暴露容器内部结构的情况下对容器的遍历。

## 109.解释一下什么是trivial destructor
在C++中，当一个类的析构函数**不需要做任何额外的工作**时，我们称这个类的析构函数为 trivial destructor。也就是说，如果这个类不持有任何资源，比如堆内存、文件句柄等等，那么它的析构函数就是 trivial destructor。

当一个类的析构函数是 trivial destructor 时，**编译器会对其进行优化**，使得在该类对象被销毁时，不会调用析构函数。这种优化被称为trivial destructor优化，它可以提高程序的性能和效率。

需要注意的是，如果一个类的析构函数不是trivial destructor，那么在该类对象被销毁时，析构函数必须被调用。这是因为该类对象可能持有一些资源，需要在销毁时释放。如果析构函数没有被调用，这些资源可能会泄漏，导致程序出现严重的错误。


[https://www.nowcoder.com/discuss/541403936406691840](https://www.nowcoder.com/discuss/541403936406691840)

## 110.使用智能指针管理内存资源，RAII是怎么回事？
1)RAII全称是“Resource Acquisition is Initialization”，直译过来是“**资源获取即初始化**”，也就是说**在构造函数中申请分配资源，在析构函数中释放资源**。

因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定。

2)**智能指针（std::shared_ptr和std::unique_ptr）**即RAII最具代表的实现，使用智能指针，可以实现自动的内存管理，再也不需要担心忘记delete造成的内存泄漏。

## 111.说一下C++左值引用和右值引用
当一个对象被用作右值的时候，用的是对象的值（内容）；当对象被用作左值的时候，用的是对象的身份（在内存中的位置）。

所以当一个左值被当成右值使用时，实际使用的是它的内容（值）。**在需要右值的地方可以用左值来代替，但是不能把右值当成左值（也就是位置）使用**。比如取地址符` &`，就是对一个左值取地址，取出来的地址是个右值，因为右值只有内容，在内存中没有位置。而对一个地址解引用 `*p`，或者对一个数组取下标` arr[0]`，就获得了左值。


C++11 引入了 **右值引用 &&** 的概念，允许将右值绑定到一个引用上，并且可以修改其内容，这提供了更多的灵活性和效率。

	int i = 10;
	int& j = i;           // 正确：左值引用
	int& k = i * 1;       // 错误：左值引用不能绑定右值
	int&& m = i * 1;      // 正确：右值引用
	int&& n = i;          // 错误：右值引用不能绑定左值
	const int& p = i * 1; // 正确：const左值引用可以绑定右值

如果说变量是左值，那么问题来了，右值引用的变量也是变量，这个变量是左值么，比如这里的 m。

答案为左值，所以下面这个表达式是错误的：

	int&& q = m;          // 错误：右值引用不能绑定左值，即使这个左值是右值引用类型的变量
虽然直接把右值引用类型的变量绑定到变量上，但可以使用 move 来获取绑定到左值上的右值引用。

	int&& q = std::move(m);    // 正确：std::move可以将左值转换为右值


[https://segmentfault.com/a/1190000044307595](https://segmentfault.com/a/1190000044307595)


**左值引用**：传统的 C++ 中引用被称为左值引用；  
**右值引用**：C++11 中增加了右值引用，右值引用关联到右值时，右值被存储到特定位置，右值引用指向该特定位置，也就是说，**右值虽然无法获取地址，但是右值引用是可以获取地址的**，该地址表示临时对象的存储位置；


### 112.STL中 hashtable 的实现？
STL中的 hashtable 使用的是**开链法**解决hash冲突问题；

hashtable中 的 bucket 所维护的 list 既不是 list 也不是 slist，而是其自己定义的由hashtable_node 数据结构组成的 linked-list，而 bucket 聚合体本身使用 vector 进行存储。**hashtable 的迭代器只提供前进操作，不提供后退操作**。

在hashtable设计bucket的数量上，其**内置了28个质数**[53, 97, 193,...,429496729]，在创建hashtable时，会**根据存入的元素个数选择大于等于元素个数的质数作为 hashtable 的容量**（vector的长度），其中**每个 bucket 所维护的 linked-list 长度也等于hashtable的容量**。如果插入 hashtable 的元素个数超过了 bucket 的容量，就要进行重建 table 操作，即找出下一个质数，创建新的 buckets vector，重新计算元素在新 hashtable 的位置。

<img src = "http://oss.interviewguide.cn/img/202205220035271.png"  weight="300" height = "200">

[https://github.com/Light-City/CPlusPlusThings/blob/master/src_analysis/stl/hashtable.md](https://github.com/Light-City/CPlusPlusThings/blob/master/src_analysis/stl/hashtable.md)

## 113.c++  traits 技法理解
**traits，又被叫做特性萃取技术**，说得简单点就是**提取“被传进的对象”对应的返回类型，让同一个接口实现对应的功能**。因为STL的算法和容器是分离的，两者通过迭代器链接。算法的实现并不知道自己被传进来什么。萃取器相当于在接口和实现之间加一层封装，来隐藏一些细节并协助调用合适的方法，这需要一些技巧（例如，偏特化）。

traits 技法利用“内嵌型别”的编程技巧与编译器的 template 参数推导功能，增强C++ 未能提供的关于型别认证方面的能力。常用的有 `iterator_traits` 和 `type_traits` 。

C++ 中的模板特性（Traits）是一种常见的技术，用于**在编译时提取或操作类型信息**。Traits类提供了一种灵活且可扩展的方法，用于实现类型特定的行为和元编程。Traits的主要作用包括：

- **类型信息提取**：提取类型的某些属性或信息，例如类型的基本类型、是否为指针、是否为某种类型的实例等。
- **类型操作**：定义某些类型转换或操作，例如从一种类型转换为另一种类型。
- **条件编译**：根据类型信息进行条件编译，以实现不同类型的特定行为。

[https://www.cnblogs.com/codemagiciant/p/17601959.html](https://www.cnblogs.com/codemagiciant/p/17601959.html)


## 114.STL的两级空间配置器

**为什么有适配器？**  
（1）小块内存带来的内存碎片问题；  
（2）小块内存频繁申请释放带来的性能问题；   
（3）小块空间太多会造成空间的浪费；

**STL里面的空间配置主要分为两级**：一级空间配置器(`__malloc_alloc_template`)和二级空间配置器(`__default_alloc_template`)。  
（1）在STL中默认**如果要分配的内存大于128个字节的话就是大块内存，调用一级空间配置器直接向系统申请**；  
直接采用malloc和free进行内存的申请和释放


（2）**如果小于等于128个字节的话则认为是小内存，则就去内存池中申请**。  
> `default_alloc_template` 维护着一个内存池，内存池每次分配内存都会分配一大块内存，并维护 free_list，free_list 是一个指针数组，free_list有16项，每一项都维护一个对应大小的内存块链表，大小分别为8、16、24、32、40、48、56、64、72、80、88、96、104、112、120、128；
> 
> 从 `free_list` 找到管理指定内存块大小的链表，如果该链表上没有内存块，那么就重新填充（从缓存块中获取内存，填充free_list对应的链表），之后将分配得到的内存块从链表中删除，再返回此内存块。

## 115.STL 中vector删除其中的元素，迭代器如何变化？为什么是两倍扩容？释放空间？

 C++ vector 容器利用类似于数组的连续内存空间来存储其元素，当利用其 `erase` 函数删除相应的元素之后，该容器会重新分配所有剩下的元素，同时 **erase 函数会返回指向已经删除的那些元素的下一个元素的迭代器**，**以前所有指向被删除元素以后的元素的迭代器会失效**。

size()函数返回的是已用空间大小，capacity()返回的是总空间大小，capacity()-size()则是剩余的可用空间大小。当size()和capacity()相等，说明vector目前的空间已被用完，如果再添加新元素，则会引起vector空间的动态增长。

可以使用`reserve(n)`预先分配一块较大的指定大小的内存空间，这样当指定大小的内存空间未使用完时，是不会重新分配内存空间的，这样便提升了效率。

整体的一个**扩容流程**为：  
申请新的内存空间（空间大小为原空间的两倍或一点五倍）—> 把原空间的元素拷贝到新的空间里 —> 释放原空间 —> 数组指针指向新空间。

使用k=2增长因子的问题在于，**每次扩展的新尺寸必然刚好大于之前分配的总和**，也就是说，之前分配的内存空间不可能被使用。

## 116.Vector如何释放空间?
1. **清空vector** ：用vector的clear()方法可以清空vector中的元素，但是并不会释放vector所占用的内存空间。这意味着，如果之后还需要往vector中添加元素，vector会尝试使用之前已经分配的内存空间，而不是重新分配内存空间。【如果需要释放vector占用的内存空间，<font color=blue>可以**在调用clear()方法之后再调用vector的shrink_to_fit()方法，该方法会将vector的容量减小到与其大小相等，从而释放多余的内存空间**。</font>】
2. **重新分配vector大小**：
可以使用resize()方法重新分配vector的大小，从而释放多余的内存空间。
3. **使用swap()方法**：
可以使用swap()方法交换两个vector的内容，从而释放一个vector占用的内存空间。
4. **使用移动语义**：
C++11引入了移动语义，可以通过将一个 vector **移动** 到另一个 vector 来释放内存空间。具体方法是，使用`std::move()`函数将一个vector移动到另一个vector中，然后将原vector置为空。


[https://www.cnblogs.com/ybqjymy/p/18054639](https://www.cnblogs.com/ybqjymy/p/18054639)

## 117.容器内部删除一个元素？
- **关联容器的删除**  
对于关联容器(如map, set,multimap,multiset)，**删除当前的iterator，仅仅会使当前的iterator失效**，只要在erase时，递增当前iterator即可。这是因为map之类的容器，使用了红黑树来实现，插入、删除一个结点不会对其他结点造成影响。erase迭代器只是被删元素的迭代器失效，但是返回值为void，所以要采用erase(iter++)的方式删除迭代器。
- **顺序容器的删除**  
顺序容器就是数组式容器，删除当前的iterator会使后面所有元素的iterator都失效。这是因为vetor，deque使用了连续分配的内存，删除一个元素导致后面所有的元素会向前移动一个位置。所以不能使用erase(iter++)的方式，还好erase方法可以返回下一个有效的iterator。
- **链表式容器的删除**  
对于list型的数据结构，使用了不连续分配的内存，删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器。解决办法两种，erase(*iter)会返回下一个有效迭代器的值，或者erase(iter++)。

## 118.STL迭代器如何实现？
1. 迭代器是一种抽象的设计理念，**通过迭代器可以在不了解容器内部原理的情况下遍历容器**，除此之外，STL中迭代器一个最重要的作用就是作为容器与STL算法的粘合剂。
2.  迭代器的作用就是**提供一个遍历容器内部所有元素的接口**，**因此迭代器内部必须保存一个与容器相关联的指针**，然后**重载各种运算操作来遍历**，其中最重要的是*运算符与->运算符，以及++、--等可能需要重载的运算符重载。这和C++中的智能指针很像，智能指针也是将一个指针封装，然后通过引用计数或是其他方法完成自动释放内存的功能。
3. 最常用的迭代器的相应型别有五种:value type、difference type、pointer、reference、iterator catagoly;

## 119.map、set是怎么实现的，红黑树是怎么能够同时实现这两种容器?为什么使用红黑树？
- 他们的底层都是以红黑树的结构实现，因此插入删除等操作都在O(logn)时间内完成，因此可以完成高效的插入删除；
- 在这里定义了一个模版参数，如果它是 key 那么它就是 set，如果它是map，那么它就是 map；底层是红黑树，实现 map 的红黑树的节点数据类型是key+value，而实现 set 的节点数据类型是value
- 因为 map 和 set 要求是自动排序的，红黑树能够实现这一功能，而且时间复杂度比较低。


> 红黑树和AVL树都是高效的平衡二叉树，复杂度都一样。**红黑树不追求绝对平衡，其只需保证最长路径不超过最短路径的2倍**，相对而言，**降低了插入和旋转的次数**，所以在经常进行增删的结构中性能比AVL树（当需要大量增删的时候，AVL树旋转次数太多，效率并不高）更优，而且红黑树实现比较简单，所以实际运用中红黑树更多。

## 120.如何在共享内存上使用STL标准库？
1. 一个最笨拙的办法是**在堆上构造STL容器，然后把容器复制到共享内存**，并且确保所有容器的内部分配的内存指向共享内存中的相应区域，这基本是个不可能完成的任务。
2. 进程A把容器放在共享内存中的确定地址上（fixed offsets），则进程B可以从该已知地址上获取容器。
3. 进程A先在共享内存**某块确定地址上放置一个map容器，然后进程A再创建其他容器，然后给其取个名字和地址一并保存到这个map容器里**。进程B知道如何获取该保存了地址映射的map容器，然后同样再根据名字取得其他容器的地址。

## 121.map插入方式有哪几种？
1. 用insert函数插入pair数据

    	mapStudent.insert(pair<int, string>(1, "student_one")); 

2. 用insert函数插入value_type数据

    	mapStudent.insert(map<int, string>::value_type (1, "student_one"));

3. 在insert函数中使用make_pair()函数

    	mapStudent.insert(make_pair(1, "student_one")); 

4. 用数组方式插入数据

    	mapStudent[1] = "student_one"; 

## 122.STL 中 unordered_map(hash_map) 和 map 的区别，hash_map 如何解决冲突以及扩容？
1、**需要引入的头文件不同**  
map: #include < map >  
unordered_map: #include < unordered_map >  

2、内部实现机理不同   
 map内部实现了一个红黑树，具有 **自动排序** 的功能，因此 map 内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素。因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行的操作。map中的元素是按照二叉搜索树存储的，使用 **中序遍历** 可将键值按照从小到大遍历出来。  
unordered_map内部实现了一个 **哈希表**（也叫散列表，通过把关键码值映射到Hash表中一个位置来访问记录，查找的时间复杂度可达到O(1)，其在海量数据处理中有着广泛应用）。因此，其元素的排列顺序是无序的。  

3、使用时 map 的 key 需要定义`operator<`。而unordered_map需要定义`hash_value`函数并且重载`operator=`=    
std::map 是一个 **排序的关联容器**，需要对键值进行比较，以确定元素的存储位置。默认情况下，std::map使用`operator<`来比较键；  
std::unordered_map是一个基于哈希的关联容器，它使用哈希函数来确定元素的存储位置，同时也需要一个比较函数来处理哈希冲突。默认情况下，std::unordered_map使用`std::hash`作为哈希函数，`operator==`作为比较函数。


**hash_map如何解决冲突？**

- 开放地址法：线性探测再散列、平方探测再散列；
- 拉链法：如果发生冲突，就继续往前一个元素上链接；
- 再哈希：如果发生冲突，就用另一个方法计算hashcode，两次结果值不一样就不会发生hash冲突；
- 建立公共溢出区：将哈希表分为基本表和溢出表两部分，与基本表发生冲突的元素，一律填入溢出表。


[https://blog.csdn.net/qq_43434328/article/details/115876864](https://blog.csdn.net/qq_43434328/article/details/115876864)



**hash_map如何扩容？**

哈希表（如std::unordered_map）的扩容是一个重要的过程，在 **装载因子（即哈希表中当前元素数量与哈希表大小的比值）** 达到或超过某个阈值（例如0.75）时发生。装载因子过高会增加哈希冲突的可能性，从而降低哈希表的性能。

1、**分配新内存**：首先，哈希表会分配一个新的、更大的内存块。新哈希表的大小通常是原来的两倍，但具体的扩展策略可能因具体的哈希表实现和特定的应用需求而不同。

2、**元素重新哈希**：然后，哈希表会遍历原来的所有元素，并使用哈希函数重新计算每个元素的哈希值。由于哈希表的大小已经改变，这通常会导致元素的哈希值也随之改变。

3、**元素迁移**：接着，哈希表会根据每个元素新的哈希值，将元素移动到新哈希表的相应位置。

4、**释放旧内存**：最后，一旦所有的元素都被成功地迁移到新的哈希表，就可以释放旧的哈希表占用的内存。

哈希表的扩容操作需要对所有元素进行重新哈希和迁移，因此时间复杂度为`O(n)`，其中`n`是哈希表中的元素数量。


## 123.vector越界访问下标，map越界访问下标？
- 在C++中，如果你 **使用operator[]来访问std::vector的元素，当下标越界时，编译器不会抛出任何错误或异常** ，而且它通常会**返回一个未定义的值**，这可能导致程序行为异常或崩溃。这种情况下，错误可能很难被检测到，因为程序可能会在某些情况下正常运行，但在其他情况下出现错误。  
【为了避免这种情况，C++提供了`std::vector::at()`成员函数，这个函数在访问超出std::vector范围的索引时 **会抛出std::out_of_range异常**。】


- 在C++的std::map中，使用operator[]**访问一个不存在的键会创建一个具有该键和默认值（通常为0或等效初始化值）的新元素**。  
【如果不希望在键不存在时创建新元素，你应该使用`std::map::find()`。（用 key 执行查找，找到了返回该位置的迭代器；如果不存在这个关键码，就返回尾迭代器）】

## 124.STL中list与queue之间的区别？
1. **容器类型**：std::list 是一个**双向链表**，而 std::queue 是一个队列，可以使用多种实现方式（如顺序容器、优先队列等）。
1. **插入和删除元素**：在 std::list 中，可以在任何位置插入和删除元素，而在 std::queue 中，只能在队尾插入元素，从队头删除元素。
1. **访问元素**：在 std::list 中，可以随机访问元素，而在 std::queue 中，只能顺序访问元素。
1. **存储方式**：std::list 采用链表存储元素，而 std::queue 采用顺序容器或优先队列等实现方式存储元素。
1. **适用场景**：std::list 适用于需要在任意位置进行插入和删除操作的场景，而 std::queue 适用于进行先进先出操作的场景。


## 125.常见容器性质总结？
C++ STL（Standard Template Library）提供了多种容器，用于存储和操作各种类型的数据。以下是一些常见容器的特性总结：

1.std::vector：动态数组，能高效地在末尾进行插入和删除操作，能直接访问任何元素。但在中间位置进行插入或删除操作则需要移动元素，效率较低。此外，当插入的元素超过当前分配的空间时，会重新分配内存，可能导致大规模元素移动。底层数据结构为数组

2.std::deque：双端队列，支持高效的头部和尾部插入和删除操作，并能直接访问任何元素。与std::vector相比，std::deque不保证元素在内存中的连续存储，因此当插入的元素超过当前分配的空间时，不需要移动其他元素。

3.std::queue：基于其它容器（如std::deque）实现的队列，支持两端的插入和删除操作。

4.std::priority_queue：基于其它容器（如std::vector）实现的优先队列，堆（heap）为处理规则来管理底层容器实现，元素按优先级排序。

5.std::list：底层数据结构为双向链表，能在任何位置高效地进行插入和删除操作。但不支持直接访问元素，只能通过迭代器进行访问。

6.std::forward_list：单向链表，只能从头部开始遍历，并只支持头部和后面的高效插入和删除操作。

7.std::array：固定大小的数组，提供与std::vector类似的接口，但其大小在编译时确定，无法动态改变。

8.std::set：底层数据结构为红黑树实现的有序集合，元素按排序顺序存储，每个元素只能出现一次。插入和查找操作的复杂度为对数级别。

9.std::multiset：与std::set类似，底层数据结构为红黑树，有序，允许元素重复。

10.std::map：底层数据结构为红黑树实现的有序映射表，存储键值对，键是唯一的，插入和查找操作的复杂度为对数级别。

11.std::unordered_map：基于哈希表实现的无序映射表，存储键值对，键是唯一的。在理想情况下，插入和查找操作的复杂度为常数级别。

12.std::multimap：与std::map类似，但允许键重复。

13.std::unordered_multimap：与std::unordered_map类似，但允许键重复。

14.std::unordered_set：基于哈希表实现的无序集合，每个元素只能出现一次。在理想情况下，插入和查找操作的复杂度为常数级别。

15.std::unordered_multiset：与std::unordered_set类似，但允许元素重复。

16.std::stack：基于其它容器（如std::deque）实现的栈，只支持顶部的插入和删除操作。


## 126.STL中的 allocator、deallocator
1) 第一级配置器直接使用malloc()、free()和relloc()，第二级配置器视情况采用不同的策略：当配置区块 超过128bytes时，视之为足够大，便调用第一级配置器；当配置器区块小于128bytes时，为了降低额外负担，使用复杂的内存池整理方式，而不再用一级配置器；

2) 第二级配置器主动将任何小额区块的内存需求量上调至8的倍数，并维护16个free-list，各自管理大小 为8~128bytes的小额区块。

3) 空间配置函数`allocate()`，首先判断区块大小，大于128就直接调用第一级配置器，小于128时就检查对 应的free-list。如果 free-list 之内有可用区块，就直接拿来用，如果没有可用区块，就将区块大小调整至8 的倍数，然后调用refill()，为free-list重新分配空间；

4) 空间释放函数`deallocate()`，该函数首先判断区块大小，大于128bytes 时，直接调用一级配置器，小于 128bytes 就找到对应的 free-list 然后释放内存。



## 127.STL 中 hash table 扩容发生什么?
当哈希表的元素数量增长到某个阈值时，就需要进行扩容。这个阈值通常是哈希表容量（bucket count）和装载因子（load factor）的乘积。装载因子是一个浮点数，它决定了哈希表元素数与容量之间的比例。默认装载因子通常是1.0。

当需要扩容时，STL会执行以下步骤：

1.创建一个新的、更大的哈希表。新的大小通常是原来大小的两倍。  
2.遍历原有哈希表中的所有元素，并重新计算它们在新哈希表中的位置（这个位置由元素的哈希值和新的哈希表大小决定）。  
3.将每个元素从旧的哈希表移动到新的哈希表的对应位置。

这个过程被称为 **rehashing**。这是一个相当消耗资源的操作，因为它涉及到重新计算每个元素的哈希值，并可能涉及到大量的内存操作。但是，通过这种方式，可以保证哈希表的性能，因为它能保证元素在哈希表中的分布更均匀，减少哈希冲突，提高查找效率。

注意，虽然扩容可以提高哈希表的性能，但是频繁的扩容操作会消耗大量的资源，影响程序的性能。因此，如果你预先知道哈希表需要存储大量的元素，可以通过 rehash 或 reserve 方法预先分配足够的空间，避免频繁的扩容操作。

[https://www.cnblogs.com/codemagiciant/p/17602267.html](https://www.cnblogs.com/codemagiciant/p/17602267.html)

## 128.hashtable 中解决冲突有哪些方法？

1. **开放定址法**；
	- 线行探查法：  
	使用 hash 函数计算出的位置如果已经有元素占用了，则向后依次寻找，找到表尾则回到表头，直到找到一个空位
	- 平方探查法：  
	使用hash函数计算出的位置如果已经有元素占用了，按照 $1^2$ 、$2^2$、$3^2...的步长依次寻找，如果步长是随机数序列，则称之为伪随机探测
	- 双散列函数探查法：  
	使用两个散列函数hl和h2，其探查序列的步长值是同一关键字的另一散列函数的值
2. **链地址法（拉链法）**：  
每个表格维护一个list，如果hash函数计算出的格子相同，则按顺序存在这个list中
3. **再哈希法**：  
发生冲突时使用另一种hash函数再计算一个地址，直到不冲突
4. **建立公共溢出区**：  
一旦hash函数计算的结果相同，就放入公共溢出区







## 129.C++的多态如何实现？
 在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将会根据所指对象的实如果对象类型是派生类，就调用派生类的函数，如果对象类型是际类型来调用相应的函数，基类，就调用基类的函数。

**具体过程：**

>**虚表**：虚函数表的缩写，类中含有 `virtual` 关键字修饰的方法时，编译器会自动生成；  
>**虚表虚表指针**：在含有虚函数的类实例化对象时，对象地址的前四个字节存储的指向虚表的指针。

（1）编译器在发现基类中有虚函数时，会自动**为每个含有虚函数的类生成一份虚表**，该表是一个一维数组，虚表里保存了虚函数的入口地址；  
（2）编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr，指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚指针 vptr，从而让 vptr 指向正确的虚表，从而在调用虚函数时，能找到正确的函数；  
（3）所谓的合适时机，在派生类定义对象时，程序运行会自动调用构造函数，在构造函数中创建虚表并对虚表初始化。在构造子类对象时，会先调用父类的构造函数，此时，编译器只“看到了"父类，并为父类对象初始化虚表指针，令它指向父类的虚表；当调用子类的构造函数时，为子类对象初始化虚表指针，令它指向子类的虚表。    
（4）**当派生类对基类的虚函数没有重写时，派生类的虚表指针指向的是基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向的是自身的虚表；**当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面。

这样指向派生类的基类指针在运行时，就可以根据派生类对虚函数重写情况动态的进行调用，从而实现多态性。

> C++中虚函数表位于只读**数据段(.rodata)**，也就是C++内存模型中的**常量区**；而虚函数则位于**代码段(.text)**，也就是C++内存模型中的**代码区**。

## 130.为什么析构函数一般写成虚函数？
由于类的多态性，基类指针可以指向派生类的对象，如果删除该基类的指针，就会调用该指针指向的派生类析构函数，而派生类的析构函数又自动调用基类的析构函数，这样整个派生类的对象完全被释放。

如果析构函数不被声明成虚函数，则编译器实施**静态绑定**，**在删除基类指针时，只会调用基类的析构函数而不调用派生类析构函数，这样就会造成派生类对象析构不完全，造成内存泄漏**。

## 131.模板函数和模板类的特例化
**引入原因**：
编写单一的模板，它能适应多种类型的需求，使每种类型都具有相同的功能，但对于某种特定类型，如果要实现其特有的功能，单一模板就无法做到，这时就需要**模板特例化**。


**定义**：
对单一模板提供的一个特殊实例，它将一个或多个模板参数绑定到特定的类型或值上。

**（1）模板函数特例化**  
必须为原函数模板的每个模板参数都提供实参，且使用关键字 `template` 后跟一个空尖括号对表明将原模板的所有模板参数提供实参。

	template<typename T> //模板函数
	int compare(const T &v1,const T &v2)
	{
	    if(v1 > v2) return -1;
	    if(v2 > v1) return 1;
	    return 0;
	}
	//模板特例化,满足针对字符串特定的比较，要提供所有实参，这里只有一个T
	template<> 
	int compare(const char* const &v1,const char* const &v2)
	{
	    return strcmp(p1,p2);
	}

特例化的本质是实例化一个模板，而非重载它。特例化不影响参数匹配。参数匹配都以最佳匹配为原则。

**（2）模板类特例化**   
原理类似函数模板，**不过在类中，我们可以对模板进行特例化，也可以对类进行部分特例**对类进行特例化时，仍然用`template<>`表示是一个特例化版本。

	template<>
	class hash<sales_data>
	{
		size_t operator()(sales_data& s);
		//里面所有T都换成特例化类型版本sales_data
		//按照最佳匹配原则，若T != sales_data，就用普通类模板，否则，就使用含有特定功能的特例化版本。
	};

特例化类中的部分成员，**可以特例化类中的部分成员函数而不是整个类**。

	template<typename T>
	class Foo
	{
	    void Bar();
	    void Barst(T a)();
	};
	
	template<>
	void Foo<int>::Bar()
	{
	    //进行int类型的特例化处理
	    cout << "我是int型特例化" << endl;
	}
	
	Foo<string> fs;
	Foo<int> fi;//使用特例化
	fs.Bar();//使用的是普通模板，即Foo<string>::Bar()
	fi.Bar();//特例化版本，执行Foo<int>::Bar()
	//Foo<string>::Bar()和Foo<int>::Bar()功能不同


## 132.C++模板是什么，你知道底层怎么实现的？
编译器并不是把函数模板处理成能够处理任意类的函数；**编译器从函数模板通过具体类型产生不同的函数**；  
编译器会对函数模板进行**两次编译**：在声明的地方对模板代码本身进行编译，在调用的地方对参数替换后的代码进行编译。

这是因为函数模板要被实例化后才能成为真正的函数，在使用函数模板的源文件中包含函数模板的头文件，如果该头文件中只有声明，没有定义，那编译器无法实例化该模板，最终导致链接错误。

## 133.构造函数析构函数可否抛出异常？
C++**只会析构已经完成的对象**，对象只有在其构造函数执行完毕才算是完全构造妥，当在构造函数中发生异常，控制权转出构造函数之外。  
因此，在对象 b 的构造函数中发生异常，对象 b 的析构函数不会被调用。因此会造成内存泄漏。

用 `auto_ptr` 对象来取代指针类成员，便对构造函数做了强化，免除了抛出异常时发生资源泄漏的危机，不再需要在析构函数中手动释放资源；

**如果控制权基于异常的因素离开析构函数**，而此时正有另一个异常处于作用状态 C++ 会调用 terminate 函数让程序结束；

如果异常从析构函数抛出，而且没有在当地进行捕捉，那个析构函数便是执行不全的。  
如果析构函数执行不全，就是没有完成他应该执行的每一件事情。


## 134.构造函数或者析构函数中可以调用虚函数吗？
可以，虚函数底层实现原理(但是最好不要在构造和析构函数中调用) 可以，但是**没有动态绑定的效果**，父类构造函数中调用的仍然是父类版本的函数，子类中调用的仍然是子类版本的函数。

a) 如果有继承，构造函数会先调用父类构造函数，而如果构造函数中有虚函数，此时子类还没有构造，所以此时的对象还是父类的，不会触发多态。更容易记的是基类构造期间，virtual 函数不是 virtual 函数。

b) 析构函数也是一样，子类先进行析构，这时，如果有 virtual 函数的话，子类的内容已经被析构了，C++会视其父类，执行父类的 virtual 函数。

## 135.构造函数的几种关键字
- `default` 关键字可以显式要求编译器生成合成构造函数，防止在调用时相关构造函数类型没有定义而报错；
- `delete` 关键字可以删除构造函数、赋值运算符函数等，这样在使用的时候会得到友善的提示；
- `0` 将虚函数定义为纯虚函数（纯虚函数无需定义），`=0`只能出现在类内部虚函数的声明语句处；当然，也可以为纯虚函数提供定义，函数体可以定义在类的外部也可以定义在内部。它在基类中没有定义，但**要求任何派生类都要定义自己的实现方法**。


## 136.拷贝构造函数和赋值运算符重载的区别？
- 拷贝构造函数是函数，赋值运算符是运算符重载。
- 拷贝构造函数会生成新的类对象，赋值运算符不能。
- 拷贝构造函数是直接构造一个新的类对象，所以在初始化对象前不需要检查源对象和新建对象是否相同；赋值运算符需要上述操作并提供两套不同的复制策略，另外赋值运算符中如果原来的对象有内存分配则需要先把内存释放掉。
- 形参传递是调用拷贝构造函数(调用的被赋值对象的拷贝构造函数)，但并不是所有出形参传递是调用拷贝构造函数(调用的被赋值对象的拷贝构造函数)，但并不是所有出。


## 137.什么是虚拟继承？
由于C++支持多重继承，那么在这种情况下会出现重复的基类这种情况，也就是说可能出现将一个类两次作为基类的可能性。如：类D继承自类B1、B2，而类B1、B2都继 承自类A，因此在类D中两次出现类A中的变量和函数。

为了节省内存空间，可以将B1、B2对A的继承定义为虚拟继承，而A就成了虚拟基类。

虚拟继承是多重继承中特有的概念。**虚拟基类是为解决多重继承而出现的**。

<font color=blue>虚继承的特点是，在任何派生类中的 `virtual` 基类总用同一个（共享）对象表示。</font>

**引入虚继承和直接继承会有什么区别呢**

由于有了间接性和共享性两个特征，所以决定了虚继承体系下的对象在访问时必然会在时间和空间上与一般情况有较大不同。

**时间**：在通过继承类对象访问虚基类对象中的成员（包括数据成员和函数成员）时，都必须通过某种间接引用来完成，这样会增加引用寻址时间（就和虚函数一样），其实就是调整 this 指针以指向虚基类对象，只不过这个调整是运行时间接完成的。

**空间**：由于共享所以不必要在对象内存中保存多份虚基类子对象的拷贝，这样较之多继承节省空间。虚拟继承与普通继承不同的是，虚拟继承可以防止出现 diamond 继承时，一个派生类中同时出现了两个基类的子对象。也就是说，为了保证 这一点，在虚拟继承情况下，基类子对象的布局是不同于普通继承的。因此，它**需要多出一个指向基类子对象的指针**。


    第一种情况：　　　　　　　　 第二种情况：　　　　　　　　　　第三种情况　　　　　　　　　　　　第四种情况：
	class a　　　　　　　　　　　class a　　　　　　　　　　　　  class a　　　　　　　　　　　　　　class a
	{　　　　　　　　　　　　　 {　　　　　　　　　　　　　　　 {　　　　　　　　　　　　　　　　　{
	    virtual void func();　　　　　　virtual void func();　　　　　　　virtual void func();　　　　　　　　virtual void func();
	};　　　　　　　　　　　　　 };　　　　　　　　　　　　　　　　　 char x;　　　　　　　　　　　　　　char x;
	class b:public virtual a　　　class b :public a　　　　　　　    };　　　　　　　　　　　　　　　　};
	{　　　　　　　　　　　　　　{　　　　　　　　　　　　　　 　class b:public virtual a　　　　　 class b:public a
	    virtual void foo();　　　　　　  virtual void foo();　　　　　{　　　　　　　　　　　　　　　　 {
	};　　　　　　　　　　　　　 };　　　　　　　　　　　　　　　　　　virtual void foo();　　　　　　　　virtual void foo();
	　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　};　　　　　　　　　　　　　　　　};
如果对这四种情况分别求sizeof(a）,  sizeof(b)。结果是什么样的呢？下面是输出结果：（在vc6.0中运行）
第一种：4，12
第二种：4，4
第三种：8，16
第四种：8，8

因为**每个存在虚函数的类都要有一个4字节的指针指向自己的虚函数表**，所以每种情况的类a所占的字节数应该是没有什么问题的，那么类b的字节数怎么算呢？看“第一种”和“第三种”情况采用的是虚继承，那么这时候就要有这样的一个指针 `vptr_b_a`，这个指针叫**虚类指针**，也是**四个字节**；**还要包括类a的字节数**，所以类b的字节数就求出来了。而“第二种”和“第四种”情况则不包括 `vptr_b_a` 这个指针。

[https://www.cnblogs.com/heyonggang/p/3255155.html](https://www.cnblogs.com/heyonggang/p/3255155.html)


## 138.什么情况会自动生成默认构造函数？
1. 带有默认构造函数的类成员对象，如果一个类没有任何构造函数，但它含有一个成员对象，而后者有默认构造函数，那么编译器就为该类合成出一个默认构造函数；
2. 带有默认构造函数的基类，如果一个没有任务构造函数的派生类派生自一个带有默认构造函数基类，那么该派生类会合成一个构造函数调用上一层基类的默认构造函数；
3. 带有一个虚函数的类；
4. 带有一个虚基类的类（ 虚基类是用关键字 `virtual` 声明继承的父类）；
5. 合成的默认构造函数中，只有基类子对象和成员类对象会被初始化。所有其他的非静态数据成员都不会被初始化。


## 139.抽象基类为什么不能创建对象？
抽象类是一种特殊的类，它是为了抽象和设计的目的为建立的，它处于继承层次结构的较上层。

（1）抽象类的定义：称带有纯虚函数的类为抽象类。

（2）抽象类的作用：抽象类的主要作用是**将有关的操作作为结果接口组织在一个继承层次结构中，由它来为派生类提供一 个公共的根，派生类将具体实现在其基类中作为接口的操作**。所以派生类实际上刻画了一组子类的操作接口的通用语义，这些语义也传给子类，子类可以具体实现这些语义，也可以再将这些语义传给自己的子类。

（3）使用抽象类时注意：抽象类只能作为基类来使用，其纯虚函数的实现由派生类给出。如果派生类中没有重新定义纯虚函数，而只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体的类。

## 140.模板类和模板函数的区别是什么？
函数模板的实例化是**由编译程序在处理函数调用时自动完成的**，而类模板的实例化必须**由程序员在程序中显式地指定**。

即**函数模板允许隐式调用和显式调用**而**类模板只能显示调用**。在使用时类模板必须加`<T>`，而函数模板不必。


## 141.无论是系统默认还是自定义的拷贝构造函数，都是传一个引用，而不是值，这是为什么呢？
若拷贝构造函数参数为值传递，当**实参赋值给形参时，又发生了一次拷贝函数的调用**，无限递归下去，导致爆栈。

拷贝构造函数用来初始化一个非引用类类型对象，如果用传值的方式进行传参数，那么**构造实参需要调用拷贝构造函数**，而拷贝构造函数需要传递实参，所以会一直递归。

拷贝构造函数参数为引用，不为值传递是为了**防止拷贝构造函数的无限递归**，最终导致栈溢出。


[https://pabebezz.github.io/article/c13c7aad/](https://pabebezz.github.io/article/c13c7aad/)


## 142.静态函数能定义为虚函数吗？常函数呢？说说你的理解？
1、static成员不属于任何类对象或类实例，所以即使给此函数加上virutal也是没有任何意义的；

2、静态与非静态成员函数之间有一个主要的区别，那就是静态成员函数没有this指针。它没有this指针，所以无法访问vptr【static 函数不能为 virtual 】。

## 143.虚函数的代价是什么?
- 带有虚函数的类，每一个类会**产生一个虚函数表**，用来存储指向虚成员函数的指针，增大类；
- 带有虚函数的类的每一个对象，都会有有一个指向**虚表的指针**，会增加对象的空间大小；
- 不能再是内联的函数，因为内联函数在编译阶段进行替代，而虚函数表示等待，在运行阶段才能确定到低是采用哪种函数，**虚函数不能是内联函数**。

## 144.哪些函数不能是虚函数？把你知道的都说一说？
1. **构造函数**，构造函数初始化对象，派生类必须知道基类函数干了什么，才能进行构造当有虚函数时，每一个类有一个虚表，每一个对象有一个虚表指针，虚表指针在构造函数中初始化;
2. **内联函数**，内联函数表示在编译阶段进行函数体的替换操作，而虚函数意味着在运行期间进行类型确定，所以内联函数不能是虚函数；
3. **静态函数**，静态函数不属于对象属于类，静态成员函数没有 `this` 指针，因此静态函数设置为虚函数没有任何意义。
4. **友元函数**，友元函数不属于类的成员函数，不能被继承。对于没有继承特性的函数没有虚函数的说法。
5. **普通函数**，普通函数不属于类的成员函数，不具有继承特性，因此普通函数没有虚函S数。


## 145.什么是纯虚函数，与虚函数的区别？
虚函数是有实现的，而纯虚函数没有实现。** 虚函数在基类中有默认实现，子类可以重写它，也可以不重写，但纯虚函数必须在子类中实现**。   
如果一个类中包含至少一个纯虚函数，那么这个类就是抽象类，不能直接实例化对象。 而虚函数不会强制一个类成为抽象类。

## 146.构造函数的执行顺序是什么?
1. 在派生类构造函数中，所有的虚基类及上一层基类的构造函数调用；
2. 对象的 `vptr` 被初始化；
3. 如果有成员初始化列表，将在构造函数体内扩展开来，这必须在 `vptr` 被设定之后才做；
4. 执行程序员所提供的代码；

## 147.C++ using 关键字的三种作用
1. **使用命名空间**：`using namespace nsp;`
2. **改变父类成员的访问权限**：子类继承了父类后，在修饰符（public、protected、private）下使用 using + 可访问的父类成员，该成员就相当于是子类在该修饰符下中声明的。

	    // 原本 _m_Base_pub 在默认继承下是私有的，不可通过 Derive 对象实例访问，但是子类在 public 修饰符下对他使用了 using，
    	// 该变量就像是子类自己声明的一样，可以通过子类对象实例访问了
    	using Base::_m_Base_pub;	
    	int _m_Derive_pub;

3.**类型别名**：相当于 typedef，但是某种程度上来说 using 要更加直观；

    // 基本类型别名，两者等价
    typedef int MyInt;
    using MyInt = int;
    
    //声明函数指针类型的别名，使用 using 要直观些，一眼就能看出来 func 是函数指针
    typedef void (*func)(void);
    using func = void (*)(void);

**模板别名：**

    template <typename T>;
    using MyVector = std::vector<T>;

## 148.移动语义与完美转发

`std::move` 无条件地将实参转换为右值；

>  std::move 底层是做 static_cast；  
>  std::move 允许我们截断左值，也就是说**不再使用该左值，可以自由移动它所拥有的资源**；这是非常特殊的类型操作，通过使用 std::move 方便我们确定在哪里对左值做了截断，语义上更加清晰。

<font color=blue>使用 std::move 并不代表移动操作一定会发生</font>

- 可能这个类型根本没有定义移动操作
- std::move 并不会去除实参的 const 性质，因此把 const 的对象传给它，得到的返回值类型也是 const 的，对它的操作会变为拷贝操作；  
因为移动操作往往会修改源对象，所以我们不希望在 const 对象上触发移动操作。


`std::forward` 在部分条件下将实参转换为右值；

**完美转发**指的是函数模板可以将自己的参数“完美”的转发给内部调用的其他函数中。
所谓的**完美**，指的是不仅能准确的转发参数的值，还能**保证被转发的参数的左、右值属性不变**。

某些函数**需要将其一个或多个实参连同类型不变地转发给其他函数，转发后需要保持被转发实参的所有性质**，包括

- 实参是否是 const 的；
- 实参是左值还是右值；



<font color=red>在函数中多次使用某个右值引用或通用引用，那么只有在最后一次使用它的时候，才可以对它调 `std::move` 或 `std::forward`，因为将它转为右值后，它的内容就不能再被使用了</font>


> C++ 标准中规定，右值引用形式的参数只能接收右值，不能接受左值。
> 但是对于函数模板中使用右值引用语法定义的参数来说，它既可以接受左值，又可以接受右值，此时这个右值引用被称为**万能引用**。


只要在模板函数中，调用 std::forward() 函数，就可以将传入参数的属性和数值一同传递到内部的调用函数中


std::forward 相比于简单地将参数传递给另一个函数而言，可以提高代码的效率，主要体现在以下几个方面：

1. **避免多余的拷贝**：当参数是左值（lvalue）时，使用std::forward可以将参数作为左值引用传递给下一层函数，避免产生额外的拷贝操作。如果直接传递参数，会导致参数被当作右值（rvalue）来处理，从而触发拷贝构造函数。
2. **精确匹配重载函数**：有时我们在一个函数中需要对传递的参数进行重载函数的调用，而这些重载函数可能接受不同的参数类型（比如一个接受左值引用，一个接受右值引用）。使用std::forward可以精确匹配原始传入参数的类型，从而调用正确的重载函数。
3. **消除重载冗余**：std::forward使用引用折叠规则，从而避免引入额外的重载函数，以减少代码的冗余。通过std::forward，可以将参数的左值引用和右值引用统一起来，消除了传递参数时的冗余重载处理。


[https://www.cnblogs.com/ljx-null/p/16512384.html](https://www.cnblogs.com/ljx-null/p/16512384.html)

[https://www.cnblogs.com/wanghao-boke/p/17756937.html](https://www.cnblogs.com/wanghao-boke/p/17756937.html)


## 149. C++ 协程
**协程不受操作系统调度，切换方便，轻量级**

- **依赖关系**：线程是由操作系统内核进行调度管理的，并且每个线程通常拥有自己的独立堆栈和上下文。而**协程则是由程序员在代码中显式地定义和管理的，没有操作系统参与调度**。协程依赖于某种运行时环境或者特定的库来实现调度和切换。
- **并发性能**：线程属于操作系统层面的并发机制，它可以充分利用多核处理器的计算能力。每个线程都需要一定的系统资源来进行管理，因此创建大量线程可能会导致资源消耗过大。相比之下，协程是轻量级的，可以在单个线程中运行大量的协程，节省了线程切换的开销。
- **切换机制**：在线程之间进行切换时，需要进行上下文的保存和恢复，这是由操作系统内核负责完成的，并且通常涉及到用户态和内核态之间的切换。而**协程的切换是在用户态完成的**，切换开销更小。协程通过手动选择合适的切换点，在不同的协程之间进行切换，使得程序可以在合适的时机保存和恢复中间状态。
- **同步方式**：线程通常通过共享内存或者消息传递来进行通信和同步。而协程则通常通过显式的调度和消息传递机制来实现数据共享和同步。协程之间的切换是协作性的，需要各个协程自行决定何时让出执行权。

总的来说，线程更加底层和系统级别，可以充分利用多核处理器的并行计算能力，但线程数量受限于系统资源，并且线程切换开销较大。而**协程是一种高级抽象，更适合处理大量的轻型任务，并且协程之间的切换开销较小**。但协程需要依赖特定的运行时环境或库的支持，无法直接利用多核处理器的并行计算能力。




[https://www.bennyhuo.com/2022/03/09/cpp-coroutines-01-intro/](https://www.bennyhuo.com/2022/03/09/cpp-coroutines-01-intro/)

---

# 操作系统

## 1.将字符串 “hello world" 从开始到打印到屏幕上的全过程？

1. 用户告诉操作系统执行 HelloWorld 程序（通过键盘输入等）
2. 操作系统：找到 helloworld 程序的相关信息，检查其类型是否是可执行文件；并通过程序首部信息，确定代码和数据在可执行文件中的位置并计算出对应的磁盘块地址;
3. 操作系统：**创建一个新进程**，将 HelloWorld 可执行文件**映射到该进程**结构，表示由该进程执行 helloworld 程序。

4. 操作系统：为 helloworld 程序**设置 cpu 上下文环境**，并**跳到程序开始处**。

5. 执行 helloworld 程序的第一条指令，发生**缺页异常**；

6. 操作系统：分配一页物理内存，并将代码**从磁盘读入内存**，然后继续执行helloworld程序;

7. helloword 程序**执行 puts 函数（系统调用）**，在显示器上写一字符串；

8. 操作系统：找到要**将字符串送往的显示设备**，通常设备是由一个进程控制的，所以，**操作系统将要写的字符串送给该进程**

9. 操作系统：控制设备的进程告诉设备的窗口系统，它要显示该字符串，窗口系统确定这是一个合法 的操作，然后将字符串转换成像素，**将像素写入设备的存储映像区**；

10. 视频硬件将像素转换成显示器可接收和一组控制数据信号；

11. 显示器解释信号，激发液晶屏；

12. OK，我们在屏幕上看到了HelloWorld；

## 2.进程、线程和协程的区别和联系
- **进程**： 是操作系统进行 **资源分配的基本单位** ，每个进程都有自己的独立内存空间。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。  
对于操作系统来说，***一个任务就是一个进程（Process）***；

- **线程**： 又叫做轻量级进程，是进程的一个实体，是 **处理器任务调度和执行的基本单位** 。它是比进程更小的能独立运行的基本单位。线程只拥有一点在运行中必不可少的资源(**如程序计数器，一组寄存器和栈**)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。  
由于每个进程至少要干一件事，所以， ***一个进程至少有一个线程***。

- **协程** ：又称微线程，是一种用户态的轻量级线程，协程的 **调度完全由用户控制** （也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。  **线程是抢占式，而协程是非抢占式的**，所以需要用户代码释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。
因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和线程切换相比，**线程数量越多，协程的性能优势就越明显**。



[https://cloud.tencent.com/developer/article/1839604](https://cloud.tencent.com/developer/article/1839604)

## 3.线程和进程的区别？
- 调度：线程是调度的基本单位(PC，状态码，通用寄存器，线程栈及栈指针)；进程是拥有资源的基本单位(打开文件，堆，静态区，代码段等)。
- 并发性：一个进程内多个线程可以并发(最好和CPU核数相等)；多个进程可以并发。
- 拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享隶属进程的资源；进程是拥有资源的独立单位。
- 系统开销：线程创建销毁只需要处理 PC 值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁 `task_struct` 结构。

## 4.一个进程可以创建多少线程，和什么有关？
- 如果是32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 如果是 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制而会受系统的参数或性能限制。

过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负
面影响，无用线程要及时销毁。

## 5.外中断和异常有什么区别？
外中断是指**由 CPU 执行指令以外的事件引起**，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

而异常时**由 CPU 执行指令的内部事件引起**，如非法操作码、地址越界、算术溢出等。

[https://www.cnblogs.com/codemagiciant/p/17707137.html](https://www.cnblogs.com/codemagiciant/p/17707137.html)


## 6.进程线程模型你知道多少？

**多线程**

同一个进程内部有多个线程，所有的线程共享同个进程的内存空间，进程中定义的全局变量会被所有的线程共享；

除了标识线程的`tid`，**每个线程还有自己独立的栈空间**，线程彼此之间是无法访问其他线程栈上内容的。

原先顺序执行的程序（暂时不考虑多进程）可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务（最好这些任务是不相关的）。

而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和PC即可，相比进程切换开销要小很多。


- 线程之间有无先后访问顺序(线程依赖关系)
- 多个线程共享访问同一变量(同步互斥问题)


**多进程**

每一个进程是资源分配的基本单位。

进程结构由以下几个部分组成：代码段、堆栈段、数据段。**代码段是静态的二进制代码，多个程序可以共享**。

实际上在父进程创建子进程之后，父、子进程除了 pid 外，几乎所有的部分几乎一样。

父、子进程共享全部数据，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过**写时复制机制将公共的数据重新拷贝一份**，之后在拷贝出的数据上进行操作。

如果子进程想要运行自己的代码段，还可以通过调用`execv()`函数重新加载新的代码段，之后就和父进程独立开了。



每个线程都是一个轻量级进程(Light Weight Process)，都有自己的唯一PID和一个**TGID**(Thread group ID)。TGID是启动整个进程的thread的PID。例如，当一个进程被创建的时候，它其实是一个PID和TGID数值相同线程。当线程A启动线程B时，线程B会有自己的唯一PID，但它的TGID会从A继承而来。这样通过PID线程可以独立得到调度，而**相同的TGID可以知道哪些线程属于同一个进程，这样可以共享资源(RAM，虚拟内存、文件等)**。

线程进程的区别体现在6个方面：

1. **根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
1. **资源开销**：每个进程都有独立的代码和数据空间，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一进程的线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
1. **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的。
1. **内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。
1. **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
1. **执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。两者均可并发执行。


## 7.进程调度算法你了解多少？
- **先来先服务**：按照请求的顺序进行调度。 这种调度方式简单，但是能导致较长作业阻塞较短作业。
- **最短作业优先**：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。 但是如果一直有短作业到来，那么长作业永远得不到调度，造成长作业“饥饿”现象。
- **高响应比优先**：既考虑作业的执行时间也考虑作业的等待时间，综合了先来先服务和最短作业优先两种算法的特点。先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行；优先权 = （等待时间 + 要求服务时间）/ 要求服务时间；
- **最短剩余时间优先**：基于最短作业优先改进，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。
- **优先级调度**：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
- **时间片轮转**：为每个进程分配一个时间片，进程轮流执行，时间片用完后切换到下一个进程。
- **多级反馈队列**：时间片轮转算法」和「最高优先级算法」的综合和发展。【多级】表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。【反馈】表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

## 8.进程间的通信方式(IPC)有哪些？
每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）。

- **管道**：一种半双工（即数据只能在一个方向上流动）的通信方式，数据只能单向流动，通信的数据是无格式的流并且大小受限，而且只能在具有亲缘关系（兄弟、父子）的进程间使用。进程写入的数据都是 **缓存在内核** 中，另一个进程读取数据时候也是从内核中获取。同时通信数据都遵循 **先进先出** 原则，不支持 `lseek` 之类的文件定位操作。
- **消息队列**：消息队列的消息体是**可以用户自定义的数据类型**，发送数据时，会被分成一个一个独立的消息体，由消息的**链表**，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列通信的速度不是最及时的，毕竟 **每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程** 。
- **共享内存**：解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销， **直接分配一个共享空间，每个进程都可以直接访问** 。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制（如信号量）配合使用来实现进程间的同步和通信。共享内存是**临界资源**，所以需要操作时必须要保证原子性。使用信号量或者互斥锁都可以。
- **信号量**：一个计数器，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作（p 操作为申请资源，会将数值减去M，v 操作是归还资源操作），可以用来控制多个进程对共享资源的访问。它常作为一种**锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
- **信号**：是软件中断产生，用于进程间异步传递信息。信号可以用来直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。进程有三种方式响应信号 **1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`；一共有`64`种信号，在shell中输入` kill -l `可查阅
- **套接字(socket)**：套接字允许两个进程进行通讯，这两个进程可能运行在同一个机器上，也可能运行在不同机器上。套接字只能一对一。此外由于**序列化等操作占用大量资源**，相对于共享内存，套接字更适合传输少量数据。


## 9.解释一下进程同步和互斥，以及如何实现进程同步和互斥？
**进程同步**是指多个并发执行的进程之间协调和管理它们的执行顺序，以确保它们按照一定的顺序或时间间隔执行。

**互斥**指的是在某一时刻只允许一个进程访问某个共享资源。当一个进程正在使用共享资源时，其他进程不能同时访问该资源。

解决进程同步和互斥的问题有很多种方法，其中一种常见的方法是使用**信号量和 PV 操作**。信号量是一种特殊的变量，它表示系统中某种资源的数量或者状态。PV 操作是一种对信号量进行增加或者减少的操作，它们可以用来控制进程之间的同步或者互斥。

- P操作：相当于“检查”信号量，如果资源可用，就减少计数，然后使用资源。
- V操作：相当于“归还”资源，增加信号量的计数，并可能唤醒等待的进程。

除此之外，下面的方法也可以解决进程同步和互斥问题：

- **临界区**：将可能引发互斥问题的代码段称为临界区，里面包含了需要互斥访问的资源。进入这个区域前需要先获取锁，退出临界区后释放该锁。这确保同一时间只有一个进程可以进入临界区。
- **互斥锁（Mutex）**：互斥锁是一种同步机制，用于实现互斥。每个共享资源都关联一个互斥锁，进程在访问该资源前需要先获取互斥锁，使用完后释放锁。只有获得锁的进程才能访问共享资源。
- **条件变量**：条件变量**用于在进程之间传递信息**，以便它们在特定条件下等待或唤醒。通常与互斥锁一起使用，以确保等待和唤醒的操作在正确的时机执行。


<font color = red>
POSIX 信号量：可用于进程同步，也可用于线程同步。  
**POSIX 互斥锁 + 条件变量：只能用于线程同步。**
</font>

## 10.如果系统中具有快表后，那么地址的转换过程变成什么样了?
**快表**， 又称联想寄存器（TLB， translation lookaside buffer ） ， 是一种访问速度比内存快很多的**高速缓存**（TLB不是内存！） ， 用来<font color=red>存放最近访问的页表项的副本</font>， 可以加速地址变换的速度。与此对应， **内存中的页表常称为慢表**。


**引入快表后，地址的变换过程**

1. CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较；
1. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。
1. 因此，**若快表命中，则访问某个逻辑地址仅需一次访存即可**。
1. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。
1. 因此，**若快表未命中，则访问某个逻辑地址需要两次访存**（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但**若快表已满，则必须按照一定的算法对旧的页表项进行替换**）。


[http://t.csdnimg.cn/Lfdji](http://t.csdnimg.cn/Lfdji)  
[https://blog.csdn.net/qq_41375318/article/details/102851088](https://blog.csdn.net/qq_41375318/article/details/102851088)

## 11.内存交换和覆盖有什么区别？
**交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中**。 覆盖和交换技术是在多道程序环境下用来扩充内存的两种方法。 覆盖技术主要用在早期的操作系统中，而交换技术则在现代操作系统中仍具有较强的生命力。

1、内存覆盖（Overlay）

在早期的计算机系统中，主存容量很小。虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生。这一矛盾可以用覆盖技术来解决。覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序）， 因此**可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。**  

2、内存交换（Swapping）

交换（对换）的基本思想是：

**把处于等待（阻塞）状态（或在CPU调度原则下被剥夺运行权利）的程序（进程）从内存移到辅存（外存）**，把内存空间腾出来，这一过程又叫换出。把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。中级调度（策略）就是釆用交换技术。

## 12.动态分区分配算法有哪几种?可以分别说说吗?
**1、首次适应算法**

**算法思想**：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。  
**如何实现**：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链（ 或空闲分［表），找到大小能满足要求的第一个空闲分区。

<img src ="http://oss.interviewguide.cn/img/202205220001798.png">

**2、最佳适应算法**

**算法思想**：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。

**如何实现**：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001901.png">

**3、最坏适应算法**

又称最大适应算法（Largest Fit）

**算法思想**：为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

**如何实现**：空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001434.png">

**4、邻近适应算法**

**算法思想**：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

**如何实现**：空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

<img src="http://oss.interviewguide.cn/img/202205220001500.png">


## 13.虚拟技术你了解吗？
虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

**多进程与多线程**：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

**虚拟内存使用了空分复用技术**，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。


## 14.进程状态的切换你知道多少？
<img src="http://oss.interviewguide.cn/img/202205220001439.png">

就绪状态(ready)：等待被调度；  
运行状态(running)；  
阻塞状态(waiting)：等待资源；  

1. **只有就绪态和运行态可以相互转换**，**其它的都是单向转换**。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。

2. **阻塞状态是缺少需要的资源从而由运行状态转换而来**，但是该资源不包括 CPU 时间，缺少 CPU 时间 会从运行态转换为就绪态。

## 15.通过例子讲解逻辑地址转换为物理地址的基本过程？
**逻辑地址（Logical Address）**：在计算机体系结构中是指应用程序角度看到的内存单元（memory cell）、存储单元（storage element）、网络主机（network host）的地址，又叫**相对地址**。 是在网络层及以上使用的地址（ip地址就是其中一种）。  `逻辑地址=页号地址+页内地址`

**物理地址（Physical Address）**：是在存储器里以字节为单位存储信息，为正确地存放或取得信息，每一个字节单元给以一个唯一的存储器地址，又叫实际地址、绝对地址、mac 地址或硬件地址。是在数据链路层和物理层使用的地址。  `物理地址=块号地址+块内地址=块号地址+页内地址`  `块号地址=块号∗块大小`     

<font color = blue> 逻辑地址和物理地址相互转换的本质是块号地址和页号地址的相互转换。</font>

可以借助进程的页表将逻辑地址转换为物理地址

通常会在系统中设置一个**页表寄存器(PTR)**，存放页表在内存中的起始地址 F 和页表长度 M。**进程未执行时，页表的始址和页表长度放在进程控制块(PCB)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。**

<img src="http://oss.interviewguide.cn/img/202205220001941.png">

①计算页号、页内偏移量 页号` P=A/L=2500/1024=2`；页内偏移量    `W= A%L
=2500%1024=452`  ；
②根据题中条件可知，页号 2 没有越界，其存放的内存块号`b=8` ；   
③物理地址 `E=b*L+W=8*1024+425=8644`。

在分页存储管理（页式管理）的系统中，只要确定了每个页面的大小，逻辑地址结构就确定了。因此，**页式管理中地址是一维的**。即，**只要给出一个逻辑地址，系统就可以自动地算出页号、页内偏移量两个部分**，并不需要显式地告诉系统这个逻辑地址中，页内偏移量占多少位。

## 16.进程同步的四种方法？
1. 临界区：为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查；
2. 同步与互斥：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系，多个进程在同一时刻只有一个进程能进入临界区；
3. 信号量：down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断；
4. 管程；

管程的两个主要功能：

- **互斥访问**：管程确保多个线程对共享变量的访问互斥，即同一时间只有一个线程可以访问共享资源，以避免竞态条件和数据不一致性问题。
- **条件等待和通知**：管程提供了等待线程满足特定条件的机制，线程可以通过条件变量等待某个条件满足后再继续执行，或者通过条件变量通知其他线程某个条件已经满足。


管程有一个重要特性：**在一个时刻只能有一个进程使用管程**。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程由以下几个主要部分组成：

- **共享变量**：管程中包含了共享的变量或数据结构，多个线程或进程需要通过管程来访问和修改这些共享资源。
- **互斥锁（Mutex）**：互斥锁是管程中的一个关键组成部分，用于确保在同一时间只有一个线程或进程可以进入管程。一旦一个线程或进程进入管程，其他线程或进程必须等待，直到当前线程或进程退出管程。
- **条件变量（Condition Variables）**：条件变量用于实现线程或进程之间的等待和通知机制。当一个线程或进程需要等待某个条件满足时（比如某个共享资源的状态），它可以通过条件变量进入等待状态。当其他线程或进程满足了这个条件时，它们可以通过条件变量发送信号来唤醒等待的线程或进程。
- **管程接口（对管程进行操作的函数）**：管程还包括了一组操作共享资源的接口或方法。这些接口定义了对共享资源的操作，并且在内部实现中包含了互斥锁和条件变量的管理逻辑。其他线程或进程通过调用这些接口来访问共享资源，从而确保了对共享资源的有序访问。

[http://t.csdnimg.cn/oZeJL](http://t.csdnimg.cn/oZeJL)



## 17.操作系统在对内存进行管理的时候需要做些什么？
- 操作系统负责**内存空间的分配与回收**；
- 操作系统需要提供某种技术**从逻辑上对内存空间进行扩充**；
- 操作系统需要提**地址转换功能**，负责程序的逻辑地址与物理地址的转；
- 操作系统需要提供**内存保护功能**。保证各进程在各自存储空间内运行，互不干扰。


## 18.虚拟内存的目的是什么？
- 第一，虚拟内存可以使得进**程对运行内存超过物理内存大小**，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了**多进程之间地址冲突**的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了**更好的安全性**。
> **局部性原理**是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。


## 19.说一下你理解中的内存?他有什么作用呢？
内存（Memory）是计算机中最重要的部件之一，它是 **程序与CPU进行沟通的桥梁**。计算机中所有程序的运行都是在内存中进行的，因此内存对计算机的影响非常大，内存又被称为**主存**，其作用是**存放 CPU 中的运算数据，以及与硬盘等外部存储设备交换的数据**。只要计算机在运行中，CPU 就会把需要运算的数据调到主存中进行运算，当运算完成后CPU再将结果传送出来，主存的运行也决定了计算机的稳定运行。

## 20.介绍一下几种典型的锁？
**1.读写锁**

- 多个读者可以同时进行读
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）

**2.互斥锁**

- 一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以**互斥锁在加锁操作时涉及上下文的切换**。互斥锁实际的效率还是可以让人接受的，加锁的时间大概 100ns 左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁。

**3.条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而**条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足**，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。**总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制**。

**4.自旋锁**

如果进线程无法取得锁，进线程不会立刻放弃 CPU 时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁那么自旋就是在浪费 CPU 做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。


## 21.操作系统中的逻辑地址和物理地址
- **逻辑地址**  
是在**程序运行时由 CPU 生成的**。逻辑地址是虚拟地址，因为它在物理上不存在，因此也称为虚拟地址。此地址用作 CPU 访问物理内存位置的参考。术语逻辑地址空间用于由程序的角度生成的所有逻辑地址的集合。 内存管理单元的硬件设备用于将逻辑地址映射到其相应的物理地址。
 
- **物理地址**  
 标识内存中所需数据的物理位置。**用户从不直接处理物理地址，但可以通过其对应的逻辑地址进行访问**。用户程序生成逻辑地址，认为程序运行在这个逻辑地址上，但程序需要物理内存来执行，因此，**逻辑地址必须通过MMU映射到物理地址才能使用**。术语物理地址空间用于与逻辑地址空间中的逻辑地址对应的所有物理地址。

## 22.怎么回收线程？有哪几种方法？
线程的资源回收通常包括两个方面：

1. 线程的**内存资源回收**：当一个线程执行完毕或被终止时，系统会自动回收该线程的内存资源，将其占用的内存空间交还给操作系统。
2. 线程的**句柄资源回收**：系统中的每个线程都有一个唯一的线程句柄，用于标识线程、控制线程的执行等。当线程执行完毕或被终止后，需要将其句柄资源回收，以便其他线程可以使用该句柄。


**1.等待线程结束**：`int pthread_join(pthread_t tid, void** retval);`

主线程调用，等待子线程退出并回收其资源，类似于进程中 `wait/waitpid` 回收僵尸进程，调用 `pthread_join` 的线程会被阻塞。   
`tid`：创建线程时通过指针得到 `tid` 值。  
`retval`：指向返回值的指针。

**2.结束线程**：`pthread_exit(void *retval);`

子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过 `pthread_join` 获得。  
`retval`：指向返回值的指针。

**3.分离线程**：`int pthread_detach(pthread_t tid);`

主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中 `pthread_detach(pthread_self())`，调用后和主线程分离，子线程结束时自己立即回收资源。  
`tid`：创建线程时通过指针得到 `tid` 值。

可结合的线程的几种退出方式：

1. 子线程使用 `return` 退出，主线程中使用 `pthread_join` 回收线程；
2. 子线程使用 `pthread_exit` 退出，主线程中使用 `pthread_join` 接收 `pthread_exit` 的返回值，并回收线程；
3. 主线程中调用 `pthread_cancel`，然后调用 `pthread_join` 回收线程；


[http://t.csdnimg.cn/K2B7j](http://t.csdnimg.cn/K2B7j)

## 23.终端退出，终端运行的进程会怎样？
在 linux 上作业的**终端对应了一个 bash 进程，在其上运行的命令和程序都是 bash的子进程，或由bash的子进程衍生**。

在 linux 下，**一个 session 是由一组进程组构成的**，每个进程组又由多个进程构成。
在一个 bash 上运行的程序都归属于一个 session（除非特别处理），而这个 **bash 就是这个 session 的leader**。每个 session 又可以关联一个控制终端（Controlling Terminal）。

终端在退出时会发送 `SIGHUP` 给对应的 `bash` 进程，`bash` 进程收到这个信号后首先将它发给 `session` 下面的进程【bash 在第一次收到 SIGHUP 时先把信号发给 session 内其他进程，然后再次发送SIGHUP命令给自己，将自己杀死】，如果程序没有对 `SIGHUP` 信号做特殊处理，那么进程就会随着终端关闭而退出。

> 在 Linux 系统中，kill -SIGHUP 是发送 SIGHUP 信号给进程的命令。 **SIGHUP 是一种用于通知进程重新读取配置文件或重新加载的信号，通常用于重新启动服务或重新加载配置**。 当进程收到 SIGHUP 信号时，它会尝试重新读取其配置文件或重新加载，以使最新的配置生效。

> Shell session 是终端中当前的状态，在终端中只能有一个 session。当我们打开一个新的终端时，总会创建一个新的 shell session。

[http://t.csdnimg.cn/lLgP4](http://t.csdnimg.cn/lLgP4)  
[https://www.cnblogs.com/sparkdev/p/12146305.html](https://www.cnblogs.com/sparkdev/p/12146305.html)

## 24.如何让进程后台运行？
当我们在终端或控制台工作时，可能不希望由于运行一个作业而占住了屏幕。
为了使这些进程能够在后台运行，也就是说不在终端屏幕上运行，有几种选择方法可供使用：

- **命令后面加上 `&` 即可**，实际上，这样是将命令放入到一个作业队列中了，`e.g. sh test.sh &`；
- **`ctrl + z `命令**：将一个正在前台执行的命令放到后台，并且处于暂停状态；
- `nohup +&`，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断(SIGHUP)信号；
- **运行指令前面 +setsid**，使其父进程编程 init 进程，不受 HUP 信号的影响；
- 将命令`+&`放在 `()` 括号中，也可以是进程不受 HUP 信号的影响；

> 使用 & 命令后，作业被提交到后台运行，当前控制台没有被占用，但是一但把当前控制台关掉(退出帐户时)，作业就会停止运行。nohup 命令可以在你退出帐户之后继续运行相应的进程。nohup 就是不挂起的意思( no hang up / ignoring hangup signals) 即忽略挂起信号一直在后台执行。



**查看后台运行的命令：** `ps` 和 `jobs`。区别在于 `jobs` 只能查看当前终端后台执行的任务，换了终端就看不见了；而 `ps` 命令适用于查看瞬时进程的动态，可以看到别的终端的任务。  

**前后台进程的切换与控制：**  
`fg` 将后台中的命令调至前台继续运行。如果后台中有多个命令，可以用 `fg %jobnumber`（是命令编号，不是进程号）将选中的命令调出；  
`bg`  将一个在后台暂停的命令，变成在后台继续执行。如果后台中有多个命令，可以用`bg %jobnumber`将选中的命令调出。



[https://www.cnblogs.com/FLY_DREAM/p/13881674.html](https://www.cnblogs.com/FLY_DREAM/p/13881674.html)


## 25.守护进程、僵尸进程和孤儿进程？
**1.孤儿进程**  
一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 init 进程(进程号为1)所收养，并由 init 进程对它们完成状态收集工作。  
由于孤儿进程会被 init 进程给收养，所以孤儿进程不会对系统造成危害

**2.僵尸进程**    
一个进程使用 `fork` 创建子进程，如果子进程退出，而父进程并没有调用 `wait` 或 `waitpid` 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

**3.守护进程**  
Linux Daemon（守护进程）是运行在后台的一种特殊进程。它**独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件**。它不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。Linux 系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程 syslogd、 web 服务器 httpd、邮件服务器 sendmail 和数据库服务器 mysqld 等。

**守护进程一般在系统启动时开始运行**，除非强行终止，否则直到系统关机都保持运行。守护进程经常以超级用户（root）权限运行，因为它们要使用特殊的端口（`1-1024`）或访问某些特殊的资源。

**一个守护进程的父进程是 init 进程**，因为它真正的父进程在fork出子进程后就先于子进程 exit 退出了，所以它是一个由 init 继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备 stdout还是标准出错设备stderr的输出都需要特殊处理。

**守护进程的名称通常以d结尾，比如sshd、xinetd、crond等**

**编写守护进程的一般步骤步骤：**  
（1）在父进程中执行 `fork` 并 `exit` 退出；  
（2）在子进程中调用 `setsid` 函数创建新的会话（成长为新的会话与进程组长，与原来的登录会话、进程组和控制终端脱离）；  
（3）在子进程中调用 `chdir` 函数，让根目录 ”`/`” 成为子进程的工作目录（进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录）；  
（4）在子进程中调用 `umask` 函数，设置进程的 `umask` 为 `0`（进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除）；  
（5）在子进程中关闭任何不需要的文件描述符（进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误） 。

**创建守护进程的三种方式**

- 使用nohup命令；
- 使用fork()函数按步骤创建；
- daemon() 函数直接创建守护进程；

[Linux 之守护进程、僵死进程与孤儿进程](https://liubigbin.github.io/2016/03/11/Linux-%E4%B9%8B%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%E3%80%81%E5%83%B5%E6%AD%BB%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/)




## 26.如何避免僵尸进程？
1.在 `fork` 后调用 `wait/waitpid` 函数取得子进程退出状态。

2.调用 `fork` 两次（第一次调用产生一个子进程，第二次调用`fork`是在第一个子进程中调用，同时将父进程退出（第一个子进程退出），此时的第二个子进程的父进程`id`为`init`进程id（注意：新版本Ubuntu并不是init的进程id））。

3.在程序中显示忽略 `SIGCHLD` 信号（子进程退出时会产生一个SIGCHLD信号，我们显示忽略此信号即可）。

4.捕获 `SIGCHLD` 信号并在捕获程序中调用`wait/waitpid`函数。 


[https://www.51cto.com/article/628082.html](https://www.51cto.com/article/628082.html)


## 27.局部性原理你知道吗？主要有哪两大局部性原理?各自是什么？
主要分为**时间局部性**和**空间局部性**。

**时间局部性**：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)；

**空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)。


<img src="http://oss.interviewguide.cn/img/202205212344455.png">

## 28.父进程、子进程、进程组、作业和会话
**1.进程&子进程**

进程是程序的一个具体实现。

**父进程**：已创建一个或多个子进程的进程

**子进程**：由 `fork` 创建的新进程被称为子进程(child process)。该函数被调用一次，但返回两次。两次返回的区别是 **子进程的返回值是 0** ，而 **父进程的返回值则是新进程(子进程)的进程id** 。

将子进程 id 返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程 id。对子进程来说，之所以 fork 返回 0 给它，是因为它随时可以调用`getpid(0)`来获取自己的`pid`；也可以调用`getppid()`来获取父进程的 id。(进程id 0总是由交换进程使用，所以一个子进程的进程 id 不可能为 0)。

fork 之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这 **2 个进程共亨代码空间**，但是**数据空间是互相独立的**，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（**两进程的程序计数器 pc（PC指向的是下一条指令指令） 值相同，也就是说，子进程是从fork返回处开始执行的**），但有一点不同，如果 fork 成功，子进程中fork的返回值是 0，父进程中 fork 的返回值是子进程的进程号，如果 fork 不成功，父进程会返回错误。


**子进程从父进程继承的有：**
1. 进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))；
2. 环境(environment)；
3. 堆栈；
4. 内存；
5. 进程组号；

**独有：**  
1.进程号；  
2.不同的父进程号(即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)；  
3.资源使用(resource utilizations)设定为 0 ；  


**进程组**：进程组就是多个进程的集合，其中肯定有一个组长，其进程 PID等于进程组的 PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关。

**作业**：shell 分前后台来控制的不是进程而是作业(job)或者进程组(Process Group)。一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，shell 可以运行一个前台作业和任意多个后台作业，这称为**作业控制**；

**会话**：会话(Session)是一个或多个进程组的集合。一个会话可以有一个控制终端。在 xshell 或者 WinSCP 中打开一个窗口就是新建一个会话。


## 29.为什么只能运行一个前台作业?
当我们在前台新起了一个作业，shell 就被提到了后台，因此 shell 就没有办法再继续接受我们的指令并且解析运行了。   
但是如果前台进程退出了，shell 就会又被提到前台来，就可以继续接受我们的命令并且解析运行。
  
作业与进程组的区别：如果作业中的某个进程有创建了子进程，则该子进程是不属于该作业的。一旦作业运行结束，shell 就把自己提到前台（子进程还存在，但是子进程不属于作业），如果原来的前台进程还存在（这个子进程还没有终止)，他将自动变为后台进程组）。

## 30.进程终止的几种方式？
1、main函数的自然返回，# return #；   
2、调用 `exit` 函数，属于c的函数库；  
3、调用 `_exit` 函数，属于系统调用；  
4、调用 `abort` 函数，异常程序终止，同时发送 `SIGABRT` 信号给调用进程；   
5、接受能导致进程终止的信号：`ctrl+c`(^C)、SIGINT(SIGINT中断进程)


## 31.Linux中异常和中断的区别？
- **异常**又叫同步中断，是当指令执行时由cpu控制单元产生的，之所以称之为异常，是因为只有在一条指令结束之后才发出中断（程序执行异常或者系统调用）。
- **中断**又叫异步中断，是由其他硬件设备依照 cpu 时钟信号随机产生的。

相同点：

- 最后都是由CPU发送给内核，由内核去处理；
- 处理程序的流程设计上是相似的；

不同点：

- 产生源不相同，异常是由 CPU 产生的，而中断主要是由硬件设备产生的；
- 内核需要根据是异常还是中断调用不同的处理程序；
- 中断不是时钟同步的，这意味着中断可能随时到来，异常由于是CPU产生的，所以它是时钟同步的；
- 当处理中断时，处于中断上下文中，处理异常时，处于进程上下文中。



[https://www.cnblogs.com/charlesblc/p/6261741.html](https://www.cnblogs.com/charlesblc/p/6261741.html)

## 32.内存分布情况
操作系统下：
<img src="http://inews.gtimg.com/newsapp_bt/0/14071993259/640">

C++ 下：
<img src="https://i-blog.csdnimg.cn/blog_migrate/b5bf86b2742e773db67fd03d0c16d5e2.png">

- Windows系统中，栈的大小被记录在可执行文件中，**由编译器设置决定**，VS2013中栈大小理默认为1M。
- linux系统中，栈大小不是由编译器决定，而是**由操作系统决定**，栈大小默认为8M。`ulimit -s`


## 33.程序从堆中动态分配内存时，虚拟内存上怎么操作的？
**页表**：是一个存放在物理内存中的数据结构，它记录了虚拟页与物理页的映射关系；

在进行动态内存分配时，例如`malloc()`函数或者其他高级语言中的 `new` 关键字，操作系统会在硬盘中创建或申请一段虚拟内存空间，并更新到页表（分配一个页表条目（PTE），使该PTE指向硬盘上这个新创建的虚拟页），通过 PTE建立虚拟页和物理页的映射关系。


## 34.常见的几种磁盘调度算法
读写一个磁盘块的时间的影响因素有：

- 旋转时间(主轴转动盘面，使得磁头移动到适当的扇区上)；
- 寻道时间(制动手臂移动，使得磁头移动到适当的磁道上)；
- 实际的数据传输时间；


其中，寻道时间最长，因此**磁盘调度的主要目标是使磁盘的平均寻道时间最短**。



**1、先来先服务（FCFS）**  
先来先服务（First-Come, First-Served） 磁盘调度算法按照请求的顺序依次处理。它简单易实现，但可能导致磁头在磁盘上移动的距离较大，效率不高。

**2、最短寻道时间优先（SSTF）**  
最短寻道时间优先（Shortest Seek Time First） 算法选择离磁头当前位置最近的请求进行处理。这可以最大程度地减少寻道时间，但可能导致某些请求长时间等待。

**3、电梯算法**  
电梯算法 包括 SCAN 和 C-SCAN 两种变种。  
SCAN 算法从当前位置向某个方向移动，直到最远的请求为止，然后改变方向。  
C-SCAN 算法类似，但在到达磁盘末端后立即返回到磁盘的起始位置。这些算法能够平衡请求的等待时间，但可能会导致某些请求长时间等待。

**4、LOOK和C-LOOK**  
LOOK 和 C-LOOK 是电梯算法的改进版本，它们不会在到达磁盘末端时立即返回，而是根据需要调整方向。这可以减少一些请求的等待时间，提高了效率。

头部从一个方向的第一个请求开始，向另一端的最后一个请求移动，为中间的所有请求服务。在到达一端的最后一个请求后，头部跳到另一个方向，并向剩余的请求移动，然后像以前一样满足它们。**与C-SCAN不同，磁头指针将移动到磁盘的最后一个请求**。

## 35.交换空间与虚拟内存的关系？
Linux 中的 **交换空间** （Swap space）在物理内存（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。

交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。

**交换空间的总大小应该相当于你的计算机内存的两倍**和 32 MB这两个值中较大的一个，但是它不能超过 2048 MB（2 GB）。



**虚拟内存** 是文件数据交叉链接的活动文件。是 WINDOWS目录下的一个"WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。

就速度方面而言，CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是虚拟内存使用的是硬盘的空间，为什么我们要使用速度最慢的硬盘来做为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。

**交换空间与虚拟内存区别**

一、主体不同

1、交换空间：存在于数据服务器上的一个共享文件夹。  
2、虚拟内存：是计算机系统内存管理的一种技术。

二、作用不同

1、交换空间：作用是为前台与后台数据交换提供一个场所。  
2、虚拟内存：使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

三、特点不同

1、交换空间：挂载交换区空间的情形有两种系统内存不足，特殊应用程序的需求，如 oracle、lotus notes 等。  
2、虚拟内存：将逻辑和物理地址空间都分成固定大小的页。主存按页顺序编号，而每个独立编址的程序空间有自己的页号顺序，通过调度辅存中程序的各页可以离散装入主存中不同的页面位置。

<font color = red>对于'虚拟内存'有两种理解：

1. Linux中的内存管理机制；
2. Windows上的虚拟内存，类似Linux下的内存交换分区；

</font>


## 36.抖动你知道是什么吗？它也叫颠簸现象
颠簸（thrashing）又称“抖动”，是指页面在内存与外存储器之间频繁地调度，以致系统用于调度页面的时间比进程实际运行所占用的时间还要长。

颠簸是由于页故障率过高而产生的结果（**主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)**），它将严重地影响系统的效率，甚至可能使系统全面崩溃。
通俗来讲就是一个进程的页面放入内存中，被淘汰出去后，进程又需要使用这个页面然后重新把他放入内存的过程。即你把我赶走之后，又叫我回来。

## 37.从堆和栈上建立对象哪个快？(考察堆和栈的分配效率比较)
**栈对象**

- 在适当的时候自动生成，又在适当的时候自动销毁，不需要程序员操心；
- 栈对象的创建速度一般较堆对象快，因为分配堆对象时，会调用operator new操作，operator new 会采用某种内存空间搜索算法，而该搜索过程可能是很费时间的，产生栈对象则没有这么麻烦，它仅仅需要移动栈顶指针就可以了。但是要注意的是，通常栈空间容量比较小，一般是1MB～2MB，所以体积比较大的对象不适合在栈中分配。
- 特别要注意递归函数中最好不要使用栈对象，因为随着递归调用深度的增加，所需的栈空间也会线性增加，当所需栈空间不够时，便会导致栈溢出，这样就会产生运行时错误。

**堆对象**

- 其产生时刻和销毁时刻都要程序员精确定义，也就是说，程序员对堆对象的生命具有完全的控制权。我们常常需要这样的对象，比如，我们需要创建一个对象，能够被多个函数所访问，但是又不想使其成为全局的，那么这个时候创建一个堆对象无疑是良好的选择，然后在各个函数之间传递这个堆对象的指针，便可以实现对该对象的共享。
- 相比于栈空间，堆的容量要大得多。实际上，当物理内存不够时，如果这时还需要生成新的堆对象，通常不会产生运行时错误，而是系统会使用虚拟内存来扩展实际的物理内存。



**分配和释放**，堆在分配和释放时都要调用函数(malloc,free)，比如分配时会到堆空间去**寻找足够大小的空间**（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。


**访问时间**，**访问堆的一个具体单元，需要两次访问内存**，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

## 38.常见内存分配方式有哪些？
**静态内存分配**：

- 静态内存分配是在程序**编译阶段**完成的，使得内存分配在程序运行期间保持不变；
- 静态内存分配使用**全局变量或静态变量**来分配内存空间；
- 内存分配在程序的数据段或全局内存中，会一直**保持**分配的内存空间直至程序退出；
- 内存大小是在编译时**确定的**，无法在运行时动态改变。


**栈内存分配**：

- 栈内存分配是由编译器**自动**进行的，用于存储函数的局部变量和函数调用信息；
- 使用栈来管理内存分配，分配和释放内存的速度非常快；
- 内存大小是在**编译时确定**的，不能在运行时动态改变；
- 栈内存分配的**生命周期与其所在的函数相对应**，在函数执行完毕后，内存会自动释放。


堆内存分配：

- 堆内存**分配是在运行时动态进行**的，用于存储动态分配的内存块。
- 使用堆来管理内存分配，通过函数如 malloc 和 free 或 new 和 delete 进行操作。
- 内存大小**可以在运行时动态改变**，可以根据需要分配和释放内存。
- 堆内存分配**需要手动管理**内存的分配和释放，避免出现内存泄漏或悬挂指针等问题。
- 堆内存分配的生命周期由程序员控制，需要显式地释放已分配的内存。


## 39.常见内存分配内存错误
（1）**内存分配未成功，却使用了它**。

常用解决办法是，在使用内存之前检查指针是否为 `NULL`。如果指针p是函数的参数，那么在函数的入口处用 `assert(p!=NULL) `进行检查。如果是用 `malloc` 或 `new` 来申请内存，应该用`if(p==NULL)` 或 `if(p!=NULL)` 进行防错处理。

（2）**内存分配虽然成功，但是尚未初始化就引用它**。

（3）**内存分配成功并且已经初始化，但操作越过了内存的边界**。

（4）**忘记了程放内存，造成内存泄露**。

含有这种错误的函数每被调用一次就丢失一块内存了。动态内存的申请与释放必须配对，程序中 `malloc` 与 `free` 的使用次数一定要相同，否则肯定有错误( `new/delete` 同理）。

（5）释放了内存却继续使用它。

## 40.ASCIl、Unicode和UTF-8编码的区别？

**ASCII编码**

ASCII 码使用指定的 7 位或 8 位二进制数组合来表示 128 或 256 种可能的字符。标准 ASCII 码也叫基础 ASCII 码，使用 7 位二进制数（剩下的1位二进制为0）来表示所有的大写和小写字母，数字 0  到 9、标点符号， 以及在美式英语中使用的特殊控制字符。其中最后一位用于奇偶校验。

问题：ASCII 是单字节编码，无法用来表示中文（**中文编码至少需要2个字节**），所以，中国制定了GB2312编码，用来把中文编进去。但世界上有许多不同的语言，所以需要一种统一的编码。

**Unicode**

Unicode 把所有语言都统一到一套编码里，这样就不会再有乱码问题了。
Unicode 最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要 4 个字节）。现代操作系统和大多数编程语言都直接支持 Unicode。


**UTF8**

所以，本着节约的精神，又出现了把 Unicode 编码转化为“可变长编码”的 UTF-8 编码。  

UTF-8 编码把一个 Unicode 字符根据不同的数字大小编码成 1-6 个字节，常用的英文字母被编码成 1 个字节，汉字通常是 3 个字节，只有很生僻的字符才会被编码成 4-6 个字节。如果你要传输的文本包含大量英文字符，用 UTF-8 编码就能节省空间。  

UTF-8 编码有一个额外的好处，就是 ASCII 编码实际上可以被看成是 UTF-8 编码的一部分，所以，大量只支持 ASCII 编码的历史遗留软件可以在 UTF-8 编码下继续工作。


<font color=blue>

- 在计算机内存中，统一使用 Unicode 编码，当需要保存到硬盘或者需要传输的时候，就转换为 UTF-8 编码。
-  用记事本编辑的时候，从文件读取的 UTF-8 字符被转换为 Unicode 字符到内存里，编辑完成后，保存的时候再把 Unicode 转换为 UTF-8 保存到文件。
- 浏览网页的时候，服务器会把动态生成的 Unicode 内容转换为 UTF-8 再传输到浏览器。

</font>

<img src="https://ask.qcloudimg.com/http-save/1692602/zs2m48pymr.png">
<img src = "https://ask.qcloudimg.com/http-save/1692602/zxks1cbo4v.png">

[https://cloud.tencent.com/developer/article/1441294](https://cloud.tencent.com/developer/article/1441294)

## 41.原子操作的是如何实现的
原子操作（atomic operation）指的是由多步操作组成的一个操作。如果该操作不能原子地执行，则**要么执行完所有步骤，要么一步也不执行**，不可能只执行所有步骤的一个子集。

在单核环境中，一般的意义下原子操作中线程不会被切换，线程切换要么在原子操作之前，要么在原子操作完成之后。更广泛的意义下原子操作是指一系列必须整体完成的操作步骤，如果任何一步操作没有完成，那么所有完成的步骤都必须回滚，这样就可以保证要么所有操作步骤都未完成，要么所有操作步骤都被完成。

- 在单核系统里，**单个的机器指令可以看成是原子操作**（如果有编译器优化、乱序执行等情况除外）；
- 在多核系统中，单个的机器指令就不是原子操作，因为多核系统里是多指令流并行运行的，一个核在执行一个指令时，其他核同时执行的指令有可能操作同一块内存区域，从而出现数据竞争现象。多核系统中的原子操作通常使用 **内存栅障（memory barrier）** 来实现，即**一个CPU核在执行原子操作时，其他 CPU 核必须停止对内存操作或者不对指定的内存进行操作**，这样才能避免数据竞争问题。

**原子操作的底层实现**

**1. 总线加锁**
所谓总线锁就是使用处理器提供的一个 `lock#` 信号，**当一个处理器在总线上输出此信号时，其他处理器的请求会被阻塞住**，那么该处理器可以独占共享内存。  
但总线锁定把 cpu 和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以开销比较大。

**2.缓存加锁**
通过缓存锁定来保证原子性。在同一时刻，我们只需**保证对某个内存地址的操作是原子性即可**，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。  
所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在 `Lock` 操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言`LOCK#`信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为 **缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据** ，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。


有两种情况下处理器不会使用缓存锁定。

1. 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。
1. 第二种情况是：有些处理器不支持缓存锁定。对于 Intel 486 和 Pentium 处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。


**编程使用**  
（1）GCC编译器提供的原子操作 API： ` type __sync_fetch_and_add (type *ptr, type value); `还有很多；  
（2）C++11提供的原子操作：C++11中在<atomic>中定义了 `atomic` 模板类，`atomic` 的模板参数类型可以为`int、long、bool`等等，C++ 中称为 trivially copyable type。atomic_int、atomic_long 为 atomic 模板实例化后的宏定义；  

[http://t.csdnimg.cn/vs2Gz](http://t.csdnimg.cn/vs2Gz)


## 42.页面置换算法？
访问的页面不在内存中时，会发生一个缺页异常，操作系统必须将该页换入内存，如果此时内存已满，则操作系统必须将其中一个页面换出，放到 swap 交换区中，**为当前访问的页面腾出空间**，这个过程称为页面置换。操作系统提供了多种页面置换算法：

**1.最优页面置换算法**

选择一个将来最长时间不会被访问的页面换出。这样可以保证将来最低的缺页率。这是一种理论上的算法，因为无法知道哪个页面是将来最长时间都不会被访问的。

**2.最近未使用页面置换算法 (NRU)**

为每个页面设两个状态位：被访问时设置为 R=1 位，页面被修改时，设置为 M=1 位。当启动一个进程时，所有页面都被初始化为 R=0，M=0。其中 R 位会被定时的清 0，以此区分最近被访问的页面和没有被访问的页面。

于是所有页面可以分为以下 4 类：

- 0 类：R=0，M=0；
- 1 类：R=0，M=1；
- 2 类：R=1，M=0；
- 3 类：R=1，M=1；

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出（挑选优先级：1 类 > 2 类 > 3 类）。

**3.最近最少未使用（LRU）页面置换算法**

在内存中维护一个所有页面的单链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**4.先进先出（FIFO）页面置换算法**

维护一个链表，最先进入的页面放在表头，最后进入的页面放在表尾，当缺页中断发生时，直接淘汰表头的页面，并把新的页面放在表尾。

这种算法有可能置换掉经常访问的页面，导致缺页率升高。

**5.第二次机会页面置换算法**

对 FIFO 算法做一个修改：取出表头的页面时，检查该页面的 R 位，如果是 1 表示是最近有访问的，将其清 0，然后放入表尾，然后继续检查下一个表头的页面，直到遇到一个 R 位为 0 的页面，将其换出。

**6.时钟页面置换算法**

单链表改成了环形链表，形成一个时钟，移动的也不是页面，而是中间的表针。检查页面逻辑类似，如果该页面 R 为 0，则直接置换该页面，否则将该 R 位清 0，然后表针向前移动。


[https://www.cnblogs.com/Leophen/p/11397699.html](https://www.cnblogs.com/Leophen/p/11397699.html)

[https://xiaolincoding.com/os/5_schedule/schedule.html#%E6%9C%80%E4%BD%B3%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95](https://xiaolincoding.com/os/5_schedule/schedule.html#%E6%9C%80%E4%BD%B3%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95)


## 43.内存碎片之外部碎片与内部碎片
“内存碎片”描述了一个**系统中所有不可用的空闲内存**。这些资源之所以仍然未被使用，是因为负责分配内存的分配器使这些内存无法使用**，原因在于空闲内存以小而不连续方式出现在不同的位置，内存分配器无法将这些内存利用起来分配给新的进程**。由于分配方法决定内存碎片是否是一个问题，因此内存分配器在保证空闲资源可用性方面扮演着重要的角色。


**内部碎片** 是由于 **系统分配给进程的空间大于其所申请的大小** ，处于（操作系统分配的用于装载某一进程的内存）区域内部或页面内部的存储块， **占有这些区域或页面的进程并不使用这个存储块**。而在进程占有这块存储块时，系统无法利用它。**直到进程释放它**，或进程结束时，系统才有可能利用这个存储块。

**外部碎片** 指的是**还没有被分配出去**（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域，即 **处于任何两个已分配区域或页面之间的空闲存储块**。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。


分段式分配是按需分配，而固定式分配是固定分配的方式。
[https://jacktang816.github.io/post/memoryfragmentation/](https://jacktang816.github.io/post/memoryfragmentation/)

## 44.服务器高并发的解决方案你知道多少？
- **应用数据与静态资源分离** 将静态资源(图片，视频,js，css等)单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。
- **客户端缓存** 因为效率最高，消耗资源最小的就是纯静态的 html 页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用 ajax 异步请求获取动态数据。
- **集群和分布式**（集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用）（分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度)  
可以使用服务器集群和分布式架构，使得原本属于一个服务器的计算压力分散到多个服务器上。同时加快请求处理的速度。
- **反向代理** 在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端。


# 计算机网络

## 1.说一下一次完整的HTTP请求过程包括哪些内容？
- 使用 DNS 域名解析；
- 发起 TCP 的 3 次握手
- 建立TCP连接后发起http请求；
- 服务器响应 http 请求，浏览器得到返回 response；
- 浏览器解析 response，并请求其它的资源（如js、css、图片等）；
- 浏览器对页面进行渲染。

## 2.DNS是什么？工作原理？
官方解释：DNS（Domain Name System，域名系统），因特网上作为**域名和 IP 地址相互映射的一个分布式数据库**能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。
通过主机名，最终得到该主机名对应的 IP 地址的过程叫做域名解析(或主机名解析)。
通俗的讲，我们更习惯于记住一个网站的名字，比如www.baidu.com，而不是记住它的 ip 地址，比如:167.23.10.2；(**方便记忆：IP地址是面向主机的，而域名则是面向用户的**)

将主机域名转换为 ip 地址，属于**应用层协议，使用UDP传输**。


过程：

（1）当用户在浏览器中输入 www.qq.com 域名访问该网站时，操作系统 **会先检查自己本地的 hosts 文件是否有这个网址映射关系** ，如果有，就先调用这个IP地址映射，完成域名解析。   
（2）如果 hosts 里没有这个域名的映射，则**查找本地 DNS 解析器缓存**，是否有这个网址映射关系，如果有，直接返回，完成域名解析。   
（3）如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找 TCP/ip 参数中设置的首选 DNS 服务器，在此我们叫它 **本地 DNS 服务器** ，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。   
（4）如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已**缓存了此网址映射关系**，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。     
（5）如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（**是否设置转发器**）进行查询，如果未用转发模式，本地DNS就把请求发至 13 台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责 .com 域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理 .com 域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到www.qq.com 主机。   
（6）如果用的是转发模式， **此DNS服务器就会把请求转发至上一级DNS服务器** ，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

提示：从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间的交互查询就是迭代查询。

**域名解析总体可分为以下下过程：**  
(1) 输入域名后，先查找自己主机对应的域名服务器，域名服务器先查找自己的数据库中的数据；  
(2) 如果没有，就向上级域名服务器进行查找， 依次类推；  
(3) 最多回溯到根域名服务器，肯定能找到这个域名的 IP 地址；  
(4) 域名服务器自身也会进行一些缓存， 把曾经访问过的域名和对应的IP地址缓存起来，可以加速查找过程。  

**具体可描述如下：**

1. 主机先向本地域名服务器进行递归查询；
2. 本地域名服务器采用迭代查询，向一个根域名服务器进行查询；
3. 根域名服务器告诉本地域名服务器，下一次应该查询的顶级域名服务器的 IP 地址；
4. 本地域名服务器向顶级域名服务器进行查询；
5. 顶级域名服务器告诉本地域名服务器，下一步查询权限服务器的 IP 地址；
6. 本地域名服务器向权限服务器进行查询；
7. 权限服务器告诉本地域名服务器所查询的主机的IP地址；
8. 本地域名服务器最后把查询结果告诉主机。

<img src="https://i-blog.csdnimg.cn/blog_migrate/a73040d92f51a8c741b1b6f6a6d841c6.png">


[https://blog.csdn.net/mocas_wang/article/details/109167660](https://blog.csdn.net/mocas_wang/article/details/109167660)


## 3.DNS为什么既使用TCP又使用UDP？为什么域名解析用UDP协议？为什么区域传送用TCP协议?
DNS的规范规定了2种类型的DNS服务器，一个叫 **主DNS服务器**，一个叫 **辅助DNS服务器**。在一个区中主 DNS 服务器从自己本机的数据文件中读取该区的 DNS 数据信息，而辅助 DNS 服务器则从区的主DNS服务器中读取该区的 DNS 数据信息。当一个辅助 DNS 服务器启动时，它需要与主 DNS 服务器通信，并加载数据信息，这就叫做 **区传送（zone transfer）** 。

**域名解析时使用UDP协议：**

客户端向DNS服务器查询域名，一般返回的内容都**不超过512字节**，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器**负载更低**，响应更快。虽然从理论上说，客户端也可以指定向 DNS 服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持 UDP 查询包。

**区域传送时使用TCP**，主要有一下两点考虑：

- 辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。
- TCP是一种可靠的连接，保证了数据的准确性。

[为什么DNS既使用TCP又使用UDP？](https://scoolor.github.io/2018/11/10/dns-udp-tcp/#%E4%B8%BA%E4%BB%80%E4%B9%88DNS%E6%97%A2%E4%BD%BF%E7%94%A8TCP%E5%8F%88%E4%BD%BF%E7%94%A8UDP%EF%BC%9F)

## 4. HTTP 长连接和短连接的区别？
**长连接**：长连接，指在一个连接上可以连续发送多个数据包，在连接保持期间，如果没有数据包发送，需要双方发链路检测包（TCP 保活机制）。

**短连接**：短连接（short connnection）是相对于长连接而言的概念，指的是在数据传送过程中，只在需要发送数据时，才去建立一个连接，数据发送完成后，则断开此连接，即每次连接只完成一项业务的发送。

在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器**每进行一次 HTTP 操作，就建立一次连接**，任务结束就中断连接。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

## 5.什么是 TCP 粘包/拆包？发生的原因？
**粘包**：指TCP协议中，发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

> 为什么UDP没有粘包？  
> 粘包拆包问题在数**据链路层、网络层以及传输层都有可能发生**。日常的网络应用开发大都在传输层进行，由于UDP有消息保护边界，不会发生粘包拆包问题，因此粘包拆包问题只发生在TCP协议中。


因为 TCP 是面向流，没有边界，而操作系统在发送TCP数据时，会通过缓冲区来进行优化，例如缓冲区为1024个字节大小。

- 如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP则会**将多个请求合并为同一个请求**进行发送，这就形成了粘包问题。
- 如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP就会将其**拆分为多次发送**，这就是拆包。

原因  
1、应用程序写入数据的字节大小**大于**套接字发送缓冲区的大小；  
2、进行 MSS 大小的 TCP 分段。( `MSS = TCP报文段长度 - TCP首部长度`）；  
3、以太网的 payload 大于 MTU 进行 IP 分片。(MTU指：一种通信协议的某一层上面所能通过的最大数据包大小）

出现粘包的一些可能：

- 由TCP连接复用造成的粘包问题；
- 因为TCP默认会使用Nagle算法，此算法会导致粘包问题只有上一个分组得到确认，才会发送下一个分组；收集多个小分组，在一个确认到来时一起发送。
- 数据包过大造成的粘包问题；
- 流量控制，拥塞控制也可能导致粘包；
- **接收方不及时接收缓冲区的包，造成多个包接收**

**解决方案**  

1. 发送端将每个包都封装成固定的长度，比如100字节大小。如果不足100字节可通过补0或空等进行填充到指定长度；
1. 发送端在每个包的末尾使用固定的分隔符，例如\r\n。如果发生拆包需等待多个包发送过来之后再找到其中的\r\n进行合并；例如，FTP协议；
1. 将消息分为头部和消息体，头部中保存整个消息的长度，只有读取到足够长度的消息之后才算是读到了一个完整的消息；
1. 通过自定义协议进行粘包和拆包的处理。使用其它复杂的协议，如 RTMP 协议等。

[https://cloud.tencent.com/developer/article/1804413](https://cloud.tencent.com/developer/article/1804413)

## 6.为什么服务器会缓存这一项功能？如何实现的？
原因

- 缓解服务器压力；
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

实现方法  

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存。


**正向代理**：如果把局域网的Internet想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。在客户端（浏览器）配置代理服务，通过代理服务器进行**互联网访问**。
<img src = "https://i-blog.csdnimg.cn/blog_migrate/547de65ebbe20f037da0d232a227ecfe.png">

**反向代理**：其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。
<img src = "https://i-blog.csdnimg.cn/blog_migrate/0e85cb8d88d0caa7e21ff42695799b76.png">

- 正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端；
- 反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端；

> **反向代理服务器**架设在服务器端，通过**缓存经常被请求的页面**来缓解服务器（如Web服务器）的工作量。安装反向代理服务器有几个原因：

>1. 负载平衡
1. 缓存静态内容
1. 压缩数据
1. 外网发布


[缓存问题](http://t.csdnimg.cn/2S3VF)  
[Nigix](http://t.csdnimg.cn/RytbI)

## 7.GET 和 POST 的区别，你知道哪些？
<font color = blue> **GET 和 POST 本质上就是 TCP 链接，并无差别**。但是由于 HTTP 的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。</font>

**最直观的区别**就是 GET 把参数包含在 URL 中，POST 通过 request body 传递参数（相对安全）。

- get是 获取数据，post 是修改数据；
- get 提交的数据最大是2k（限制实际上取决于浏览器），post理论上没有限制；
- GET 请求会被浏览器主动缓存，而 POS T不会，除非手动设置；
- 本质区别：GET 是幂等的（只读），而 POST 不是幂等的（新增或提交数据）；
> 幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。

GET和POST还有一个重大区别：**GET产生一个TCP数据包；POST产生两个TCP数据包**。

- 对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；
- 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应 200 ok（返回数据）。


## 8.一个TCP连接可以发送多少个HTTP请求？
默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接【长连接】。

如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

- 在 HTTP/1.1 存在 管道（ pipeline） 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。【因为服务器必须按照接收请求的顺序发送对这些管道化请求的响应，如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「**队头堵塞**」】；
- 在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。【多个 Stream 复用在一条 TCP 连接，针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，**当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据（队头阻塞）。一个包丢失，所有的请求都必须等这个包重传**】


那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

- 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求；
- 和服务器建立多个 TCP 连接；

## 9.DNS负载均衡是什么策略？
当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，**DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果**，**将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器**，从而达到负载均衡的目的，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

## 10.传输过中如何保证 数据既能不被篡改，又能不被窃取？
公加私解，私加公解

- 公钥加密私钥解密，只能保证数据不会篡改，但是可以被窃取；
- 私钥加密公钥解密，只能保证数据不会窃取，但是可能被整个替换；

签名和信封

- 数据取摘要，然后私钥加密这种做法可以加快速度，保证数据不被篡改，这种方式叫做签名；
- 数据对称加密，然后公钥加密对称加密密钥，密钥保证数据安全，公钥加密保证密钥不会窃取，公钥加密密钥比直接加密数据快，这种方式叫做信封；

> 一个数字证书通常包含了：
> 
- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份文件的数字签名及使用的算法；
- 证书有效期；
- 还有一些其他额外信息；
- <font color = blue>数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充（**服务端是否是合法的**）。</font>

[https://www.cnblogs.com/cxygg/p/17725826.html](https://www.cnblogs.com/cxygg/p/17725826.html)


## 11.HTTP请求和响应报文有哪些主要字段？

**1. 请求报文**

客户端发送一个请求报文给服务器，**服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端**。

请求报文结构：

- 第一行是包含了请求方法、URL、协议版本（请求行）；
- 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值（请求头）；
- 一个空行用来分隔首部和内容主体 Body；
- 最后是请求的内容主体。


**2.响应报文**

响应报文结构：

- 第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了（相应行）；
- 接下来多行也是首部内容（响应头）；
- 一个空行分隔首部和内容主体；
- 最后是响应的内容主体。

[https://blog.csdn.net/weixin_43901865/article/details/112908748](https://blog.csdn.net/weixin_43901865/article/details/112908748)

## 12.Cookie是什么？
HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1引入 Cookie 来保存状态信息。

**Cookie 是服务器发送到用户浏览器并保存在本地**的一小块数据，它会在浏览器之后向同一服务器再次发起清求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销(尤其是在移动环境下)。

cookie 的作用就好比服务器给你贴个标签，然后每次向服务器再发请求时，服务器就能够 cookie 认出你。


**Cookie的生命周期：**
cookie 有 2 种存储方式，一种是会话性，一种是持久性。

- **会话性**：如果 cookie 为会话性，那么 cookie 仅会保存在客户端的内存中，当我们关闭客服端时 cookie 也就失效了
- **持久性**：如果 cookie 为持久性，那么 cookie 会保存在用户的硬盘中，直至生存期结束或者用户主动将其销毁。

**用途：**

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）；
- 个性化设置（如用户自定义设置、主题等）；
- 浏览器行为跟踪（如跟踪分析用户行为等）。


## 13.什么是 session？
在Web中，Session是**指一个用户与网站服务器进行一系列交互的持续时间**，通常指从注册进入系统到注销退出系统之间所经过的时间，以及在这段时间内进行的操作，还有，服务器端为保存用户状态开辟的存储空间。

- Session 就一个接口（HttpSession）。
- Session 就是会话。它是用来维护一个客户端和服务器之间关联的一种技术。
- 每个客户端都有自己的一个 Session 会话。
- Session 会话中，我们经常用来保存用户登录之后的信息。

**工作原理**：session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 session 的 id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid 之后，在内存找到与之对应的 session 这样就可以正常工作了。

http 协议只完成请求和响应的工作，不能记录用户状态，服务器为了记录用户状态，跟踪用户行为，从而提供个性化服务而引入 session，用户的一系列交互行为都包含在 session 内，用户状态信息也存储在服务器端为 session 开辟的一个存储空间内；当用户通过浏览器发送一系列 http 请求时，为了识别这些请求属于哪个 session，服务端需要给每个 session 一个 sessionID，cookie 就是浏览器端用来存储和发送这个 sessionID 的。

[https://github.com/frmachao/frmachao.github.io/issues/2](https://github.com/frmachao/frmachao.github.io/issues/2)  
[http://t.csdnimg.cn/Te9Pi](http://t.csdnimg.cn/Te9Pi)


## 14.什么是 token？
**Token** 是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个 Token 便将此 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次带上用户名和密码。

**用途**：使用token机制的身份验证方法，在服务器端不需要存储用户的登录记录。

大概的流程：

1. 客户端使用用户名和密码请求登录。
1. 服务端收到请求，验证用户名和密码。
1. 验证成功后，服务端会生成一个token，然后把这个token发送给客户端。
1. 客户端收到token后把它存储起来，可以放在 cookie 或者 Local Storage （本地存储）里。
1. 客户端每次向服务端发送请求的时候都需要带上服务端发给的 token。
1. 服务端收到请求，然后去验证客户端请求里面带着 token，如果验证成功，就向客户端返回请求的数据。

[http://t.csdnimg.cn/36YEI](http://t.csdnimg.cn/36YEI)

## 15.Session 、Cookie和Token三者的关系和区别
- Cookie 是浏览器用来保存用户信息的文件，可以保存比如用户是谁，购物车有哪些商品等，是**客户端保持状态**的方法。；
- Session 是一次会话，会话是指我们访问网站的一个周期，是**服务器保持状态**的方法。；
- token 是服务器返回的一个临时签名数据，可以使用这个签名数据表面用户身份。

 都是一个目的，服务器需要知道和自己通话的人是谁，就是 <font color = blue>**服务器需要用某种机制来识别具体的用户**。</font>

这要从HTTP协议开始说起，HTTP协议是**无状态的协议**。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话，自然无法识别用户，所以诞生了Cookie，session 和 token。

> Cookie 简单的理解就是存储**由服务器发至客户端并由客户端保存的一段字符串**。为了保持会话，服务器可以在响应客户端请求时将 Cookie 字符串放在 Set-Cookie 下，客户机收到 Cookie 之后保存这段字符串，之后再请求时候带上Cookie 就可以被识别。
> 
> **Session 保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的 Session 用户在客户端上记录用户的操作**。可以理解为每个用户有一个独一无二的 SessionID 作为 Session 文件的 Hash 键，通过这个值可以锁定具体的 Session 结构的数据，这个 Session 结构中存储了用户操作行为。

<img src="https://upload-images.jianshu.io/upload_images/1500839-a5a19abfc7488c8d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/700">




## 16.什么是 SQL 注入 (SQi)？
结构化查询语言 (SQL*) 注入是一种代码注入技术，用于修改或从 SQL 数据库检索数据。 **通过在输入字段中插入专用的 SQL 语句，攻击者可以执行命令，以允许从数据库中检索数据、破坏敏感数据或执行其他操纵行为** 。

通过正确执行 SQL 命令，未经授权的用户可以伪造特权更高的用户的身份，使自己或其他人成为数据库管理员，篡改现有数据、修改事务和余额以及检索和/或销毁所有服务器数据。

本质上：本应为特定类型的数据（例如数字）保留的 SQL 查询字段传递了意外的信息（例如命令）。该命令在运行时越过预期的范围，从而允许可能有害的行为。查询字段通常由在网页上输入表单的数据填充。

[https://www.cloudflare.com/zh-cn/learning/security/threats/sql-injection/](https://www.cloudflare.com/zh-cn/learning/security/threats/sql-injection/)

## 17.什么是RARP？工作原理？

1、定义：  
概括： 反向地址转换协议，网络层协议，RARP 与 ARP 工作方式相反。 RARP使**只知道自己硬件地址的主机能够知道其IP地址**。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。

2、原理：  
（1）网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的 MAC 地址。主机从网卡上读取 MAC 地址，然后**在网络上发送一个 RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址**。  
（2）RARP 服务器收到了 RARP 请求数据包，**为其分配 IP 地址，并将RARP回应发送给主机**。  
（3）PC1 收到 RARP 回应后，就使用得到的 IP 地址进行通讯。

## 18.端口有效范围是多少到多少？
`0-1023` 为知名端口号，比如其中 HTTP 是80（HTTPS:443），FTP是20(数据端口)、21(控制端口)

UDP 和 TCP 报头使用两个字节存放端口号，所以端口号的有效范围是从 0 到 65535。动态端口的范围是从 1024 到 65535。

## 19.为何需要把 TCP/IP 协议栈分成5 层（或7层）？开放式回答。
分层的好处：  
①各层之间是独立的；  
②灵活性好；  
③结构上可以分隔开；  
④易于实现和维护；  
⑤能促进标准化工作。

<img src="http://oss.interviewguide.cn/img/202205072300887.png">

## 20.DNS查询方式有哪些？
**当局部 DNS 服务器自己不能回答客户机的 DNS 查询时，它就需要向其他 DNS 服务器进行查询**。

**1.递归解析**   

**局部 DNS 服务器自己负责向其他 DNS 服务器进行查询**，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询。最后得到的查询结果返回给局部 DNS 服务器，再由局部 DNS 服务器返回给客户端。

（1）查看浏览器缓存；  
（2）查看系统缓存【host 文件】；  
（3）查看路由器缓存；  
（4）查看ISP DNS 缓存（比如电信的 DNS 缓存服务器）；  
（5）询问根域名服务器（全球仅有 13 台根域名服务器，1 个主根域名服务器，其余 12 为辅根域名服务器）；    
（6）询问顶级域名服务器；  
（7）询问权威域名（主域名）服务器；  
（8）保存结果至缓存。


**2.迭代解析**

局部 DNS 服务器不是自己向其他 DNS 服务器进行查询，而是**把能解析该域名的其他 DNS 服务器的 IP 地址返回给客户端 DNS 程序**，客户端 DNS 程序再继续向这些 DNS 服务器进行查询，直到得到查询结果为止，也就是说，**代解析只是帮你找到相关的服务器而已**，而不会帮你去査。比如说：baidu.com 的服务器ip地址在 192.168.4.5 这里，你自己去查吧，本人比较忙只能帮你到这里了。【如：若 dns2 不能响应 dns1 的请求，则它会将 dns3 的ip给 dns2，以便其再向dns3发出请求】；

[https://www.guokeyun.com/news/technology/detail/222.html?navId=22](https://www.guokeyun.com/news/technology/detail/222.html?navId=22)

[https://info.support.huawei.com/info-finder/encyclopedia/zh/DNS.html](https://info.support.huawei.com/info-finder/encyclopedia/zh/DNS.html)


## 21.HTTP中缓存的私有和共有字段？知道吗？
1.`private` 指令规定了将资源作为私有缓存，只能被单独用户使用，**一般存储在用户浏览器中**。    `Cache-Control: private`

2.`public` 指令规定了将资源作为公共缓存，可以被多个用户使用，**一般存储在代理服务器中**。`Cache-Control: public`

## 23.使用 session 的过程是怎样的？
- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值；
- 存入浏览器中;客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

## 24.DDos 攻击了解吗？
客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认 没有彻底根治的办法，除非不使用 TCP DDos 预防:   
1)限制同时打开SYN半链接的数目；  
2)缩短SYN半链接的 Time out 时间；  
 3)关闭不必要的服务。


## 25.MTU 和 MSS 分别是什么？
MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。

MS5：maximum segment size，最大分节大小，为 TCP 数据包每次传输的最大数据分段大小，一般由发送端向对端 TCP 通知对端在每个分节中能发送的最大TCP数据。MSS 值为 MTU 值减去I Pv4 Header(20 Byte) 和 TCP header(20Byte) 得到。

## 26.TCP头部中有哪些信息？
TCP头部由源端口、目的端口、序号、确认号、标识位、校验和以及可选信息等部分组成，最少20个字节，最多60个字节。

- **源端口和目标端口**，各占2个字节，结合IP协议包头部的源IP地址和目标IP地址可以确定连接的两台主机和端口。
- **序列号码**，占4个字节，用于标识当前数据包的位置，有两种特殊情况，当SYN标志或FIN标志为1的时候。
	- 如果SYN标志为1，其值是初始序列号ISN。
	- 如果SYN标志为0，握手后的第一个数据包的值为ISN+1，后续的数据包的值为上一个数据包的序列号码+上一个数据包的数据段长度。 
- **确认号码**，占4个字节，只有ACK标志为1时，确认号码才有效，其值是本端期望下次收到的序列号码。 
- **数据偏移**，占4bit，表示数据部分的起始位置，也可以认为是tcp头部的长度，范围是5～15，单位是4个字节，比如取值是5(二进制是1001)，说明头部长度是5 * 4字节 = 20字节。
- **保留字段**，占3bit，值是000，目前未使用，没有意义。
- **标识位(experimental)**，占 6 bit；
- **窗口大小**，占2个字节，表示从确认号码开始，发送方可以接收的字节数，即TCP缓冲区的可用大小，用于流量控制，窗口最大65535个字节。
- **校验和**，占2个字节，通过对整个TCP数据包，包括TCP头部和数据部分进行计算得到，用于校验收到的TCP数据包的正确性和完整性。
- **紧急指针**，占2个字节，只有当URG标识为1时紧急指针才有效，紧急指针指出在数据包中紧急数据共有多少个字节，紧急数据放在本报文段数据的最前面。
- **选项部分和填充**，最多40个字节，必须为4的整数倍，不够4字节的填充0。


[https://zhixing.co/lesson/detail/1435146487706779649](https://zhixing.co/lesson/detail/1435146487706779649)


## 27.网络的七层/五层模型主要的协议有哪些？
<img src = "http://oss.interviewguide.cn/img/202205072300758.png">


## 28.什么是半连接队列？
**半连接队列** 是指服务器在收到客户端的 SYN 请求，但还没有完整建立连接时所处的状态。 当服务器收到客户端的 SYN 请求后，将客户端的请求放入半连接队列，等待服务器完成第二次握手并建立连接。 在半连接队列中，服务器可以接受新的 SYN 请求，但是尚未完成三次握手的连接不会被传递给应用程序处理。

半连接队列：

- **提供临时存储空间**：半连接队列为尚未完成三次握手的连接提供了临时存储空间，保留了连接的基本信息。
- **防止连接丢失**：当服务器的并发连接请求超过其处理能力时，半连接队列可以暂存未完成握手的连接，避免连接请求被丢失。


**服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的**，所以服务器容易受到SYN洪泛攻击。

**SYN 攻击** 就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server 则回复确认包，并等待 Client 确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

常见的防御 SYN 攻击的方法有如下几种：

- 缩短超时(SYN Timeout)时间；
- 增加最大半连接数；
- 过滤网关防护；
- SYN cookies技术；


## 29.四次挥手
<img src="https://cdn.xiaolincoding.com//mysql/other/18635e15653a4affbdab2c9bf72d599e.png">

- 服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 `CLOSE_WAIT` 状态。
- 在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以**必须要得继续 read 接收缓冲区已接收的数据**。
- 接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 `LAST_ACK` 状态；

> close 函数，同时 socket 关闭发送方向和读取方向。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，也不会发送 FIN 报文，0 时才释放；
> 
> shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用。


任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。


四次挥手释放连接时，等待2MSL的意义?

- 保证客户端发送的最后一个ACK报文段能够到达服务端（超时重传）。
- 防止“已失效的连接请求报文段”出现在本连接中。 客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以**使本连接持续的时间内所产生的所有报文段都从网络中消失**，使下一个新的连接中不会出现这种旧的连接请求报文段。

<img src="http://oss.interviewguide.cn/img/202205220036408.png">


## 30.对称加密和非对称加密的区别都有那些？
密钥

- 对称加密：使用同一个密钥进行加密和解密。这意味着加密方和解密方必须事先共享同一个密钥，并且保证这个密钥的安全。
- 非对称加密：使用一对密钥，一个公开密钥（公钥）用于加密，一个私有密钥（私钥）用于解密。公钥可以公开分享，而私钥必须保持私密。

**加密速度**

- 对称加密：通常更快，因为它使用较简单的算法来处理大量数据。
- 非对称加密：由于其复杂的数学运算，尤其是在处理大量数据时，比对称加密慢得多。

**安全性**

- 对称加密：虽然对称加密算法通常很难破解，但密钥的管理和分发过程可能导致安全漏洞。
- 非对称加密：提供了更高的安全性，因为即使公钥被公开，没有私钥也无法解密信息。不过，实现上更为复杂，需要更小心地保护私钥。

**使用场景**

- 对称加密：适用于需要快速处理大量数据的场景，如文件加密、数据库加密、网络数据传输加密等。
- 非对称加密：常用于安全敏感的通信中，如数字签名、SSL/TLS证书验证、安全电子邮件等。由于其速度较慢，通常用于加密少量数据或用于加密对称加密中使用的密钥。

**典型算法**

- 对称加密算法：AES（高级加密标准）、DES（数据加密标准）、3DES（三重数据加密算法）、RC4等。
- 非对称加密算法：RSA、ECC（椭圆曲线密码学）、Diffie-Hellman密钥交换协议、ElGamal等。

## 31.从输入 URL 到页面展现发生了什么？
1. **解析 URL**：分析 URL 所需要使用的传输协议和请求的资源路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，则对非法字符进行转义后在进行下一过程。
1. **缓存判断**：判断所请求的资源是否在缓存里，如果请求的资源在缓存里且没有失效，那么就直接使用，否则向服务器发起新的请求。。
1. **域名解析** （DNS 解析）：把域名映射为 IP 的系统，访问的时候可以直接访问域名，更方便一些。
1. **获取 MAC 地址**：本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相结合，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC 地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。
1. TCP 三次握手。
1. HTTPS 的 TLS 四次握手
1. 发送 HTTP 请求（请求报文由请求行【包含请求方法、URL 和版本协议】、请求头、空行和请求体四个部分组成）。
1. 服务器处理请求并返回 HTTP 报文（响应报文由响应行、响应头部、空行和响应主体三部分组成）。
1. 断开连接（TCP 四次挥手）。
1. 浏览器解析渲染页面。

[https://github.com/yd160513/blog/issues/17](https://github.com/yd160513/blog/issues/17)

## 32.如何实现扫码登录功能？

二维码登录本质上也是一种登录认证方式。既然是登录认证，要做的也就两件：

- 告诉系统我是谁；
- 向系统证明我是谁；

**三个过程：待扫描、已扫描待确认、确认**

1. 访问PC端二维码生成页面，PC 端请求服务端获取二维码ID
1. 服务端生成相应的二维码 ID，设置二维码的过期时间，状态等【二维码ID与PC端设备信息进行绑定】。
1. PC获取二维码 ID，生成相应的二维码【为了及时知道二维码的状态，客户端在展现二维码后，PC端不断的轮询服务端，比如每隔一秒就轮询一次，请求服务端告诉当前二维码的状态及相关信息】。
1. 手机端扫描二维码，获取二维码 ID。
1. 手机端将手机端 token 和二维码 ID 发送给服务端【服务端接收到后，它可以将身份信息与二维码ID进行绑定，生成临时token，然后返回给手机端（这时**PC 端显示已扫描待确认**），手机端在接收到临时 token 后会弹出确认登录界面】，确认登录【用户点击确认时，手机端携带临时token用来调用服务端的接口，告诉服务端，我已经确认】。
1. 服务端校验手机端 token，根据手机端 token 和二维码 ID 生成 PC 端登录的 token；
1. PC 端通过轮询方式请求服务端，通过二维码ID获取二维码状态，如果已成功，返回 PC token，登录成功。

> **账号密码登录时，客户端会将设备信息一起传递给服务端**；
  
>如果账号密码校验通过，服务端会把账号与设备进行一个绑定，存在一个数据结构中，这个数据结构中包含了账号 ID，设备 ID，设备类型等等

>然后服务端会生成一个token，用它来映射数据结构，这个token其实就是一串有着特殊意义的字符串，它的意义就在于，通过它可以找到对应的账号与设备信息，

> 客户端得到这个token后，需要进行一个本地保存，每次访问系统 API 都携带上 token 与设备信息。

> 服务端就可以通过 token 找到与它绑定的账号与设备信息，然后把绑定的设备信息与客户端每次传来的设备信息进行比较， 如果相同，那么校验通过，返回AP接口响应数据， 如果不同，那就是校验不通过拒绝访问


[https://juejin.cn/post/6940976355097985032](https://juejin.cn/post/6940976355097985032)

## 33.HTTPS 的 TLS 四次握手
如果使用的是 HTTPS 协议，在通信前还存在 TLS 的四次握手。

1. 首先由客户端向服务器端发送 TLS 协议的版本号、一个随机字符串和支持使用的加密算法。
1. 服务器端收到后，确认加密的算法，也向客户端发送一个随机字符串、确定的加密算法和自己的数字证书（包含公钥）。
1. 客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机字符串，并使用证书中的公钥对随机字符串加密，再生成一个前面所有内容的 hash 值供服务器端检验，然后发送给服务器端。
1. 服务器端接收后，使用自己的私钥对数据解密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。
1. 这个时候双方都有了三个随机字符串，按照之前所约定的加密方法，使用这三个随机字符串生成一把共享秘钥。以后双方通信前，就使用这个秘钥对数据进行加密后再传输。

<img src="https://user-images.githubusercontent.com/34637837/218344479-0a111630-fbbc-44c8-9418-494b5b8bca2b.png">

> **数字证书认证机构(CA，Certificate Authority)是客户端与服务器双方都可信赖的第三方机构**。  
> 服务器的运营人员**向  CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起**。进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证如果验证通过，就可以开始通信了。

## 34.HTTP如何禁用缓存？如何确认缓存？
    Cache-Control: no-cache
    Cache-Control: no-store

**no-cache**

使用 no-cache 指令的目的是 **为了防止从缓存中返回过期的资源** 。   
"no-cache" 指令**告诉浏览器和代理服务器不要缓存响应数据**。  
这意味着缓存会将响应数据存储在缓存中，但在将响应返回给客户端之前，必须先将该响应提交给服务器进行验证。服务器会检查响应的有效性，如果发现响应仍然有效，服务器会返回一个新的验证令牌（ETag），以通知缓存可以使用它，否则服务器将返回新的响应数据。这种方式被称为“验证缓存”。

**no-store**

"no-store" 指令更为严格，它**要求浏览器和代理服务器不要在任何情况下缓存响应数据**。  
这意味着每次请求都需要从原始服务器重新获取数据，不进行任何缓存。这可以用于敏感数据或者响应数据频繁更改的情况，以确保不会在客户端或代理服务器上存储敏感信息或者过期的数据。


**总结一下：**

- "no-cache" 指令要求缓存对响应数据进行缓存，但在使用缓存数据之前需要向原始服务器进行验证。
- "no-store" 指令要求不对响应数据进行任何形式的缓存，每次请求都需要从原始服务器重新获取数据。


[通用首部字段](https://www.yuque.com/wuhanjie-lzk8u/awhf03/ryrsho03dmhryar1?singleDoc#%20%E3%80%8A%E9%80%9A%E7%94%A8%E9%A6%96%E9%83%A8%E5%AD%97%E6%AE%B5%E3%80%8B)


## 35.GET 与 POST 传递数据的最大长度能够达到多少呢？

get 是通过 UR L提交数据，因此 **GET可提交的数据量就跟URL所能达到的最大长度有直接关系** 。

**实际上，URL不存在参数上限的问题**，HTTP协议规范也没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制。如果 url 太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。

post **理论上讲是没有大小限制的**，HTTP协议规范也没有进行大小限制，但实际上 post 所能传递的数据量大小**取决于服务器的设置和内存大小**。

## 36.网络层常见协议？可以说一下吗？

1. **IP 协议（InternetProtocol，互联网协议）**  
是 TCP/IP 协议栈中最核心的协议之一，通过 IP 地址，保证了联网设备的唯一性，实现了网络通信的面向无连接和不可靠的传输功能。

2. **ICMP 协议**（Internet Control Message Protocol，Internet 控制消息协议）  
ICMP 属于 TCP/IP 协议族，用于在 IP 主机、路由器之间传递控制消息。   
	- 控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。

	ICMP 协议与 ARP 协议不同，ICMP 靠 IP 协议来完成任务，所以**ICMP 报文中要封装 IP 头部**。它与传输层协议（如 TCP 和 UDP）的目的不同，一般不用来在端系统之间传送数据，不被用户网络程序直接使用，除了像 Ping 和 Tracert 这样的诊断程序。  
	ICMP 的主要作用是主机探测，路由维护，路由选择，流量控制。
<font color =red>IP 协议是不可靠协议，不能保证 IP 数据报能够成功的到达目的主机，无法进行差错控制，当遇到 IP 数据无法访问目标、IP 路由器无法按当前的传输速率转发数据包等情况时，会自动发送 ICMP 消息。</font>

3. **IGMP 协议 （Internet Group Management Protocol，Internet 组管理协议）**
IGMP 也是 IP 协议的一个补充，位于 TCP/IP 体系中的网络层，是用于管理网路协议多播组成员的一种通信协议。   
该协议用来在**ip 主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系**，但不包括组播路由器之间的组成员关系信息的传播与维护，这部分工作由各组播路由协议完成。所有参与组播的主机必须实现 IGMP。

4. RIP是一种基于距离矢量（Distance-Vector）算法的协议，它通过UDP报文进行路由信息的交换，使用的端口号为520。  
RIP使用跳数来**衡量到达目的地址的距离**，跳数称为度量值。在RIP中，路由器到与它直接相连网络的跳数为 0，通过与其相连的路由器到达另一个网络的跳数为 1，其余依此类推。为限制收敛时间，RIP 规定度量值取 0～15 之间的整数，大于或等于 16 的跳数被定义为无穷大，即目的网络或主机不可达。主要用于规模较小的网络中。

[网络层、传输层、应用层常用协议](https://leeyuxun.github.io/%E7%BD%91%E7%BB%9C%E5%B1%82%E3%80%81%E4%BC%A0%E8%BE%93%E5%B1%82%E3%80%81%E5%BA%94%E7%94%A8%E5%B1%82%E5%B8%B8%E7%94%A8%E5%8D%8F%E8%AE%AE.html)


## 37.TCP 拥塞控制算法总结？
TCP拥塞控制是传输控制协议避免网络拥塞的算法，是互联网上主要的一个拥塞控制措施。拥塞控制是**避免发送方填满整个网络**。

当网络极度拥堵时，如果没有拥塞控制，发送方会继续发送大量的网络数据包，而这些**数据包因为网络阻塞而延时、丢失，触发了TCP重传，重传使得网络更加阻塞**，整个网络将会陷入不可用的状态。

什么是拥塞窗口？  
**拥塞窗口(cwnd)** 是发送方维护的一个状态变量，它会*根据网路拥堵情况动态调节*。
之前发送窗口约等于接收窗口，但在拥塞窗口加入后，`发送窗口=min(拥塞窗口，接收窗口)`。

- 只要网络中没有出现阻塞，窗口就会增大；
- 网络中出现阻塞，窗口就会减小；

**发送方判定网络出现阻塞**：发送方在规定时间内没有收到 ACK 报文（也就是触发了超时重传）。

<img src="http://oss.interviewguide.cn/img/202205220036635.png" width="500" height="300">

拥塞控制算法：

1. 慢启动；
1. 拥塞避免；
1. 拥塞发生；
1. 快速恢复；

**1.慢启动**：慢启动的规则就是当发送方收到一个 ACK，拥塞窗口的大小就会加 1 。

- 连接建立完成后，拥塞窗口 `cwnd` 为 1，表示可以发送一个 `MSS` 的数据；
- 当发送方收到一个 ACK 报文以后，拥塞窗口 `cwnd` 增加 1 变为 2，发送方一次可以发送两个 `MSS` 的数据；
- 当收到 `2` 个 `ACK` 报文以后，拥塞窗口 `cwnd` 增加 `2` 变为 `4`，此时发送方一次可以发送 `4` 个MSS的数据；
- 当收到 `4` 个ACK报文以后，拥塞窗口 `cwnd` 增加 `4` 变为`8`，此时能够发送8个MSS的数据。

<img src="https://ask.qcloudimg.com/http-save/yehe-2513555/58a111fff690029be910532da61a63f3.jpeg" width="500" height="300">


**慢启动算法的发报个数呈指数级增长**。

慢启动算法何时停止？

慢启动算法中有一个 **慢启动门限** `ssthresh`（slow start threshold）的状态变量:

- 当拥塞窗口 cwnd < ssthresh 时，使用慢启动算法
- 当拥塞窗口 cwnd >= ssthresh 时，使用拥塞避免算法
- 一般来说，ssthresh 的大小为 65535 字节。


**2.拥塞避免**  规则是每收到一个ACK报文，拥塞窗口 cwnd 增加 `1/cwnd`。

<img src="https://ask.qcloudimg.com/http-save/yehe-2513555/403f4af6dd0b582834fae1a618d68fca.jpeg" width="500" height="300">

	cwnd = cwnd + 1/cwnd 

进入拥塞避免算法以后，拥塞避免算法拥塞窗口还是增长的，只不过增长速度由指数变为了线性。

窗口一直在增长，网络会渐渐开始变得阻塞，网络中逐渐出现延时、丢包现象，导致TCP发生重传，此时就会进入拥塞发生阶段。


**3.拥塞发生**

TCP重传的机制大类主要有两种：

- 超时重传；
- 快速重传；


**超时重传拥塞发生以后**，ssthresh和cwnd会发生变化：

<img src="https://ask.qcloudimg.com/http-save/yehe-2513555/445cb3ad482f5b03e310be7429069a41.jpeg" width="300">

- ssthresh（慢启动门阀）设置为 `cwnd/2`；
- cwnd（拥塞窗口）重置为 `1`；


**快速重传拥塞发生**

<img src="https://ask.qcloudimg.com/http-save/yehe-2513555/49807ba609f43f705025d3550d41ff34.jpeg" width="300">

快速重传会在收到相同的 3个ACK 包时发生，发送端可以快速重传，不必在等待超时。这种情况下ssthresh和cwnd会发生以下变化：

- `cwnd（拥塞窗口） = cwnd / 2`，拥塞窗口减少为一半；
- `ssthresh = cwnd`；



**4.进入快速恢复算法**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" width="300">

进入快速恢复前，ssthresh和cwnd的值已被更新。进入快速恢复以后：

- 拥塞窗口` cwnd = ssthresh + 3`（表示有三个数据包被收到）；
- 重传丢失的数据包；
- 如果收到的ACK是重复的，cwnd 增加1；
- 如果收到新数据的ACK，把拥塞窗口设置为第1步中ssthresh的值，因为ACK已经确认了新数据，快速恢复过程可以结束，可以再次进入拥塞避免阶段。原因是该 ACK 确认了新的数据，


[https://cloud.tencent.com/developer/article/1920081](https://cloud.tencent.com/developer/article/1920081)


## 38.为何快速重传是选择 3 次 ACK？
发送端收到 三个 DupAck，其实意思是**总共四个相同的ACK**，第一为正常确认ACK，**后续三个为重复ACK**。

大致原因是因为网络传输是不可靠的，丢包、乱序和复制等情况，如果出现三次以上 DupAck 的就**认为丢包的可能性很高**，可以进入快速重传机制。

在没有fast retransmit / recovery 算法之前，重传依靠发送方的 retransmit  timeout，就是在 timeout 内如果没有接收到对方的ACK，默认包丢了，发送方就重传，
包的丢失原因：  
1）包 checksum 出错；  
2）网络拥塞；  
3）网络断，包括路由重收敛，

但是**发送方无法判断是哪一种情况**，于是采用最笨的办法，就是将自己的发送速率减半，即CWND 减为1/2，这样的方法对 2 是有效的，可以缓解网络拥塞，3 则无所谓，反正网络断了，无论发快发慢都会被丢；

但对于 1 来说，丢包是因为偶尔的出错引起，一丢包就对半减速不合理。于是有了fast retransmit 算法，基于在反向还可以接收到 ACK，可以认为网络并没有断，否则也接收不到 ACK，如果在 timeout 时间内没有接收到 `> 2` 的duplicated ACK，则概率大事件为乱序，乱序无需重传，接收方会进行排序工作；而如果接收到三个或三个以上的duplicated ACK，则大概率是丢包，可以逻辑推理，发送方可以接收ACK，则网络是通的，可能是 1、2 造成的，先不降速，重传一次，如果接收到正确的ACK，则一切OK，流速依然（包出错被丢）。而如果依然接收到 duplicated ACK，则认为是网络拥塞造成的，此时降速则比较合理。

[https://blog.csdn.net/u010202588/article/details/54563648](https://blog.csdn.net/u010202588/article/details/54563648)

## 39.TCP 四次挥手过程

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230614791.png" width="300x">

`FIN_WAIT_2`：半关闭状态。
发送断开请求一方还有接收数据能力，但已经没有发送数据能力。

`CLOSE_WAIT` 状态：
被动关闭连接一方接收到 `FIN` 包会立即回应 `ACK` 包表示已接收到断开请求。
被动关闭连接一方如果还有剩余数据要发送就会进入 `CLOSE_WAIT` 状态。

`TIME_WAIT` 状态：
又叫 2MSL 等待状态（至少允许报文丢失一次）。
如果客户端直接进入 `CLOSED` 状态，如果服务端没有接收到最后一次 `ACK` 包会在 **超时之后重新再发** `FIN` 包，此时因为客户端已经 `CLOSED`，所以服务端就不会收到 `ACK` 而是收到 `RST`。所以 `TIME_WAIT` 状态目的是防止最后一次握手数据没有到达对方而触发重传 `FIN` 准备的。【服务端收到这个 RST 并将其解释为一个错误，这对于一个可靠的协议来说不是一个优雅的终止方式】
在 2MSL 时间内，同一个 socket 不能再被使用，否则有可能会和旧连接数据混淆（如果新连接和旧连接的socket相同的话）。

## 40.你了解流量控制原理吗？
双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里（失序的数据包也会被存放在缓存区里）。

如果缓存区满了发送方还在疯狂着发送数据，接收方只能把收到的数据包丢掉，大量的丢包会极大着浪费网络资源，因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。

**对发送方发送速率的控制，**我们称之为流量控制。

TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个**发送窗**和**接收窗**：

接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把**缓存区的剩余大小称之为接收窗口大小**，用变量 win 来表示接收窗口的大小。

> TCP 是流数据，发送出去的数据流可以被分为以下四部分：**已发送目被确认部分|已发送未被确认部分|未发送但可发送部分|不可发送部分**，其中 `发送窗=已发送未确认部分+未发但可发送部分`。接收到的数据流可分为：**已接收|未接收但准备接收|未接收不准备接收**。`接收窗=未接收但准备接收部分`；
> 
**发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗**，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为 0 时，发送方就会停止发送数据，防止出现大量丢包情况的发生。

当发送方收到接收窗口 `win = 0` 时，这时发送方停止发送报文，并且**同时开启一个定时器**，每隔一段时间就发个测试报文去询问接收方，打听是否可以继续发送数据了，如果可以，接收方就告诉他此时接受窗口的大小；如果接受窗口大小还是为 `0`，则发送方**再次刷新**启动定时器。

[https://blog.csdn.net/weixin_43901865/article/details/113106417](https://blog.csdn.net/weixin_43901865/article/details/113106417)


## 41.建立TCP服务器的各个系统调用过程是怎样的？
服**务器：**

1、创建socket -> `int socket(int domain, int type, int protocol)`;

	domain：协议域，决定了socket的地址类型，IPv4为AF_INET。
	type：指定socket类型，SOCK_STREAM为TCP连接。
	protocol：指定协议。IPPROTO_TCP表示TCP协议，为0时自动选择type默认协议。

2、绑定socket和端口号 -> `int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);`

	sockfd：socket返回的套接字描述符，类似于文件描述符fd。
	addr：有个sockaddr类型数据的指针，指向的是被绑定结构变量。
	addrlen：地址长度。

	// IPv4的sockaddr地址结 构
	    // IPv4的sockaddr地址结构
	struct sockaddr_in {
	    sa_family_t sin_family;    // 协议类型，AF_INET
	    in_port_t sin_port;    // 端口号
	    struct in_addr sin_addr;    // IP地址
	};
	struct in_addr {
	    uint32_t s_addr;
	}


3、监听端口号 -> `int listen(int sockfd, int backlog);`

	sockfd：要监听的sock描述字。
	backlog：socket可以排队的最大连接数。

4、接收用户请求 -> `int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);`

	sockfd：服务器socket描述字。
	addr：指向地址结构指针。
	addrlen：协议地址长度。
	注：一旦accept某个客户机请求成功将返回一个全新的描述符用于标识具体客户的TCP连接。

5、从socket中读取字符 -> `ssize_t read(int fd, void *buf, size_t count);`

	fd：连接描述字。
	buf：缓冲区buf。
	count：缓冲区长度。
	注：大于0表示读取的字节数，返回0表示文件读取结束，小于0表示发生错误。

6、关闭socket -> `int close(int fd);`

	fd：accept返回的连接描述字，每个连接有一个，生命周期为连接周期。
	注：sockfd是监听描述字，一个服务器只有一个，用于监听是否有连接；fd是连接描述字，用于每个连接的操作。


**客户机：**

1、创建socket -> `int socket(int domain, int type, int protocol);`

2、连接指定计算机 -> `int connect(int sockfd, struct sockaddr * addr, socklen_t addrlen)；`

	sockfd客户端的sock描述字。
	addr：服务器的地址。
	addrlen：socket地址长度。

3、向socket写入信息 -> `ssize_t write(int fd, const void *buf, size_t count);`

	fd、buf、count：同read中意义。
	大于0表示写了部分或全部数据，小于0表示出错。

4、关闭`socket -> int close(int fd);`

	fd：同服务器端fd

## 42.TCP 协议如何保证可靠传输？
TCP协议主要通过以下七点来保证传输可靠性：连接管理，校验和，序列号，确认应答，超时重传，流量控制，拥塞控制。

- **连接管理**：即三次握手和四次挥手。连接管理机制能够建立起可靠的连接，这是保证传输可靠性的前提。
- **校验和**：发送方对发送数据的二进制求和取反，然后将值填充到TCP的校验和字段中，接收方收到数据之后，以相同的方式计算校验和并进行对比。如果结果不符合预期，则将数据包丢弃。  
注意：即便二者相等，也并不能确保数据包一定是正确无误的，基于某些巧合，会出现数据包错误，但发送端和接收端的校验和相等的场景。
- **序列号**：TCP将每个字节的数据都进行了编号，这就是序列号。  
序列号的具体作用如下：能够保证可靠性，既能防止数据丢失，又能避免数据重复。能够保证有序性，按照序列号顺序进行数据包还原。能够提高效率，基于序列号可实现多次发送，一次确认。
- **确认应答**：接收方接收数据之后，会回传 ACK 报文，报文中带有此次确认的序列号，用于告知发送方此次接收数据的情况。在指定时间后，若发送端仍未收到确认应答，就会启动超时重传。
- **超时重传**：具体来说，超时重传主要有两种场景：数据包丢失：在指定时间后，若发送端仍未收到确认应答，就会启动超时重传，向接收端重新发送数据包。确认包丢失：当接收端收到重复数据(通过序列号进行识别)时将其丢弃，并重新回传ACK报文。
- **流量控制**：接收端处理数据的速度是有限的，如果发送方发送数据的速度过快，就会导致接收端的缓冲区溢出，进而导致丢包……为了避免上述情况的发生，TCP支持根据接收端的处理能力，来决定发送端的发送速度。这就是流量控制。流量控制是通过在TCP报文段首部维护一个滑动窗口来实现的。
- **拥塞控制**：拥塞控制就是当网络拥堵严重时，发送端减少数据发送。拥塞控制是通过发送端维护一个拥塞窗口来实现的。可以得出，发送端的发送速度，受限于滑动窗口和拥塞窗口中的最小值。

[https://blog.csdn.net/zs18753479279/article/details/115588009](https://blog.csdn.net/zs18753479279/article/details/115588009)

## 43.TCP 和 UDP 的区别
1. **TCP 是面向连接的协议，UDP 是无连接协议**：  
TCP 发送数据前使用三次握手建立连接，UDP 发送数据前不需要建立连接。
2. **TCP 可靠，UDP 不可靠**：  
TCP 丢包会自动重传，UDP 不会(任何必需的可靠性必须由应用层来提供)。 TCP 可靠性由三个机制保证：1. 序号（TCP 报文的序号）2. 确认（ACK 机制）3. 重传（超时或者冗余的 ACK）
3. **TCP 有序，UDP 无序**：  
消息在传输过程中可能会乱序，后发送的消息可能会先到达，TCP 会对其进行重新排序，UDP 不会。
4. **TCP 无界，UDP 有界**：    
TCP 通过字节流传输，UDP 中每一个包都是单独的。
5. **TCP 有流量控制（拥塞控制），UDP 没有**：  
TCP 协议的流量控制是基于滑窗协议实现的。 拥塞控制和流量控制不同，流量控制是点对点的通信量抑制，抑制发送端发送速率，使得接收端来得及接收。
6. **TCP 传输慢，UDP 传输快**：  
因为 TCP 需要建立连接、保证可靠性和有序性，所以比较耗时。 这就是为什么视频流、广播电视、在线多媒体游戏等选择使用 UDP。
7. **TCP 是重量级的，UDP 是轻量级的**：  
TCP 要建立连接、保证可靠性和有序性，就会传输更多的信息，如 TCP 的包头比较大。
8. **TCP 的 头部比 UDP 大**  
TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

## 44.封包和拆包你听说过吗？它是基于TCP还是UDP的？
**封包**就是给一段数据加上包头，这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入"包尾"内容)。包头其实上是个大小固定的结构体，其中有个结构体成员变量表示包体的长度，这是个很重要的变量，其他的结构体成员可根据需要自己定义。根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。

拆包

对于拆包目前我最常用的是以下两种方式：  
（1）动态缓冲区暂存方式。之所以说缓冲区是动态的是因为当需要缓冲的数据长度超出缓冲区的长度时会增大缓冲区长度。
> A，为每一个连接动态分配一个缓冲区，同时把此缓冲区和 SOCKET 关联，常用的是通过结构体关联。  
>B，当接收到数据时首先把此段数据存放在缓冲区中；  
>C，判断缓存区中的数据长度是否够一个包头的长度，如不够，则不进行拆包操作；  
>D，根据包头数据解析出里面代表包体长度的变量；  
>E，判断缓存区中除包头外的数据长度是否够一个包体的长度，如不够，则不进行拆包操作；  
F，取出整个数据包，这里的"取"的意思是不光从缓冲区中拷贝出数据包，而且要把此数据包从缓存区中删除掉。删除的办法就是把此包后面的数据移动到缓冲区的起始地址。
  
（2）利用底层的缓冲区来进行拆包。

封包和拆包都是基于TCP的概念。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。


## 45.UDP的特点有哪些和 TCP 的特点？

**UDP的特点**

- UDP 是无连接的；
- UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态(这里面有许多参数)；
- UDP是面向报文的；
- UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低(对实时应用很有用，如IP电话，实时视频会议等)；
- UDP支持一对一、一对多、多对一和多对多的交互通信；
- UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短；

**UDP 对应的应用层协议：**

- DNS：用于域名解析服务，用的是53号端口；
- SNMP：简单网络管理协议，使用161号端口；
- TFTP(Trival file TransferProtocal)：简单文件传输协议，69；


**TCP 的特点：**

- TCP是面向连接的。(就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接)每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的(一对一)；
- TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
- TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
- 面向字节流。TCP中的“流”(stream)指的是流入进程或从进程流出的字节序列。"面向字节流"的含义是：虽然应用程序和TCP的交互是一次一个数据块(大小不等)，但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

**TCP对应的应用层协议**：

- FTP：定义了文件传输协议，使用21端口；
- Telnet：它是一种用于远程登陆的端口,23端口；
- SMTP：定义了简单邮件传送协议，服务器开放的是25号端口；
- POP3：它是和SMTP对应，POP3用于接收邮件。

## 46.数据链路层常见协议？可以说一下吗？
- ARP：地址解析协议：根据IP地址获取物理地址；
- RARP：反向地址转换协议：根据物理地址获取IP地址；
- PPP：点对点协议：主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网杯和路由器之间简单连接的一种共通的解决方案。

## 47.Ping命令基于什么协议？原理是什么？

Ping 命令的实现原理主要基于 ICMP 协议和 TCP/IP 协议栈。

当我们在命令行中输入Ping命令时，操作系统会根据目标IP地址或域名，查找本地DNS缓存或向DNS服务器查询目标IP地址。获取到目标IP地址后，Ping命令会构造一个ICMP回显请求消息，并将其封装在一个IP数据包中，然后通过网络发送到目标主机。

目标主机接收到回显请求消息后，会对其进行处理并返回一个 ICMP 回显应答消息。**回显应答消息中会包含目标主机的 IP地址、发送时间戳等信息**。Ping 命令接收到回显应答消息后，会**计算**并显示往返时延等信息，从而帮助我们了解网络连接的质量。


## 48.在进行 UDP 编程的时候，一次发送多少 bytes 好?

对于不同的系统，不同的要求，答案是不一样的。

我这里仅对像ICQ一类的发送聊天消息的情况作分析，对于其他情况，你或许也能得到一点帮助：首先，我们知道，TCP／IP通常被认为是一个四层协议系统，包括链路层，网络层，运输层，应用层．UDP属于运输层，

以太网（Ethernet）**数据帧的长度必须在46－1500字节之间**，这是由以太网的物理特性决定的．这个 **1500 字节被称为链路层的MTU（最大传输单元）**，但这并不是指链路层的长度被限制在1500字节，其实这这个MTU指的是链路层的数据区．并不包括链路层的首部和尾部的18个字节．

所以，事实上，这个1500字节就是**网络层 IP 数据报的长度限制**。因为 IP 数据报的**首部为20字节**，所以** IP 数据报的数据区长度最大为1480字节**，而这个1480字节就是用来放 TCP 传来的 TCP 报文段或 UDP 传来的UDP数据报的．又因为**UDP数据报的首部8字节**，所以UDP数据报的数据区最大长度为1472字节．这个1472字节就是我们可以使用的字节数。

当我们发送的UDP数据大于1472的时候会怎样呢？这也就是说IP数据报大于1500字节，**大于MTU．这个时候发送方IP层就需要分片**（fragmentation）。把数据报分成若干片，使每一片都小于 MTU．而接收方 IP 层则需要进行数据报的重组．这样就会多做许多事情，而更严重的是，由于UDP的特性，当某一片数据传送中丢失时，接收方便无法重组数据报．将导致丢弃整个UDP数据报。

因此，在普通的局域网环境下，我建议将UDP的数据控制在1472字节以下为好．

进行Internet编程时则不同，因为 Internet 上的路由器可能会将 MTU 设为不同的值．如果我们假定 MTU 为1500来发送数据的，而途经的某个网络的 MTU 值小于1500字节，那么系统将会使用一系列的机制来调整 MTU 值，使数据报能够顺利到达目的地，这样就会做许多不必要的操作。

<font color=blue> 一句话，需要根据网络中的最小MTU（最大传输单元）来进行调整，长度应该限制在 MTU - IP数据包首部长度（20字节） - 数据报首部长度（UDP为八个字节）。</font>

> 首部的前一部分是**固定长度，共20字节**，是所有IP数据报必须具有的。在首部的固定部分的后面是一些可选字段，其长度是可变的。首部中的源地址和目的地址都是IP协议地址。

[http://t.csdnimg.cn/3qBZG](http://t.csdnimg.cn/3qBZG)


## 49.可以解释一下 RTO，RTT 和超时重传分别是什么吗?
**RTO** （Retransmission Timeout 超时重传时间）：

- 通常每次重传 RTO 是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTIT...
- 重传次数到达上限之后停止重传。

**RTT**：指的是数据发送时刻到接收到确认的时刻的差值也就是包的往返时间。即数据报在网络中一个往返用时间，大小不稳定。



**超时重传**：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：

- 发送的数据没能到达接收端，所以对方没有响应；
- 接收端接收到数据，但是ACK报文在返回过程中丢失；
- 接收端拒绝或丢弃数据；

## 50.如何区分流量控制和拥塞控制？
- 流量控制属于通信双方协商；拥塞控制涉及通信链路全局；
- 流量控制雲要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的 TCP 报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。
- 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。


## 51.常见的HTTP状态码有哪些？
- `1xx`（信息性状态码）：表示接收的请求正在处理。
- `2xx`（成功状态码）：表示请求正常处理完毕。
- `3xx`（重定向状态码）：需要后续操作才能完成这一请求。
- `4xx`（客户端错误状态码）：表示请求包含语法错误或无法完成。
- `5xx`（服务器错误状态码）：服务器在处理请求的过程中发生了错误。

## 52.一台机器能够使用的端口号上限是多少，是否可以修改？如果想要用的端口超过这个限制怎么办？

65536。  

因为 TCP 的报文头部中源端口号和目的端口号的长度是 16 位，也就是可以表示 2^16=65536 个不同端口号，因此 TCP 可供识别的端口号最多只有 65536 个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。

而对于服务器来说，可以开的端口号与 65536 无关，其实是受限于 Linux 可以打开的文件数量，并且可以通过 MaxUserPort 来进行配置。


## 53.TCP可靠传输机理
TCP是通过序列号、检验和、确认应答信号、重发机制、连接管理、窗口控制、流量控制、拥塞控制一起保证TCP传输的可靠性的。

1. **应答机制**：发送方在发送数据包后，会等待接收方的确认应答。如果发送方没有收到确认应答，就会重新发送数据包，直到收到确认为止。
2. **序列号和确认号**：TCP 将每个数据包都赋予一个唯一的序列号，接收方收到数据包后会发送一个确认应答，并指定下一个期望接收的数据的序列号。发送方根据接收方的确认号知道哪些数据已经成功发送并被接收。
3. **滑动窗口**：发送方将数据分割为多个小的数据段，并使用滑动窗口的机制进行发送。接收方通过确认号告诉发送方数据被接收，发送方可以根据确认号调整滑动窗口的大小和发送速率。
4. **重传机制**：如果发送方在一定时间内未收到确认应答，就会认为数据包丢失，并进行重传。接收方在收到重复的数据包时会丢弃重复的数据，确保只有一个副本被交付给上层应用。
5. **流量控制**：TCP使用滑动窗口的机制来控制发送方发送数据的速率，避免发送过多的数据导致接收方无法及时处理或丢失数据。
6. **拥塞控制**：TCP根据网络的拥塞程度动态调整发送方的发送速率，避免过多的数据流入网络导致拥塞。TCP使用拥塞窗口大小和重传超时时间等参数来判断网络的拥塞情况，并采取相应的措施，如减小发送速率或等待较长时间进行重传。


---

# MYSQL

## 1.关系型和非关系型数据库
关系型数据库指的是使用**关系模型（二维表格模型）来组织数据**的数据库。

常见关系型数据库管理系统(ORDBMS)：

- Oracle
- MySql
- Microsoft SQL Server
- SQLite
- PostgreSQL
- IBM DB2

**优势**：

- 采用二维表结构非常贴近正常开发逻辑（关系型数据模型相对层次型数据模型和网状型数据模型等其他模型来说更容易理解）；
- 支持通用的SQL（结构化查询语言）语句；
- 丰富的完整性大大减少了数据冗余和数据不一致的问题。并且全部由表结构组成，文件格式一致；
- 可以用SQL句子多个表之间做非常繁杂的查询；
- 关系型数据库提供对事务的支持，能保证系统中事务的正确执行，同时提供事务的恢复、回滚、并发控制和死锁问题的解决。
- 数据存储在磁盘中，安全可靠。

**不足**：

- **高并发读写能力差**：网站类用户的并发性访问非常高，而一台数据库的最大连接数有限，且硬盘 I/O 有限，不能满足很多人同时连接。
- **海量数据情况下读写效率低**：对大数据量的表进行读写操作时，需要等待较长的时间等待响应。
- **可扩展性不足**：不像 web server 和 app server 那样简单的添加硬件和服务节点来拓展性能和负荷工作能力。
- **数据模型灵活度低**：关系型数据库的数据模型定义严格，无法快速容纳新的数据类型（需要提前知道需要存储什么样类型的数据）。

**非关系型数据库**又被称为 NoSQL（Not Only SQL )，意为不仅仅是 SQL。通常指数据**以对象的形式存储在数据库中**，而**对象之间的关系通过每个对象自身的属性来决定**，常用于存储非结构化的数据。

- 键值数据库：Redis、Memcached、Riak；
- 列族数据库：Bigtable、HBase、Cassandra；
- 文档数据库：MongoDB、CouchDB、MarkLogic；
- 图形数据库：Neo4j、InfoGrid；

优势：

- 非关系型数据库存储数据的格式可以是 key-value 形式、文档形式、图片形式等。使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。
- 速度快，效率高。 NoSQL 可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘。
- 海量数据的维护和处理非常轻松，成本低。
- 非关系型数据库具有扩展简单、高并发、高稳定性、成本低廉的优势。
- 可以实现数据的分布式处理。

不足：

- 非关系型数据库暂时不提供 SQL 支持，学习和使用成本较高。
- 非关系数据库没有事务处理，无法保证数据的完整性和安全性。适合处理海量数据，但是不一定安全。
- 功能没有关系型数据库完善。
- 复杂表关联查询不容易实现。


**适用场景**：日志系统，地理位置，存储数据量巨大，高可用

[https://cloud.tencent.com/developer/article/1784274](https://cloud.tencent.com/developer/article/1784274)


## 2.为什么使用索引？
- 通过创建唯一性索引，可以**保证数据库表中每一行数据的唯一性**。
- 将无序的数据变成相对有序的数据(就像查有目的一样)，可以大大**加快数据的检索速度**，这也是创建索引的最主要的原因。
- 帮助服务器**避免排序和临时表**。
- 将**随机 IO 变为顺序 IO**。
- 可以**加速表和表之间的连接**，特别是在实现数据的参考完整性方面特别有意义。


## 3.Innodb 为什么要用自增 id 作为主键？
首先，使用自增 id 作为主键可以**提供高效的插入操作**。 当一条新的记录被插入到表中时，InnoDB 会为该记录分配一个新的自增 id，而**不需要进行复杂的主键冲突检测**。 这样可以避免由于主键冲突而导致的插入失败和重试，提高了插入操作的效率。 

其次，使用自增 id 作为主键可以**提供更好的性能**。在 InnoDB 中，主键被用作索引来加速查询操作。使用自增 id 作为主键可以 **确保新插入的记录在主键索引中是有序的**，这样在查询时可以 **更快地定位到目标记录**，提高了查询的效率。

此外，使用自增 id 作为主键还可以**减少主键的冲突概率**。如果使用其他类型的主键，比如 UUID 或者字符串，由于其分布更为均匀，可能会导致更多的主键冲突。而使用自增id作为主键，由于其**生成规则简单且递增，主键冲突的可能性较小**。


**限制和潜在的问题**：首先，自增 id 只能用于整型数据类型，不能用于其他类型的数据。其次，如果需要频繁地进行数据的删除和插入操作，可能会导致自增 id 的间隙增多，浪费了存储空间。

[https://developer.aliyun.com/article/1270766](https://developer.aliyun.com/article/1270766)


## 4.MyISAM和InnoDB 索引区别
MyISM和InnoDB索引都是由B+树实现的，但在索引**管理数据方式上**却有所不同。

InnoDB 是**聚集索引**，数据文件是和（主键）索引绑在一起的，即 `索引 + 数据 = 整个表数据文件`，通过主键索引到整个记录，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，因为辅助索引是以建索引的字段为关键字索引到主键，所以需要两次，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。

MyISAM 是**非聚集索引**，也是使用 B+Tree 作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。

也就是说：<font color=blue>InnoDB 的 B+ 树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而 MyISAM 的 B+ 树主键索引和辅助索引的叶子节点都是数据文件的地址指针。</font>

从索引实现方面可以看出来：InnoDB 表数据文件本身就是索引文件，他们是一个整体，而对于 MyISAM 来说数据文件和索引文件则是分开的。

## 5.说一下 MySQL 是如何执行一条SQL的?具体步骤有哪些？

**可以分为服务（server）层和存储引擎层两部分**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/sql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png" width="500x">

- 连接器：管理连接、权限验证【验证用户身份，给予权限】；
- 查询缓存：命中缓存则直接返回结果【存在缓存则直接返回，不存在则执行后续操作】；
- 分析器：对SQL进行词法分析、语法分析(判断查询的SQL字段是否存在也是在这步)；
- 优化器：执行计划生成、选择索引【对执行的 sql 优化选择最优的执行方案方法】；
- 执行器：操作引擎、返回结果【执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口】；
- 存储引擎：存储数据、提供读写接口。

## 6.说一说 Drop、Delete 与 Truncate 的共同点和区

在 MySQL  中，使用 truncate、delete 和 drop 都可以实现表删除，但它们 3 个的使用场景和执行效果完全不同

`Delete` 用来删除表的全部或者一部分数据行，执行 `delete` 之后，用户需要提交(commit)或者回滚 (rollback)来执行删除或者撤销删除，会触发这个表上所有的 `delete` 触发器。

`Truncate` 删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，`TRUNCATE` 比 `Delete更快`，占用的空间更小，但是不能删除对于由 `foreign key` 约束引用的表，不能删除该表中的数据。

`Drop` 命令从数据库中删除表以及所有的数据行、索引和权限都会被删除，所有的 DML 触发器也不会被触发，这个命令也不能回滚。\

<font color=red> 因此，在不再需要一张表的时候，用 Drop；在想删除部分数据行时候，用 Delete；在保留表而删除所有数据的时候用 Truncate。</font>


|**区别点** |drop |truncate | delete|
| - | - | - |
| 执行速度 | 快 | 较快 | 慢 |
|命令分类|DDL（数据定义语言）|DDL（数据定义语言）|DML（数据操作语言）|
| 删除对象|删除整张表和表结构，以及表的索引、约束和触发器。|只删除表数据，表的结构、索引、约束等会被保留。|只删除表的全部或部分数据，表结构、索引、约束等会被保留。|
|删除条件(where)|不能用|不能用|可使用|
|回滚|不可回滚|不可回滚|可回滚|
|自增初始值| - |重置|不重置|



[https://cloud.tencent.com/developer/article/2035770](https://cloud.tencent.com/developer/article/2035770)

## 7.简述MySQL可以从哪些方面做到性能优化？
<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f5d5271d47a4ab4a9791b7786f99bac~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" width="500">

**1. 连接配置优化**

- 服务端增加可用连接数，及时释放不活动的连接
- 客户端尽量减少和服务端建立连接的次数（连接池）

**2. 架构优化**

- 使用缓存：在数据的缓存有效期内，直接从缓存系统中获取数据，这样就可以减轻数据库的压力并提升查询效率。
- 读写分离（集群、主从复制）：用户写数据只往小组长master节点写，而读的请求分摊到各个组员slave节点上。给组长加上组员组成的小团体起个名字，叫集群；
- 分库分表：把单个节点的数据分散到多个节点上进行存储，分库分表中的节点的含义比较宽泛，要是把数据库作为节点，那就是分库；如果把单张表作为节点，那就是分表，**水平分，主要是为了解决存储的瓶颈；垂直分，主要是为了减轻并发压力**；
- 消息队列削峰：不管同时有多少个用户请求，先存入消息队列，然后系统有条不紊地从消息队列中消费请求。

**3.优化器**
 
SQL优化指的是SQL本身语法没有问题，但是有实现相同目的的更好的写法。

- 使用小表驱动大表；用 `join` 改写子查询；`or` 改成 `union`
- 连接查询中，尽量减少驱动表的扇出（记录数），访问被驱动表的成本要尽量低，尽量在被驱动表的连接列上建立索引，降低访问成本；被驱动表的连接列最好是该表的主键或者是唯一二级索引列，这样被驱动表的成本会降到更低
- 大偏移量的 `limit`，先过滤再排序；
- 避免使用 Select*，列出需要查询的字段；


**4. 存储引擎与表结构**

建议根据不同的业务选择不同的存储引擎，例如：

- 查询操作、插入操作多的业务表，推荐使用MyISAM；
- 临时表使用Memory；
- 并发数量大、更新多的业务选择使用InnoDB；
- 不知道选啥直接默认。

**5.业务优化**

- 预售分流：分流客户的服务请求
- 降级策略：集结不重要的服务的计算资源，用来保证当前最核心的业务；


[https://juejin.cn/post/7083269706232102925](https://juejin.cn/post/7083269706232102925)


## 8.数据库隔离级别
**脏读**：数据库隔离级别为读未提交的时候，可能发生脏读。读未提交指当会话 A 的数据库操作尚未commit时，会话 B 可以 **读取到这个未提交的数据 **。而此时如果会话 A 因为某些原因rollback了，那么会话 B 读取的数据就是错误的，也就是脏读。当隔离级别提高到读已提交时，则可以避免脏读。

**不可重复读**：简单的理解就是**多次读取结果不一致**，在会话 A 中多次相同的操作读取的数据是不一致的。比如，在会话 A 的两次读取操作直接，会话 B 对此数据进行了提交，那么会话 A 第一次读取的是之前的数据，第二次读取的是之后的数据。通过隔离级别可重复读来解决这个问题。

**幻读**：不可重复读的特殊场景，不可重复读主要是指在读取某条记录时发生，而**幻读指的是范围**。比如，会话 A 第一查询年龄大于 18 的人，发现没有数据，但当第二次进行查询时，却查询到了数据。在串行化的隔离级别下，不会发生幻读。


**隔离级别**

1.读未提交

如果一个事务已经开始写操作，那么其他事务则不允许同时进行写操作，但允许其他事务读此行数据。

写操作不加锁；读操作不加锁；

2.读已提交


**对于一个事务从开始直到提交之前，所做的任何修改是其他事务不可见的**，读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。

写操作加排他锁，保持到事务结束；读操作加锁共享锁，此次查询结束后立即释放共享锁，保证读取的数据都是已提交的数据。

3.可重复读
读取数据的事务将会禁止写事务(但允许读事务)，写事务则禁止任何其他事务。保证了在同一个事务中多次读取同样数据的结果是一样的。

写操作加互斥；读操作加共享锁，保持到事务结束。不妨碍其他事务读，但其它事务无法修改这些数据，无法锁住 insert 的数据(造成幻读)；InnoDB 中， `SELECT`、`UPDATE`、`DELETE` 操作的不可重复读问题可以通过 MVCC (多版本并发控制)来解决，但是 `INSERT` 操作的幻读问题需要通过 `MVCC + Next-Key Locks` 来解决。

4.串行化  

极大的降低数据库的并发能力。读用读锁，写用写锁，读锁和写锁互斥

写操作加排他锁；读操作加排他锁；


[https://juejin.cn/post/7348288774230540297?searchId=202408201724200EA9A7BAA0A9E2061B05](https://juejin.cn/post/7348288774230540297?searchId=202408201724200EA9A7BAA0A9E2061B05)


## 9.数据库索引采用 B+ 树而不是 B 树，原因也有很多，主要原因是什么？

主要原因：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而 B 树只能中序遍历所有节点，效率太低。

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储既存索引又存记录的 B树，B+ 树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

> 树的高度决定于磁盘 I/O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说**树的高度就等于每次査询数据时磁盘 I/O 操作的次数**，所以树的高度越高，就会影响查询性能。


><font color=red>增加 B+ 树的路数可以降低树的高度，那么无限增加树的路数是不是可以有最优的查找效率？  
>这样会形成一个有序数组，文件系统和数据库的索引都是存在硬盘上的，如果数据量大，不一定能一次性加载到内存中。有序数组没法一次性加载进内存，B+树可以每次加载一个节点，一步步往下找。
></font>


## 10.听说过视图吗？那游标呢？
**视图**是一种虚拟的表，通常是有一个表或者多个表的行或列的子集，具有和物理表相同的功能，视图**只包含使用时动态检索数据的查询**；可以对视图进行增，改，查，操作，来简化数据处理以及重新格式化基础数据或保护基础数据。

对于某些视图比如未使用联结子查询分组聚集函数 Distinct Union 等，是可以对其更新的，对视图的更新将对基表进行更新；但是视图**主要用于简化检索**，保护数据，并不用于更新，而且**大部分视图都不可以更新**。


**游标**是对查询出来的结果集作为一个单元来有效的处理。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。

[http://t.csdnimg.cn/BnOiu](http://t.csdnimg.cn/BnOiu)

## 11.MySQL中为什么要有事务回滚机制？
在 MySQL 中，恢复机制是通过**回滚日志（undo log）**实现的，所有事务进行的修改都会先记录到这个 回滚日志中，然后在对数据库中的对应行进行写入。 当事务已经被提交之后，就无法再次回滚了。

回滚日志作用：

1)能够在发生错误或者用户执行 `ROLLBACK` 时提供回滚相关的信息；

2) 在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

## 12.数据库引擎 InnoDB 与 MyISAM 的区别
- **事务**：lnnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- **并发**：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- **外键**：InnoDB 支持外键。
- **备份**：InnoDB 支持在线热备份。
- **崩溃恢复**：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- **其它特性**：MyISAM 文持压缩表和空间数据索引。


适用场景：

- MYISAM适合：插入不频繁，查询非常频繁，如果执行大量的 SELECT，MyISAM 是更好的选择，没有事务。
- InnoDB适合：可靠性要求比较高，或者要求事务；表更新和查询都相当的频繁，大量的 INSERT 或 UPDATE；

## 13.数据库悲观锁和乐观锁的原理和应用场景分别有什么？
**悲观锁**，先获取锁，再进行业务操作，一般就是利用类似 `SELECT..FOR UPDATE` 这样的语句，对数据加锁，避免其他事务意外修改数据。 当数据库执行 `SELECT..FOR UPDATE` 时会获取被 `select` 中的数据行的行锁，`select for update`获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。

**乐观锁**，先进行业务操作，只在最后实际更新数据时进行检查数据是否被更新过。Java 并发包中的AtomicFieldUpdater类似，也是利用 **CAS 机制**，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

## 14.MySQL索引主要使用的两种数据结构是什么？
- **哈希索引**，对于哈希索引来说，底层的数据结构肯定是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择 BTree 索引。
- **BTree索引**，Mysql 的 BTree 索引 使用的是B树中的 B+Tree，BTREE 索引就是一种将索引值按一定的算法，存入一个树形的数据结构中(二叉树)，每次查询都是从树的入口 root 开始，依次遍历 node，获取 leaf。但对于主要的两种存储引擎(MyISAM和InnoDB)的实现方式是不同的。

## 15.数据库为什么要进行分库和分表呢？都放在一个库或者一张表中不可以吗？

<font color=red>分库与分表的目的在于，减小数据库的单库单表负担，提高查询性能，缩短查询时间。</font>

**通过分表**，可以减少数据库的单表负担，将压力分散到不同的表上，同时因为不同的表上的数据量少了，起到提高查询性能，缩短查询时间的作用，此外，可以很大的缓解表锁的问题。 分表策略可以归纳为垂直拆分和水平拆分：

- 垂直切分：基于表或者字段划分，表结构不同。
- 水平拆分：基于数据划分，表结构相同，数据不同。根据表中字段的某一列特性，分而治之。

**库内分表，仅仅是解决了单表数据过大的问题，但并没有把单表的数据分散到不同的物理机上**，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。


引入分库分表虽然可以解决数据库瓶颈问题，但是也给系统带来巨大的复杂性，不是非必须不要使用。

**分库与分表带来的分布式困境与应对之策**

- 数据迁移与扩容问题：一般做法是通过程序先读出数据，然后按照指定的分表策略再将数据写入到各个分表中。
- 分页与排序问题：需要在不同的分表中将数据进行排序并返回，并将不同分表返回的结果集进行汇总和再次排序，最后再返回给用户。

[http://t.csdnimg.cn/KcvGp](http://t.csdnimg.cn/KcvGp)

## 16.不可重复读和幻读区别是什么？可以举个例子吗？
不可重复读的重点是修改，幻读的重点在于新增或者删除。

## 17.MySQL中有四种索引类型，可以简单说说吗？
**主键索引**：`PRIMARY KEY`
主键是一种唯一性索引，但它必须指定为 `PRIMARY KEY`，每个表只能有一个主键。

  **唯一索引**：`unique index`
索引列的所有值都只能出现一次，即必须唯一，值可以为空。

**普通索引**：`index`
基本的索引类型，值可以为空，没有唯一性的限制。

**全文索引**：
全文索引的索引类型为 `FULLTEXT`。全文索引可以在 `varchar`、`char`、`text` 类型的列上创建。可以通过 `ALTER TABLE` 或 `CREATE INDEX` 命令创建。对于大规模的数据集，通过 `ALTER TABLE`（或者 `CREATE INDEX`）命令创建全文索引要比把记录插入带有全文索引的空表更快。MyISAM 支持全文索引，InnoDB 在 mysql5.6 之后支持了全文索引。

## 18.覆盖索引是什么？

**覆盖索引**（covering index ，或称为索引覆盖）即从非主键索引中就能查到的记录，而不需要查询主键索引中的记录，**避免了回表的产生减少了树的搜索次数**，显著提升性能。

**如何使用是覆盖索引：** 使用联合索引，将非主键索引与要查询的普通索引建立联合索引（name, age）.

	ALTER TABLE student DROP INDEX I_name;
	ALTER TABLE student ADD INDEX I_name_age(name, age);

	SELECT age FROM student WHERE name = '小李'；

[https://juejin.cn/post/6844903967365791752](https://juejin.cn/post/6844903967365791752)


> 索引下推(Index Condition Pushdown，简称ICP)，是MySQL5.6版本的新特性，它也能减少回表查询次数，提高查询效率。**索引下推的下推其实就是指将部分上层（服务层）负责的事情，交给了下层（引擎层）去处理**。对于InnoDB的聚簇索引来说，数据和索引是在一起的，不存在回表这一说。
> 
> [https://www.cnblogs.com/three-fighter/p/15246577.html](https://www.cnblogs.com/three-fighter/p/15246577.html)

## 19.超键、候选键、主键、外键是什么？

- **超键(super key)**：在关系中能唯一标识元组的属性集称为关系模式的超键；
- **候选键(candidate key)**：不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！
- **主键(primary key)**：用户选作元组标识的一个候选键程序主键；
- **外键(foreign key)**：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

示例：创建简单的两个表

**学生信息（学号 身份证号 性别 年龄 身高 体重 宿舍号）和 宿舍信息（宿舍号 楼号）**

超键：只要含有“学号”或者“身份证号”两个属性的集合就叫超键，例如R1（学号 性别）、R2（身份证号 身高）、R3（学号 身份证号）等等都可以称为超键！

候选键：不含有多余的属性的超键，比如（学号）、（身份证号）都是候选键，又比如R1中学号这一个属性就可以唯一标识元组了，而有没有性别这一属性对是否唯一标识元组没有任何的影响！

主键：就是用户从很多候选键选出来的一个键就是主键，比如你要求学号是主键，那么身份证号就不可以是主键了！

外键：宿舍号就是学生信息表的外键；


[https://blog.csdn.net/jerry11112/article/details/78160771](https://blog.csdn.net/jerry11112/article/details/78160771)

<font color=blue>主键为候选键的子集，候选键为超键的子集，而外键的确定是相对于主键的。</font>


## 20.数据库三大范式
**第一范式（1NF）**：要求数据库表的每一列都是不可分割的原子数据项；简而言之，第一范式就是无重复的列。

**第二范式（2NF）**：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）；简而言之，第二范式就是非主属性非部分依赖于主关键字。

>第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。


**第三范式（3NF）**：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）；简而言之，第三范式(3NF)要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。

> 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。

[数据库三大范式是什么](https://xiaolincoding.com/interview/mysql.html#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F%E6%98%AF%E4%BB%80%E4%B9%88)

数据库三大范式精要总结：

- 第一范式(1NF)：字段不可分【原子性，否则就不是关系数据库】；
- 第二范式(2NF)：有主键，非主键字段依赖主键【一个表只说明一个事务】；
- 第三范式(3NF)：非主键字段不能相互依赖【每列都与主键有直接关系，不存在传递依赖】。



## 21.事务四大特性(ACID)原子性、一致性、隔离性、持久性？
- 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态；
- 一致性：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态；
- 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。
- 一致性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失，则是通过持久性+原子性+隔离性来保证；


## 22.SQL 中的 NOW() 和 CURRENT_DATE() 两个函数有什么区别？
在 MySQL 中，NOW() 和 CURRENT_DATE() 函数都是用于**获取当前日期和时间的函数**，但是它们之间存在一些区别。

NOW() 函数返回当前日期和时间，其格式为 `"YYYY-MM-DD HH:MM:SS"`，其中 YYYY 表示年份，MM 表示月份，DD 表示日期，HH 表示小时，MM 表示分钟，SS 表示秒。

	SELECT NOW();
	2024-08-21 15:46:45

CURRENT_DATE() 函数返回当前日期，其格式为 `"YYYY-MM-DD"`，其中 YYYY 表示年份，MM 表示月份，DD 表示日期。

	SELECT CURRENT_DATE();
	2023-03-31

<font color=red>NOW() 的返回值包含小时、分钟和秒数，而 CURRENT_DATE() 只包含日期。</font>


## 23.什么是聚簇索引
**聚簇索引**是**对磁盘上实际数据重新组织以按指定的一个或多个列的值排序**的算法。特点是存储数据的顺序和索引顺序一致。一般情况下主键会默认创建聚簇索引，且一张表只允许存在一个聚簇索引（理由：数据一旦存储，顺序只能有一种）。

**聚簇索引和非聚簇索引的区别**：聚簇索引（innodb）的叶子节点就是数据节点 而非聚簇索引（myisam）的叶子节点仍然是索引文件，只是这个索引文件中包含指向对应数据块的指针。

- 优势：根据主键查询条目比较少时，不用回行(数据就在主键节点下)
- 劣势：如果碰到不规则数据插入时，造成频繁的页分裂。


聚簇索引的主键值，应尽量是**连续增长的值**，而不是要是随机值。

正文内容本身就是一种按照一定规则排列的目录称为"聚集索引”。  
这种目录纯粹是目录，正文纯粹是正文的排序方式称为"非聚集索引"

- 聚簇索引：将数据存储与索引放到了一块，**找到索引也就找到了数据**；
- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。


## 24.创建索引时需要注意什么？
- **非空字段**：应该指定列为 `NOT NULL`，除非你想存储 `NULL`。在 MySQL 中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替空值；
- **取值离散大的字段**：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过 `count()` 函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
- **索引字段越小越好**：数据库的数据存储以页为单位，一页存储的数据越多，一次 I/O 操作获取的数据越大，效率越高。 唯一、不为空、经常被查询的字段的字段适合建索引。

## 25.MySQL中CHAR和VARCHAR的区别有哪些？
varchar 和 char 都是MySQL中**用于存储字符串的数据类型**。

 char 是**固定长度**的数据类型，需要在创建表时指定一个固定的长度。 

varchar 是**可变长度**的数据类型，不需要指定固定的长度，只占用实际存储字符串长度所需的存储空间。

char 的存取数度还是要比 varchar 要快得多；

char 的存储方式是：对英文字符（ASCII）占用 1 个字节，对一个汉字占用两个字节。

varchar 的存储方式是：对每个英文字符占用 2 个字节，汉字也占用 2 个字节。

## 26.既然索引有那么多优点，为什么不对表总的每一列创建一个索引呢？
- 当对表中的数据进行增加、删除和修改的时候，**索引也要动态的维护**，这样就降低了数据的维护速度。
- **索引需要占物理空间**，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立簇索引，那么需要的空间就会更大。
- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加；


## 27.MySQL 索引使用的注意事项？
MySQL 索引通常是被用于提高 `WHERE` 条件的数据行匹配时的搜索速度，在索引的使用过程中，存在一些使用细节和注意事项。

函数，运算，否定操作符，连接条件，多个单列索引，最左前缀原则，范围查询，不会包含有 `NULL` 值的列，`like` 语句不要在列上使用函数和进行运算。


## 28.索引失效有哪些？
- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列使用函数，就会导致索引失效；
- 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的；
- MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。


## 29.mysql 使用索引的注意事项
（1）选择唯一性的列索引；

（2）为经常需要排序、分组和联合操作的字段建立索引，为常作为查询条件的字段建立索引；

（3）限制索引的数量，删除不再使用或者很少使用的索引；

（4）尽量使用数据量少的索引；

（5）尽量使用前缀来索引；

（6）= 和 in 内是可以乱序的；

（7）尽量选择区分度高的列作为索引，即：索引选择性。

[http://t.csdnimg.cn/CdlFN](http://t.csdnimg.cn/CdlFN)


## 30.说一下数据库表锁和行锁吧
**表锁**  

不会出现死锁，发生锁冲突几率高，并发低。
在执行查询语句(`select`)前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。

MySQL的表级锁有两种模式：**表共享读锁**和**表独占写锁**。

**读锁会阻塞写，写锁会阻塞读和写**

MyISAM 不适合做写为主表的引擎，因为写锁后，其它线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。

表锁适合于需要大批量操作表中数据的场景，例如表的重建、大量数据的加载等。

**行锁**

会出现死锁，发生锁冲突几率低，并发高。  
在 MySQL 的 InnoDB 引擎支持行锁，与 Oracle 不同，**MSQL 的行锁是通过索引加载的**，也就是说，**行锁是加在索引响应的行上的**，要是对应的 SQL 语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。

行锁适合于需要频繁对表中单独行进行操作的场景，例如订单系统中的订单修改、删除等操作。

## 31.SQL语法中内连接、自连接、外连接(左、右、全)、交叉连接的区别分别是什么？
外连接分为外左连接(left outer join)和外右连接(right outer join)

- **左连接**，取左边的表的全部，右边的表按条件，符合的显示，不符合则显示null；
- **右连接**：取右边的表的全部，左边的表按条件，符合的显示，不符合则显示null；

**内连接**：也称为等值连接，返回两张表都满足条件的部分；【`inner join` 就等于 `join` 】

**交叉连接**：返回左表中的所有行，左表中的每一行与右表中的所有行组合。交叉联接也称作**笛卡尔积**

	SELECT O.ID, O.ORDER_NUMBER, C.ID, C.NAME
	FROM ORDERS O CROSS JOIN CUSTOMERS C
	WHERE O.ID=1;

看：
[http://t.csdnimg.cn/4ymyh](http://t.csdnimg.cn/4ymyh)

## 32.为什么 MySQL 索引要使用 B+ 树，而不是 B 树或者红黑树？
B-树、B+树、红黑树，都是平衡查找树，那么查询效率上讲，平均都是 `O(logn)`。

**不用B-树：**

一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。**B-树/B+树 的特点就是每层节点数目非常多，层数很少，目的就是为了减少磁盘IO次数**，但是**B-树的每个节点都有data域（指针**），这无疑增大了节点大小，说白了**增加了磁盘IO次数**（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。


- B+优点一： B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。
- B+优点二： B+树所有的Data域在叶子节点，并且所有叶子节点之间都有一个链指针。 这样遍历叶子节点就能获得全部数据，这样就能进行区间访问啦。在数据库中基于范围的查询是非常频繁的，而B树不支持这样的遍历操作。

**不用红黑树**：

AVL 树（平衡二叉树）和红黑树（二叉查找树）基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，红黑树往往出现由于**树的深度过大而造成磁盘I/O读写过于频繁**，进而导致效率低下的情况。


**不用哈希表：**

利用Hash需要把数据全部加载到内存中，如果数据量大，是一件很消耗内存的事，而采用B+树，是基于按照节点分段加载，由此减少内存消耗。并且，从业务场景上说，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条，这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。


[http://t.csdnimg.cn/w0ohE](http://t.csdnimg.cn/w0ohE)

## 33.数据库高并发是我们经常会遇到的，你有什么好的解决方案吗？
- 在 web 服务框架中加入缓存。在服务器与数据库层之间加入缓存层，将高频访问的数据存入缓存中，减少数据库的读取负担；
- 增加数据库索引，进而提高查询速度。(不过索引太多会导致速度变慢，并且数据库的写入会导致索引的更新也会导致速度变慢)；
- 主从读写分离，让主服务器负责写，从服务器负责读；
- 将数据库进行拆分，使得数据库的表尽可能小，提高查询的速度；
- 使用分布式架构，分散计算压力。


## 34.日志文件是分成了哪几种？
- redo log 重做日志，是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；redo log 是物理日志，记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。
- undo log 回滚日志，是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。
- bin log 二进制日志，是 Server 层生成的日志，主要用于数据备份和主从复制；binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志，用于备份恢复、主从复制；


## 35.update语句的具体执行过程是怎样的？
具体更新一条记录 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 的流程如下：

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录；
 - 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
 - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
 - 如果一样的话就不进行后续更新流程；
 - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。
4. InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。
7. 事务提交（两阶段）：
 - prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
 - commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；
8. 至此，一条更新语句执行完成。

----------

# 嵌入式

<font color=blue>串口、UART口、COM口、USB口是指的物理接口形式(硬件)。而TTL、RS-232、RS-485是指的电平标准(电信号)。</font>

## 1.串口协议（UART/USART）
UART（通用异步收发器）、USART（通用同步异步收发器）。


**UART 通用异步收发器**

- UART 是**异步**，**全双工**串口总线。它比同步串口复杂很多。有两根线，一根 TXD 用于发送，一根 RXD 用于接收。
- UART的串行数据传输**不需要使用时钟信号来同步传输**，而是依赖于发送设备和接收设备之间预定义的配置。
- 对于发送设备和接收设备来说，两者的串行通信配置应该设置为完全相同。

<img src="https://static.mianbaoban-assets.eet-china.com/xinyu-images/MBXY-CR-525d8e4c7fc1632e016588798db46c10.png" width="300">

<img src="https://static.mianbaoban-assets.eet-china.com/xinyu-images/MBXY-CR-1e98839afc4e54c9af312efb02bdf886.png" width="500">

- **起始位**：表示数据传输的开始，电平逻辑为“0” 。
- **数据位**：可能值有5、6、7、8、9，表示传输这几个bit 位数据。一般取值为8，因为一个ASCII 字符值为8 位。
- **奇偶校验位**：用于接收方对接收到的数据进行校验，校验“1” 的位数为偶数(偶校验) 或奇数(奇校验)，以此来校验数据传送的正确性，使用时不需要此位也可以。
- **停止位**：表示一帧数据的结束。电平逻辑为“1”。
- **波特率**：串口通信时的速率，它用单位时间内传输的二进制代码的有效位(bit) 数来表示，其单位为每秒比特数bit/s(bps)。


[https://blog.csdn.net/qq_38410730/article/details/79887200](https://blog.csdn.net/qq_38410730/article/details/79887200)

**USART**  
总线信号： TX， RX， CK


**USART和UART的区别**

1. USART和UART之间的一个区别是可以为串行数据提供时钟的方式。 **UART 在内部向微控制器生成其数据时钟**，并通过使用起始位转换将该时钟与数据流同步。没有与数据相关的输入时钟信号，因此为了正确接收数据流，**接收器需要提前知道波特率应该是什么**。USART可以设置为以同步模式运行。在此模式下，发送外设将生成一个时钟，接收外设可以从数据流中恢复，而**无需提前知道波特率**。或者，链路将使用完全独立的线路来承载时钟信号。使用外部时钟可使USART的数据速率远高于标准UART的数据速率，上限可达4 Mbps。

2. 第二个主要区别是外设可以支持的协议数量。 UART很简单，**只提供其基本格式的一些选项**，例如停止位数和偶数或奇数奇偶校验。 USART更复杂，可以以与许多不同标准协议相对应的形式生成数据，例如IrDA，LIN，智能卡，RS-485接口的驱动程序启用和Modbus等。 USART也具有与UART相同的异步功能。

[http://m.jd-dz.com/news/451.html](http://m.jd-dz.com/news/451.html)


COM 口( cluster communication port )即串行通讯端口，简称串口。微机上的串口通常是9针，也有25针的接口，最大速率115200bps。

<img src="https://wiki.sipeed.com/soft/maixpy/assets/get_started/uart.jpg" width=300>

通常用于连接鼠标（串口）及通讯设备（如连接外置式调制解调器进行数据通讯或一些工厂的数控机接口）等。

一般主板外部只有一个串口，机箱后面和并口一起的那个九孔输出端（梯形），就是COM1口，COM2口一般要从主板上插针引出。并口是最长的那个梯形口；

目前主流的主板一般都只带1个串口，甚至不带，慢慢会被USB 取代。




## 2.RS232和RS485协议
串口、COM口是指的物理接口形式(硬件)。而TTL、RS-232、RS-485是指电平标准(电信号)。

- 单片机的电平标准（**TTL电平**）：+5V表示1，0V表示0；
- Rs232的电平标准：+15/+13 V表示0，-15/-13表示1。

**RS232串口通信**  
传输线有两根，地线一根。电平是负逻辑：

`-3V~-15V`逻辑“1”，`+3V~+15V`逻辑“0”。

RS-232串口通信传输距离15米左右。可做到双向传输，全双工通讯，传输速率低20kbps 。

下图是DB9公头和母头的定义，一般用最多的是RXD、TXD、GND三个信号。


**RS422串口通信**

RS-422有4根信号线：两根发送、两根接收和一根地线，是全双工通信。

它有一个主设备，其余为从设备，从设备之间不能通信，所以RS-422支持点对多的双向通信。

**RS-485 采用平衡发送和差分接收，因此具有抑制共模干扰的能力。**  
采用两线半双工传输，最大速率10Mb/s，电平逻辑是两线的电平差来决定的，提高抗干扰能力，传输距离长(几十米到上千米)。

`+2V~+6V`逻辑“1”，`-2~-6V`逻辑“0”。

> **差分传输**是一种信号传输的技术，区别于传统的一根信号线一根地线的做法，**差分传输在这两根线上都传输信号，这两个信号的振幅相同，相位相反**。在这两根线上的传输的信号就是差分信号。信号接收端比较这两个电压的差值来判断发送端发送的逻辑状态。

## 3.IIC协议
I2C 总线是一种同步、半双工双向的两线式串口总线。它由两条总线组成：**串行时钟线** SCL 和**串行数据线** SDA。这两条数据线需要接**上拉电阻**，总线空闲的时候 SCL 和 SDA 处于高电平。

- SCL线——负责产生同步时钟脉冲。
- SDA线——负责在设备间传输串行数据。

<img src="https://static.mianbaoban-assets.eet-china.com/xinyu-images/MBXY-CR-3804d7cef41125832e6f97c84ebbf3d2.png" width="300">

该总线可以将多个 I2C 设备连接到该系统上。连接到 I2C 总线上的设备既可以用作主设备，也可以用作从设备。

**为什么使用I2C？**

- I2C总线目前仍然是各种电路常用的通信外设，且实现简单。无论总线上连接多少个设备，只需要两条信号线（时钟SCL和数据SDA）。
- 它是真正的多主总线，优于SPI。
- 此外，I2C 接口也很灵活，使其能够与慢速设备通信，同时还具有高速模式来传输大数据。标准模式下传输速率可达100kbit/s，快速模式下可达400kbit/s，高速模式下可达3.4Mbit/s；
- 由于其灵活性，I2C 将始终是连接设备的最佳通信外设之一。

主设备负责控制通信，通过对数据传输进行初始化，来发送数据并产生所需的同步时钟脉冲。从设备则是等待来自主设备的命令，并响应命令接收。

主设备和从设备都可以作为发送设备或接收设备。无论主设备是作为发送设备还是接收设备，**同步时钟信号都只能由主设备产生**。

> 主机发送数据给从器件流程：
> 
> 1.主机首先寻址从器件（因为要支持多个器件之间进行相互通信，所以要为每一个器件进行编址）；  
> 2.然后主动发送数据至从器件，最后由主机终止数据传送；

> 主机接收从器件的数据流程：
>
> 1.主器件寻址从器件，然后主机接收从器件发送的数据；   
> 2.最后主机终止接收过程，在这种情况下主机负责产生定时时钟和终止数据传送。  

<font color=red>

- 当SCL为高电平而SDA由高到低的跳变，表示产生一个起始条件；
- 当SCL为高而SDA由低到高的跳变，表示产生一个停止条件。
- I2C 总线在数据传输的时候要保证在 SCL 高电平期间， SDA 上的数据稳定，因此 SDA 上的数据变化只能在 SCL 低电平期间发生。

</font>

<img src="https://i-blog.csdnimg.cn/blog_migrate/2d1a86fa068fa183ed6f40db34fa4b51.png" width="500">


 主设备在SCL线上产生每个时钟脉冲的过程中将在SDA线上传输一个数据位当一个字节按数据位从高位到低位的顺序传输完后，紧接着从设备将拉低SDA线，**回传给主设备一个应答位，此时才认为一个字节真正被传输完成。**

当然，并不是所有的字节传输都须有一个应答位，比如当从设备不能再接收主设备发送的数据时，从设备将回传一个**非响应应答位**。



**I2C通信的步骤**

- 步骤1：主设备将产生一个开始信号，向其他设备发出信号，开始监听总线并准备接收数据。（SCL高，SDA由高变低）当发送启动信号条件时，总线将进入繁忙状态，其中当前数据传输仅限于选定的主设备和从设备。只有在产生停止条件后，总线才会被释放并再次处于空闲模式。
- 步骤2：主设备向每个设备发送一个7位设备地址加上一位读写数据帧。该位还将指示下一个数据传输的方向。0 = 主设备向从设备写入数据。1 = 主设备读取数据到从设备。
- 步骤3：每个从机将主机发送的地址与自己的地址进行比较。成功匹配地址的从设备通过拉低 SDA 线返回 ACK 位。
- 步骤4：当主设备收到从设备的确认信号后，开始发送或接收数据。下图是向指定设备传输数据的过程图。 
- 步骤5：接收设备发送完每个数据帧后，向发送方返回另一个ACK位，以确认该帧已成功接收，然后发送方继续发送该数据帧，以此类推。
- 步骤6：当数据传输完成后，主设备会向其他设备发出停止信号，释放总线，总线进入空闲状态。

<img src="https://i-blog.csdnimg.cn/blog_migrate/8c494a0cd16a3c33b727434369849772.jpeg">

[https://blog.csdn.net/weixin_39939185/article/details/131834694](https://blog.csdn.net/weixin_39939185/article/details/131834694)

## 4.SPI协议
**SPI(Serial Peripheral Interface，串行外设接口)** 协议是一种高速高效率、全双工的通信总线，允许 CPU 与低速的外围设备之间进行同步串行数据的传输，主要是**用同步的时钟信号对串行的数据同时进行发送和接收操作，从而实现全双工**。常用于短距离通讯，主要是在嵌入式系统中。

SPI 总线是同步、全双工双向的 4 线式串行接口总线。它是由“单个主设备+多个从设备”构成的系统。

在系统中，只要任意时刻只有一个主设备是处于激活状态的，就可以存在多个 SPI 主设备。常运用于 AD 转换器、EEPROM、FLASH、实时时钟、数字信号处理器和数字信号解码器之间实现通信。

<img src="https://static.mianbaoban-assets.eet-china.com/xinyu-images/MBXY-CR-bf2469d63accd8e8aadbaa8155f465e7.png" width="300">

为了实现通信，SPI共有4条信号线，分别是：

- 主设备出、从设备入（Master Out Slave In，MOSI）：由主设备向从设备传输数据的信号线，也称为从设备输入（Slave Input/Slave Data In，SI/SDI）；
- 主设备入、从设备出（Master In Slave Out，MISO）：由从设备向主设备传输数据的信号线，也称为从设备输出（Slave Output/Slave Data Out，SO/SDO）；
- 串行时钟（Serial Clock，SCLK）：传输时钟信号的信号线；
- 从设备选择（Slave Select，SS）：用于选择从设备的信号线，低电平有效；

在**常规模式下**，主机需要为每个从机提供单独的片选信号。一旦主机使能(拉低)片选信号，MOSI/MISO线上的时钟和数据便可用于所选的从机。如果使能多个片选信号，则MISO线上的数据会被破坏，因为主机无法识别哪个从机正在传输数据。

在**菊花链模式**下，所有从机的片选信号连接在一起，数据从一个从机传播到下一个从机。在此配置中，所有从机同时接收同一SPI时钟。来自主机的数据直接送到第一个从机，该从机将数据提供给下一个从机 。

**SPI数据通信的流程可以分为以下四步：**   
1、主设备发起信号，将 CS/SS 拉低，选择片选，启动通信；  
2、主设备通过发送时钟信号，来告诉从设备进行写数据或者读数据操作（采集时机可能是时钟信号的上升沿（从低到高）或下降沿（从高到低），根据 spi 模式而定），它将立即读取数据线上的信号，这样就得到了一位数据（1bit）；          
3、主机（Master）将要发送的数据写到发送数据缓存区（Memory），缓存区经过移位寄存器（缓存长度不一定，看单片机配置），串行移位寄存器通过 MOSI 信号线将字节一位一位的移出去传送给从机，同时MISO接口接收到的数据经过移位寄存器一位一位的移到接收缓存区。   
4、从机（Slave）也将自己的串行移位寄存器（缓存长度不一定，看单片机配置）中的内容通过MISO信号线返回给主机。同时通过MOSI信号线接收主机发送的数据，这样，两个移位寄存器中的内容就被交换。

当MASTER片选一个SLAVE时，每向SLAVE发送一个周期的SCLK信号，都会有1bit的数据从MOSI发送至slave，与此同时，slave每收到一个周期的SCLK信号，都会从MISO向master发送1bit的数据。这种全双工通讯，是由硬件保证的（MASTER与HOST中各有一个移位寄存器作为收发数据的缓存）。


SPI 总线上的数据传输**由串行时钟 SCK 进行同步处理**，串行时钟 SCK 由 SPI 主机产生，每个时钟周期仅发送 1bit 数据。，SPI有四种操作模式——SPI0、SPI1、SPI2和SPI3，它们的区别是**定义了在时钟脉冲的哪条边沿转换（toggles）输出信号，哪条边沿采样输入信号，还有时钟脉冲的稳定电平值（就是时钟信号无效时是高还是低）**。  
每种模式由一对参数刻画，它们称为 **时钟极性（clock polarity）** CPOL与 **时钟相位（clock phase）** CPHA。

**CPOL 表示时钟信号的初始电平的状态**，CPOL 为 0 表示时钟信号初始状态为低电平，为1 表示时钟信号的初始电平是高电平。  
**CPHA 表示在哪个时钟沿采样数据**，CPHA 为 0 表示在首个时钟变化沿采样数据，而 CPHA 为1 则表示在第二个时钟变化沿采样数据。

根据CPOL 和CPHA 的不同组合共有4 种工作时序模式：

	CPOL=0，CPHA=0
	CPOL=0，CPHA=1
	CPOL=1，CPHA=0
	CPOL=1，CPHA=1


[https://blog.csdn.net/Luckiers/article/details/131297469](https://blog.csdn.net/Luckiers/article/details/131297469)


**SPI协议优缺点总结**

优点：

1. 无起始位和停止位，因此数据位可以连续传输而不会被中断；
1. 没有像I2C这样复杂的从设备寻址系统；
1. 数据传输速率比I2C更高（几乎快两倍）；
1. 分离的MISO和MOSI信号线，因此可以同时发送和接收数据；
1. 极其灵活的数据传输，不限于8位，它可以是任意大小的字；
1. 非常简单的硬件结构。从站不需要唯一地址（与I2C不同）。从机使用主机时钟，不需要精密时钟振荡器/晶振（与UART不同）。不需要收发器（与CAN不同）。

缺点：

1. 使用四根信号线（I2C和UART使用两根信号线）；
1. 无法确认是否已成功接收数据（I2C拥有此功能）；
1. 没有任何形式的错误检查，如UART中的奇偶校验位；
1. 只允许一个主设备；
1. 没有硬件从机应答信号（主机可能在不知情的情况下无处发送）；
1. 没有定义硬件级别的错误检查协议；
1. 与RS-232和CAN总线相比，只能支持非常短的距离

## 5.CAN协议

CAN 是**( Controller Area Network ) 控制器局域网络**的简称，是一种能够实现分布式实时控制的**串行通信网络**。CAN总线的功能复杂且智能。主要用于汽车通信，相关文章：CAN总线详解。

CAN 总线网络主要挂在 `CAN_H` 和 `CAN_L`，各个节点通过这两条线实现信号的串行差分传输，为了避免信号的反射和干扰，还需要在 `CAN_H` 和 `CAN_L` 之间接上120欧姆的终端电阻。通信线（CAN_H、CAN_L）线路少，无需共地（其中例如IIC协议 由于是单端信号 必须共地）



<img src="https://static.mianbaoban-assets.eet-china.com/xinyu-images/MBXY-CR-24767d812c6f9d963b13bb824bcc038b.png" width="300">

每一个设备既可做主设备也可做从设备。CAN总线的通信距离可达10千米（速率低于5Kbps），速度可达1Mbps（通信距离小于40M）。

CAN总线采用"线与"的规则进行总线仲裁，1&0为0，所以称0为显性，1为隐性。

从电位上看，因为规定高电位为 0，低电位为 1，同时发出信号时实际呈现为高电位，从现象上看就像 0 覆盖了1，所以称0为显性，1 为隐性。

CAN节点通常由三部分组成：**CAN收发器、CAN控制器和MCU**。

CAN总线通过差分信号进行数据传输，CAN收发器将差分信号转换为TTL电平信号，或者将TTL电平信号转换为差分信号，CAN控制器将TTL电平信号接收并传输给MCU。

![](https://pic3.zhimg.com/80/v2-6e1466769abec75450b48b9e79f4b830_720w.webp)

CAN总线是一种**广播类型**的总线，可支持线形拓扑、星形拓扑、树形拓扑和环形拓扑等。**CAN网络中至少需要两个节点设备才可进行通信，无法仅向某一个特定节点设备发送消息**，发送数据时所有节点都不可避免地接收所有流量。但是，**CAN总线硬件支持本地过滤，因此每个节点可以设置对有效的消息做出反应**。


[https://blog.csdn.net/qq_38880380/article/details/84573821](https://blog.csdn.net/qq_38880380/article/details/84573821)

[https://zhuanlan.zhihu.com/p/662099209](https://zhuanlan.zhihu.com/p/662099209)

## 6.USB通信串行总线

深入理解 USB 通信协议(详解)

USB接口最少有四根线，其中有两根是数据线，而所有的USB数据传输都是通过这两根线完成。它的通信远比串口复杂的多。

两根数据线采用差分传输，即需要两根数据线配合才能传输一个bit，因此是半双工通信，同一时间只能发送或者接收。

USB 规定，如果电压电平不变，代表逻辑1；如果电压电平变化，则代表逻辑0。


<img src="https://wiki.sipeed.com/soft/maixpy/assets/get_started/usb_vs_uart.png">

## 7.DMA直接存储器访问
DMA 是 STM32 内的一个硬件模块，它独立于 CPU，在外围设备和内存之间进行数据传输，解放了CPU，可使CPU的效率大大提高。

它可以高速访问外设、内存，传输不受CPU的控制，并且是双向通信。因此，使用DMA可以大大提高数据传输速度，这也是ARM架构的一个亮点——DMA总线控制。

DMA就相应于一条高速公路，专用、高速的特性。如果不使用DMA，也可以达到目的，只是达到目的的时间比较长。


[嵌入式开发中常用的几种通信接口总结](https://www.eet-china.com/mp/a244872.html)


## 8.PCB 与 TCB
**进程控制块（process control block，PCB）**

- 进程描述信息【进程标识符、用户标识符】；
- 进程控制和管理信息【进程当前状态、进程优先级】；
- 资源分配清单【有关内存地址空间或虚拟地址空间的信息、内存空间范围】；
- CPU 相关信息【CPU 中各个寄存器的值】；
- 锁、信号量等同步机制与上下文信息；

通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列【就绪队列、阻塞队列】


**线程控制块（Thread Control Block, TCB）**

- 线程ID；
- 线程状态寄存器；
- 锁、信号量等同步机制与上下文信息；
- 线程优先级。

## 9.上下文切换

进程是程序的一次执行过程，**拥有自己的地址空间和资源**，是资源分配的基本单位。进程之间通过上下文切换来共享CPU，保证公平分配。进程切换涉及到保存和加载进程的相关信息、状态变更、队列操作、调度算法等。


线程是进程中的独立执行流程，可以共享进程的资源，但**有独立的寄存器和栈**。线程的上下文切换相比进程较小，只需要保存线程的相关寄存器和计数器等信息。



## 10.程序的装入、静态链接、动态链接
**1.绝对装入（编译时确定绝对地址）**   
在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件(装入模块)，之后不再拆开。在另一台内存不同的电脑上可能无法运行；

**2.静态重定位（保存相对地址）（读取时转换）**   
编译、链接后存放为逻辑地址，保存的都是相对于 0 地址的相对值；   
地址空间必须连续且读入内存时，对所有逻辑地址进行运算，转换为物理地址（读入时），将各目标模块装入内存时，边装入边链接的链接方式。

**3.动态重定位（保存相对地址）（运行时转换）**  
程序读入内存后，并不直接计算物理地址，实际执行时才进行转换，将逻辑地址转换为物理地址（调用时），便于修改和更新，便于实现对目标模块的共享。

## 11.ARM 汇编
ARM微处理器支持加载/存储指令**用于在寄存器和存储器之间传送数据**，加载指令用于将存储器中的数据传送到寄存器，存储指令则完成相反的操作。常用的加载存储指令如下：

- `LDR`     字数据加载指令	【存储器 -> 寄存器】
- `LDRB`    字节数据加载指令
- `LDRH`    半字数据加载指令
- `STR`     字数据存储指令	【寄存器 -> 存储器】
- `STRB`    字节数据存储指令
- `STRH`    半字数据存储指令


[https://www.cnblogs.com/blogernice/articles/13840178.html](https://www.cnblogs.com/blogernice/articles/13840178.html)



## 12.Linux嵌入式驱动开发的流程
1. **了解硬件设备及其规范**：首先要对目标硬件设备进行研究，包括芯片型号、外设接口、寄存器规范等。同时，对于设备的功能和特性也需要有基本的了解。
2. **编写设备树（Device Tree）描述文件**：Linux内核使用设备树来描述硬件设备的信息。需要编写设备树描述文件，以便内核能够识别和配置硬件设备。
3. **编写驱动程序源码**：根据设备的规格和需求，编写对应的驱动程序源码。通常需要涉及到底层寄存器的读写、中断处理、设备初始化和资源分配等操作。
4. **将驱动程序源码添加到内核源码树**：将驱动程序源码添加到Linux内核源码树，并在内核配置选项中选择该驱动模块进行编译。
5. **构建并刷写内核镜像**：完成驱动程序源码的添加和内核配置后，进行内核的构建。通过编译得到的内核镜像可以刷写到目标嵌入式设备上。
6. **调试和测试**：将构建好的内核镜像刷写到目标设备，并进行调试和测试。检查设备与驱动之间的通信，确保驱动程序能够正确地初始化设备并提供所需的功能。
7. **优化和性能测试**：根据实际使用情况对驱动程序进行优化，并进行性能测试。通过性能测试来评估驱动程序的性能，并进行必要的调整和优化。


## 13.Linux内核的组成
**五部分**：进程管理、内存管理、进程间通信、虚拟文件系统、网络接口

1. 进程管理与调度

2. 内存管理：Linux内存管理对于每个进程完成从虚拟内存到物理内存的转换；

3. 虚拟文件系统：隐藏硬件的细节，采用vfs_read，vfs_write等接口

4. 网络接口：分为网络协议和网络驱动程序

5. 进程间通信：信号量、共享内存、消息队列、管道等，实现资源互斥、同步


## 14.系统调用read() write()，内核具体做了哪些事情

用户空间read()-->内核空间sys_read()-->scull_fops.read-->scull_read()；

**过程分为两个部分：用户空间的处理和内核空间的处理。**

在用户空间中通过 0x80 中断的方式将控制权交给内核处理，

内核接管后，经过6个层次的处理最后将请求交给磁盘，由磁盘完成最终的数据拷贝操作。在这个过程中，调用了一系列的内核函数


## 15.Bootloader内核 、根文件的关系
启动顺序：bootloader->linuxkernel->rootfile

- u-boot：初始化硬件，将内核装载入RAM，设置 SP 与 PC，准备启动内核；
- kernel：（底层驱动向内核注册，上层应用向内核调用）启动并挂载 rootfile（存放了文件、库、命令）；
- rootfile：业务涉及的文件系统；


## 16.Bootloader启动过程
**上电后运行的第一个程序：bootloader（u-boot）（universal bootloader）**

- 典型嵌入式系统的部署：uboot程序（类似BIOS）部署在Flash(能作为启动设备的NorFlash)上、OS部署在FLash(嵌入式系统中用Flash代替了硬盘)上、内存在掉电时无作用，CPU在掉电时不工作。
- 启动过程：嵌入式系统上电后先执行uboot、然后 uboot 负责初始化DDR，初始化 Flash，然后将 OS 从 Flash 中读取到 DDR 中，然后启动 OS(OS启动后uboot就无用了）。

总结：嵌入式系统和PC机的启动过程几乎没有两样，只是BIOS成了uboot，硬盘成了Flash。

**Stage1（汇编实现，依赖cpu体系结构初始化）**

- 进行硬件的初始化（watchdog, ram 初始化）；
- 为Stage2加载代码准备RAM空间；
- 复制Stage2阶段代码到RAM空间；
- 设置好栈；
- 跳转到第二阶段代码的入口点；


**Stage2（c语言实现，具有好的可读性和移植性）**

- 初始化该阶段所用到的硬件设备；
- 检测系统内存映射；
- 将uImage ,Rootfs，dtb文件从flash读取到RAM内存中；
- 设置内核启动参数。（如通过寄存器传递设备树文件的内存地址）


## 17.Linux启动流程
1. **引导加载程序（Bootloader）启动**：U-Boot 被加载到内存中执行。 U-Boot 提供了一个命令行界面，用户可以在这个界面上进行配置和操作。
2. **加载内核和备树文件**：通过 U-Boot 的命令，加载 Linux 内核（kernel）和设备树（device tree）文件到内存中，启动 Linux 内核：U-Boot控制权交给 Linux 内核，内核开始执行。内核会初始化系统硬设置页表、启动调度器等。
3. **启动 init 进程**：在内核初始化完成后，内核会执行 init 进程，init 进程是用户空间的第一个进程。 init 进程负责启动其他系统服务，并根据配置加载所需的模块。
4. **用户空间初始化**：init 进程会根据配置启动用户空间的各个进程和服务，完成系统的初始化。


>**进程0**：Linux引导中创建的第一个进程，完成加载系统后，演变为进程调度、交换及存储管理进程。  
>**进程1**：init 进程，由0进程创建，完成系统的初始化，是系统中所有其它用户进程的祖先进程。


## 18.设备树
**Linux设备树（Device Tree）** 是一种描述硬件设备和设备间关系的数据结构，用于在嵌入式系统中配置和管理硬件。它是一种与平台无关的机制，它将硬件设备的相关信息以一种可移植的格式储存在一个或多个设备树文件中。

设备树文件是以一种层级结构的形式描述硬件设备及其属性。它包含了设备的类型、寄存器地址、中断、时钟等信息，以及设备间的关系和依赖关系。通过解析设备树文件，内核可以获取设备的配置信息，并正确地初始化和管理硬件设备。


## 19.Linux 命令
**1.搜索**

    grep *.c
    grep -n "linux" test.txt // 查找文件中的关键字并显示行号

**2.搜索文件**

    find /home/user/dir -type f -name "*.c"
    -type f 表示只搜索文件，而不包括目录

**3.进程**

    ps：查看进程
    pstree：查看父子进程关系

**4.内存占用**

    free –h：系统相关RAM使用情况（物理内存、交换内存）
    top：查看系统CPU、进程、内存使用情况

**5.磁盘占用**
   
    df -h：查看磁盘占用

**6.关机、重启、挂起、节电**

    shutdown -h now
    shutdown -h +10 // 延时10min
    shutdown -h 19:30
    sudo reboot
    sudo pm-suspend
    sudo pm-powersave
'
**7.文件大小写转换**

    cat file | tr a-z A-Z > newfile #将文件内容转换为大写


## 20.手动释放内存的方法
采用TOP命令查看内存张后，采用`/proc/sys/vm/drop_caches`来释放内存：

    echo 0~3 > /proc/sys/vm/drop_caches

drop_caches的值可以是0-3之间的数字，代表不同的含义：

    0：不释放（系统默认值）
    1：释放页缓存
    2：释放dentries和inodes
    3：释放所有缓存

## 21.Linux权限

文件角色有3种：

- 文件拥有者 ：谁创建这文件谁就是拥有者；
- 文件所属组 ：所有用户都要隶属于某一个组，哪怕只有一个人；
- 其他人 ：除了拥有者之外的人都是 other。


- **更改拥有者** ： 需要 sudo 提升到管理员身份才能修改
- **更改所属组** ：sudo chgrp yz func.c



## 22.Linux的7种文件类型
1. 普通文件类型   
Linux中最多的一种文件类型, 包括 纯文本文件；二进制文件；数据格式的文件；各种压缩文件。第
一个属性为 [-]；
2. 目录文件  
就是目录， 能用 cd 命令进入的。第一个属性为 [d]；
3. 块设备文件    
块设备文件 ： 硬盘。例如一号硬盘的代码是 /dev/hda1等文件。第一个属性为 [b]；
4. 字符设备     
即串行端口的接口设备，例如键盘、鼠标等等。第一个属性为 [c]；
5. 套接字文件    
这类文件通常用在网络数据连接。可以启动一个程序来监听客户端的要求，客户端就可以通过套接字来进行数据通信。第一个属性为 [s]，最常在 /var/run目录中看到这种文件类型；  
6. 管道文件  
FIFO也是一种特殊的文件类型，它主要的目的是，解决多个程序同时存取一个文件所造成的错误。第一个属性为 [p]；
7. 链接文件
类似 Windows下面的快捷方式。第一个属性为 [l]

## 23.




# CMAKE

[https://zhuanlan.zhihu.com/p/662623216](https://zhuanlan.zhihu.com/p/662623216)

## 1.什么是CMake？
 CMake是一个跨平台的自动化构建系统，主要用来管理软件构建的过程，它使用一个名为 CMakeLists.txt 的配置文件来指导编译和链接的过程。CMake支持多种编译器和开发环境，可以生成标准的构建文件，如Makefile或者Visual Studio的项目文件。它不仅能够管理C/C++项目的构建，还支持多种编程语言和库的集成。


## 2.CMakeLists.txt文件的基本结构是什么？
 CMakeLists.txt文件通常包含一系列的CMake命令，用来定义项目的属性、包含的源文件、依赖的库等。

基本结构包括：

- cmake_minimum_required(VERSION x.x): 指定项目需要的最低CMake版本。
- project(ProjectName): 定义项目的名称和使用的语言。
- add_executable(TargetName source1 source2 ...)： 添加一个可执行目标，并指定其源文件。
- add_library(TargetName type source1 source2 ...)：添加一个库目标，并指定其类型（静态或动态）和源文件。
- find_package(PackageName)：查找并加载外部依赖包。
- target_link_libraries(TargetName library1 library2 ...)：指定目标链接的库。

这些是最基础和最常用的指令，当然还有更多高级功能和指令可以使用。


## 3.如何处理项目中的依赖关系？
我通常会使用 `find_package` 命令来查找并加载外部依赖包。如果依赖的库是通过CMake构建的，那么它通常会提供CMake的配置文件，使得 `find_package` 可以直接找到并加载库。如果库没有提供CMake支持，我可能需要手动设置库的路径和链接库。一旦找到依赖库，我会使用 `target_link_libraries` 来链接库，并使用 `target_include_directories` 来添加头文件的搜索路径。

## 4.如何确保构建的可移植性？
为了确保构建的可移植性，我会避免使用平台特定的代码和构建设置。我会使用 CMake 提供的检查和配置功能来查询平台特性，并根据查询的结果来调整构建设置。例如，我可以使用 check_function_exists 来检查某个函数是否存在，然后根据结果定义宏来启用或禁用相关的代码。我还会确保使用 CMake 提供的命令来设置编译器标志和定义，而不是直接写死在 CMakeLists.txt 文件中。

## 5.如何组织大型项目的CMake构建系统？
对于大型项目，我会将构建系统分解为多个CMakeLists.txt文件，每个目录一个，以保持组织结构的清晰。我会利用 add_subdirectory 命令来包含子目录，这样每个子目录可以有其自己的 CMakeLists.txt 文件来管理其源文件和依赖关系。我还会使用 CMake 的函数和宏来封装重复的逻辑，以减少重复代码并提高可维护性。通过这种方式，我可以保持构建系统的清晰和可管理，即使项目规模很大。

## 6.如何使用CMake来管理编译选项？
我通常会使用 CMake 的 set 命令来设置编译器标志，以及 add_compile_options 来添加编译选项。为了区分不同的构建类型（如Debug和Release），我会使用 CMAKE_BUILD_TYPE 变量，并根据这个变量的值来设置不同的编译选项。

    set(CMAKE_CXX_FLAGS_DEBUG "-g")
    set(CMAKE_CXX_FLAGS_RELEASE "-O3")

这样，在Debug构建中，-g 选项会被添加到编译命令中，而在 Release 构建中，-O3 选项会被添加。

## 7.如何集成第三方库？
为了集成第三方库，我通常会首先使用 find_package 命令来查找库是否已经安装在系统中。如果库提供了 CMake 配置文件，那么 find_package 会自动设置所有必要的变量和目标。如果库没有提供CMake支持，我可能需要手动设置库的路径和链接选项。

一旦找到库，我会使用 `target_link_libraries` 来链接库，并使用 `target_include_directories` 来添加头文件的搜索路径。

如果第三方库没有预先安装，或者我需要使用特定版本的库，我可能会将库的源代码包含在我的项目中，并使用 `add_subdirectory` 或 `ExternalProject_Add` 来构建和链接库。


## 8.如何确保项目的构建速度？

- **分离代码**：将项目分解为多个库和可执行文件，这样只有发生变化的部分需要被重新构建。
- **预编译头文件**：对于C++项目，使用预编译头文件可以显著减少编译时间。
- **并行构建**：使用make -j或其他构建工具的并行构建选项来利用多核CPU。
- **ccache**：使用ccache来缓存编译结果，避免重复编译。
- **优化编译选项**：谨慎使用编译优化选项，避免使用过度的优化，因为它们可能会增加编译时间。


## 9.如何确保项目的可测试性？
为了确保项目的可测试性，我会使用 CMake 的 `enable_testing` 和 `add_test` 命令来添加和管理测试。我会为项目中的每个测试用例创建一个可执行文件，并使用 `add_test` 来注册测试。然后，我可以使用 `ctest` 命令来运行所有的测试，并获取测试结果。

除了基本的测试注册和运行外，我还可以使用 `set_tests_properties` 来设置测试属性，如超时时间、所需的环境变量等。如果我的项目使用了Google Test或者其他测试框架，我还可以集成这些框架的 CMake 模块，以更方便地添加和运行测试。

## 10.遇到CMake构建错误时，你通常如何调试？
- **查看错误信息**：仔细阅读CMake或编译器提供的错误信息和警告，这通常会指向问题的根源。
- **增加消息输出**：使用message()函数在CMakeLists.txt文件中添加打印语句，以输出变量的值或显示代码执行的流程，帮助定位问题。
- **检查路径和变量**：确保所有的路径、文件名和变量设置都是正确的，特别是在使用相对路径或者环境变量时。
- **分阶段构建**：逐步执行CMake配置和构建过程，尝试定位问题发生的具体阶段。
- **查阅文档和社区帮助**：查阅CMake的官方文档，或者在Stack Overflow等社区寻找类似问题的解决方案。
- **简化CMakeLists.txt**：临时删除或注释掉一部分代码，逐步缩小问题范围，直到找到问题的根源。


## 11.如何确保CMake项目的安全性？

1. **避免使用不安全的函数和命令**：避免使用可能引入安全漏洞的CMake命令和函数。
2. **检查依赖库的安全性**：定期检查项目依赖的第三方库，确保它们是最新的，并且没有已知的安全漏洞。
3. **使用安全的编译选项**：使用编译器提供的安全相关编译选项，如栈保护等。使用安全的编译选项。
4. **代码审计**：定期进行代码审计，检查可能的安全漏洞。


## 12.如何管理外部依赖？
我通常会使用 find_package 来查找并加载外部依赖。如果依赖库提供了 CMake 支持，这将非常简单和直接。对于不提供 CMake 支持的库，我可能需要使用 find_path 和 find_library 来手动查找头文件和库文件。

我还会使用 ExternalProject_Add 或 FetchContent 来下载和构建未安装的依赖，这样我就可以确保使用正确的版本，并且不需要手动安装依赖。


## 13.请简单介绍Makefile是什么？
Makefile是用于编译和管理项目的一组规则和指令。它保存了编译器和连接器的参数选项，还表述了所有源文件之间的关系（如源代码文件需要的特定包含文件，可执行文件要求包含的目标文件模块及库等。

Makefile主要包含了以下几个部分：

- 显式规则：明确说明了如何生成一个或多个目标文件，包括要生成的文件、文件的依赖文件和生成命令。
- 隐晦规则：由make工具内置的推理规则组成，用于自动推导文件依赖关系。
- 变量定义：Makefile中可以使用变量来存储文件名、编译器选项等，以便在多处引用。
- 文件指示：包括include指令，用于引入其他Makefile文件。
- 注释：使用#符号开头的行作为注释。

## 14.Makefile中的依赖关系如何处理？
Makefile通过规则中的依赖关系来确定哪些文件需要被重新编译。当一个源文件被修改时，make会自动检查其依赖关系，并重新编译所有受影响的文件。


## 15.Makefile的调试技巧有哪些？
- 使用make -n或make --just-print选项可以查看make将要执行的命令，但不实际执行它们。
- 使用make -d或make --debug选项可以输出详细的调试信息，帮助诊断问题。
- 在Makefile中添加echo命令来输出变量的值或执行过程中的关键信息。

# GDB

## 1.GDB是什么？其主要功能有哪些？
GDB是GNU开源组织发布的一个强大的Unix/Linux下的程序调试工具。其主要功能包括：

1. 启动用户程序后，可以按照用户的要求随意运行程序。
1. 可让被调试的程序在用户所设定的断点处停住。
1. 当程序被停住时，可以检查或者说监视此时程序中的数值。
1. 可以修改被调试程序中的错误，并将修正后的程序继续执行。


## 2.简述GDB的基本操作？
GDB的基本操作主要包括：

1. 启动：通过gdb [可执行文件名]启动GDB，并加载要调试的程序。
1. 设置断点：使用b [行号]或b [函数名]在指定行或函数处设置断点。
1. 查看断点：使用info b查看已设置的断点信息。
1. 删除断点：使用d [断点编号]删除指定编号的断点。
1. 运行：使用r或run命令开始运行程序，程序运行到断点的位置会停下来。
1. 查看源代码：使用l或list命令查看源代码。
1. 逐过程执行：使用n或next命令逐过程执行代码，即一行一行地执行，但不进入函数内部。
1. 逐语句执行：使用s或step命令逐语句执行代码，包括进入函数内部。
1. 监视变量：使用watch [变量名]命令监视变量的值，当变量值发生变化时，GDB会自动停止程序。
2. gdb 还有另外一个 display 命令，每次程序暂停都可以自动显示变量值。
1. 退出GDB：使用q或quit命令退出GDB。

## 3.如何使用GDB调试多线程程序？
调试多线程程序时，GDB提供了以下功能：

- 查看线程列表：使用info threads命令查看当前进程的线程列表。
- 切换线程：使用thread [线程编号]命令切换到指定编号的线程。
- 设置调度器锁定：使用set scheduler-locking命令设置调度器锁定模式，以便在调试时控制其他线程的执行。常见的锁定模式有off（不锁定任何线程）、on（只有当前线程可以运行）和step（当单步调试某一个线程时，保证在调试过程中当前线程不会发生改变，其他线程也会随着被调试线程的单步执行而单步执行）。
- 调试技巧：在调试多线程程序时，需要特别注意线程间的同步和通信机制，以及避免竞态条件等问题。可以使用GDB的断点、监视点等功能来跟踪和调试线程的执行过程。

## 4.GDB如何调试coredump文件？
当程序崩溃时，操作系统可能会生成一个coredump文件（核心转储文件），该文件包含了程序崩溃时的内存映像和寄存器状态等信息。可以使用GDB来调试coredump文件以分析崩溃原因。具体步骤如下：

- **生成coredump文件**：在Linux系统中，可以通过设置ulimit -c unlimited命令来允许生成coredump文件。当程序崩溃时，会在程序所在目录下生成一个名为core或core.[pid]的文件。
- **加载coredump文件**：使用gdb [可执行文件名] [coredump文件名]命令加载coredump文件。GDB会自动加载可执行文件和coredump文件，并停留在程序崩溃时的位置。
- **查看调用堆栈**：使用bt或backtrace命令查看崩溃时的函数调用堆栈信息。通过分析调用堆栈可以确定导致崩溃的函数和代码位置。
- **分析崩溃原因**：根据调用堆栈信息和源代码分析崩溃原因。可能是数组越界、空指针引用、内存泄漏等问题导致的。根据分析结果进行修复并重新测试程序。

# boost 
Boost库是一个优秀的、可移植、开源的C++库，

- 可移植：几乎适用壬任何现代操作系统，Windows、Linux、UniX，包括UNIX和Windows变体。
- 开源免费：Boost库开源并免费；
- 高效：具有工业强度，设计结构良好，非常优秀的精品代码；


## 1.hpp文件
hpp（Header plus plus）头文件，顾名思义等于.h加上cpp，在boost开源库中频繁出现，其实质就是**将cpp的实现代码混入.h头文件当中 ，定义实现都包含在同一文件**。

hpp文件的优点：

- hpp文件将定义与实现都包含在同一文件；减少文件的数里。
- 无需再将cpp加入到项目中进行编译，将代码直接编译到调用者的obj文件中，不再生成单独的obj，大幅度减少编译次数，非常适合编写开源库。
- Boost 库大量使用模板，采用hpp的形式可以保持与各个扁译器更好的兼容性。

## 2.boost 

Boost常用的库很多都已经被包含到C++11、C++14或者C++17中了。

这里还是按照Boost程序库完全开发指针的目录结构进行总结。

- 常用功能库：
 - 关于时间的 chrono库， 已被加入C++11标准。
 - 关于随机数的random库，已被加入C++11标准。
 - 关于正则表达式的regex库，已被加入C++11标准。

- 内存管理：
 - 包括智能指针
 - scoped_ptr, 对于C++11中的unique_ptr。
 - shared_ptr， 已被加入C++11标准。
 - weak_ptr，已被加入C++11标准。
 - scoped_array
 - shared_array
 - scoped_array/shared_array是scoped_ptr/shared_ptr对动态数组的扩展，它们为动态数组提供了可自动删除的代理，shared_array比scoped_array有更多的用途，但我们应该使用vector和shared_ptr，除非程序对性能有非常苛刻的要求。

- 使用工具：
 - noncopyable，允许程序轻松实现一个禁止拷贝的类。它将拷贝构造函数和拷贝赋值函数设置为private，禁止进行拷贝和赋值。将默认构造函数设置为protected，禁止直接产出无意义的noncopyable对象。

 - ignore_unused，使用可变参数模板，可以支持任意数量、任意类型的变量，把它们作为函数的参数“使用”了一下，达到了与(void)var完全相同的效果。但它的命名更清晰，写法更简单，而且由于是inline函数，完全没有运行时的效率损失。

- uuid， 用来生成全局唯一的UUID。

- 容器与数据结构：
 - 定长数组类array，已被加入C++11标准。
 - 散列容器(无序关联容器)unordered_set、unordered_mulitset、unordered_map、unordered_multimap，已被加入C++11标准。
 - 环形缓冲区circular_buffer。
 - 元组tuple，已被加入C++11标准。
 - any，用来容纳任何类型的元素。 已被加入C++17标准。

- 函数与回调：
 - ref库，定义了一个很小很简单的引用类型的包装器，可以用来进行引用传递。 已被加入C++11标准。
 - bind库，是对C++98标准中函数适配器bind1st/bind2nd的泛化和增强，可以适配任意的可调用对象，包括函数指针，函数引用，成员函数指针和函数对象。已被加入到C++11标准。
 - function是一个函数对象的“容器”，概念上像是C/C++中函数指针类型的泛化，是一种“智能函数指针”。它以对象的形式封装了原始的函数指针或函数对象，能够容纳任意符合函数签名的可调用对象。因此可以被用于回调机制，暂时保管函数或函数对象，在之后需要的时机再调用，使回调机制拥有更多的弹性。 已被加入到C++11标准。

- 并发编程:
 - atomic实现原子操作。它封装了不同计算机硬件的底层操作原语，提供了跨平台的原子操作功能，让我们完全摆脱并发编程读写变量的困扰。
 - thread库实现了操作系统里的线程表示，赋值启动和管理线程对象。
 - asio库基于前摄器模式封装了操作系统的select、kqueue、poll/epoll、overlapped I/O 等机制，实现了异步IO模型。
